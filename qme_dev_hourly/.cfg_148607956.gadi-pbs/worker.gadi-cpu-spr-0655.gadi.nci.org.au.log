Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-03 10:52:37,371 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:39169'
2025-09-03 10:52:37,382 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:40139'
2025-09-03 10:52:37,385 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:41663'
2025-09-03 10:52:37,389 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:43019'
2025-09-03 10:52:37,393 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:37909'
2025-09-03 10:52:37,461 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:40325'
2025-09-03 10:52:37,466 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:37257'
2025-09-03 10:52:37,470 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:37627'
2025-09-03 10:52:37,475 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:45899'
2025-09-03 10:52:37,480 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:46705'
2025-09-03 10:52:37,486 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:36045'
2025-09-03 10:52:37,490 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:37385'
2025-09-03 10:52:37,495 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:43119'
2025-09-03 10:52:37,499 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:46507'
2025-09-03 10:52:37,503 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:45143'
2025-09-03 10:52:37,508 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:42113'
2025-09-03 10:52:37,513 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:46491'
2025-09-03 10:52:37,517 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:35619'
2025-09-03 10:52:37,523 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:41193'
2025-09-03 10:52:37,527 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:45047'
2025-09-03 10:52:37,532 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:34983'
2025-09-03 10:52:37,536 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:36779'
2025-09-03 10:52:37,541 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:43143'
2025-09-03 10:52:37,545 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:36427'
2025-09-03 10:52:37,551 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:43853'
2025-09-03 10:52:37,555 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:45777'
2025-09-03 10:52:37,560 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:36887'
2025-09-03 10:52:37,564 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:34913'
2025-09-03 10:52:37,569 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:34071'
2025-09-03 10:52:37,574 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:46731'
2025-09-03 10:52:37,578 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:36971'
2025-09-03 10:52:37,583 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:39735'
2025-09-03 10:52:37,586 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:34259'
2025-09-03 10:52:37,591 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:43849'
2025-09-03 10:52:37,595 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:35701'
2025-09-03 10:52:37,600 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:38361'
2025-09-03 10:52:37,603 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:35375'
2025-09-03 10:52:37,609 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:38025'
2025-09-03 10:52:37,612 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:42397'
2025-09-03 10:52:37,618 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:45959'
2025-09-03 10:52:37,622 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:35723'
2025-09-03 10:52:37,627 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:33369'
2025-09-03 10:52:37,782 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:33311'
2025-09-03 10:52:37,786 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:41129'
2025-09-03 10:52:37,792 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:39383'
2025-09-03 10:52:37,798 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:43665'
2025-09-03 10:52:37,804 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:43561'
2025-09-03 10:52:37,809 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:43407'
2025-09-03 10:52:37,814 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:35663'
2025-09-03 10:52:37,819 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:38713'
2025-09-03 10:52:37,823 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:37809'
2025-09-03 10:52:37,828 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:34101'
2025-09-03 10:52:37,832 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:34507'
2025-09-03 10:52:37,836 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:38983'
2025-09-03 10:52:37,840 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:33577'
2025-09-03 10:52:37,845 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:41419'
2025-09-03 10:52:37,850 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:46223'
2025-09-03 10:52:37,857 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:43549'
2025-09-03 10:52:37,862 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:36733'
2025-09-03 10:52:37,865 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:44913'
2025-09-03 10:52:37,868 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:38225'
2025-09-03 10:52:37,873 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:36367'
2025-09-03 10:52:37,876 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:35011'
2025-09-03 10:52:37,880 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:39253'
2025-09-03 10:52:37,884 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:44261'
2025-09-03 10:52:37,891 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:40881'
2025-09-03 10:52:37,894 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:46203'
2025-09-03 10:52:37,897 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:36221'
2025-09-03 10:52:37,900 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:40079'
2025-09-03 10:52:37,903 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:43469'
2025-09-03 10:52:37,908 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:42153'
2025-09-03 10:52:37,913 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:46319'
2025-09-03 10:52:37,920 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:44255'
2025-09-03 10:52:37,926 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:38007'
2025-09-03 10:52:37,930 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:43903'
2025-09-03 10:52:37,937 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:46383'
2025-09-03 10:52:37,942 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:41191'
2025-09-03 10:52:37,945 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:34431'
2025-09-03 10:52:37,963 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:41925'
2025-09-03 10:52:37,967 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:33073'
2025-09-03 10:52:37,972 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:35809'
2025-09-03 10:52:37,977 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:39187'
2025-09-03 10:52:37,980 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:46347'
2025-09-03 10:52:37,983 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:44353'
2025-09-03 10:52:37,988 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:45349'
2025-09-03 10:52:37,992 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:42045'
2025-09-03 10:52:37,997 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:46653'
2025-09-03 10:52:38,007 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:35593'
2025-09-03 10:52:38,014 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:45877'
2025-09-03 10:52:38,017 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:46471'
2025-09-03 10:52:38,024 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:45245'
2025-09-03 10:52:38,028 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:36111'
2025-09-03 10:52:38,031 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:45531'
2025-09-03 10:52:38,037 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:35785'
2025-09-03 10:52:38,041 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:33035'
2025-09-03 10:52:38,046 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:37773'
2025-09-03 10:52:38,049 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:38683'
2025-09-03 10:52:38,053 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:37395'
2025-09-03 10:52:38,056 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:33119'
2025-09-03 10:52:38,061 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:34285'
2025-09-03 10:52:38,067 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:45447'
2025-09-03 10:52:38,072 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:33377'
2025-09-03 10:52:38,077 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:40271'
2025-09-03 10:52:38,082 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:41409'
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:40055
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:37979
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:46145
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:41043
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:41483
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:42377
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:41545
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:40055
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:42101
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:40883
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:37979
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:33159
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:44155
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:40591
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:41383
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:45175
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:44805
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:46145
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:38381
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:42109
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:43643
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:40061
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:37289
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:38137
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:41043
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:33685
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:36473
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:41483
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:42377
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:44815
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:41545
2025-09-03 10:52:39,410 - distributed.worker - INFO -          dashboard at:           10.6.105.7:42879
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:38557
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:42101
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:40883
2025-09-03 10:52:39,410 - distributed.worker - INFO -          dashboard at:           10.6.105.7:35613
2025-09-03 10:52:39,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:37381
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:33159
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:44155
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:40591
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:41383
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:45175
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:44805
2025-09-03 10:52:39,410 - distributed.worker - INFO -          dashboard at:           10.6.105.7:34013
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:38381
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:42109
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:43643
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:40061
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:37289
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:38137
2025-09-03 10:52:39,410 - distributed.worker - INFO -          dashboard at:           10.6.105.7:36855
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:33685
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:36473
2025-09-03 10:52:39,410 - distributed.worker - INFO -          dashboard at:           10.6.105.7:42523
2025-09-03 10:52:39,410 - distributed.worker - INFO -          dashboard at:           10.6.105.7:45399
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:44815
2025-09-03 10:52:39,410 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,410 - distributed.worker - INFO -          dashboard at:           10.6.105.7:46427
2025-09-03 10:52:39,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:38557
2025-09-03 10:52:39,411 - distributed.worker - INFO -          dashboard at:           10.6.105.7:37287
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO -          dashboard at:           10.6.105.7:43619
2025-09-03 10:52:39,411 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:37381
2025-09-03 10:52:39,411 - distributed.worker - INFO -          dashboard at:           10.6.105.7:39119
2025-09-03 10:52:39,411 - distributed.worker - INFO -          dashboard at:           10.6.105.7:36705
2025-09-03 10:52:39,411 - distributed.worker - INFO -          dashboard at:           10.6.105.7:33855
2025-09-03 10:52:39,411 - distributed.worker - INFO -          dashboard at:           10.6.105.7:45277
2025-09-03 10:52:39,411 - distributed.worker - INFO -          dashboard at:           10.6.105.7:44399
2025-09-03 10:52:39,411 - distributed.worker - INFO -          dashboard at:           10.6.105.7:38287
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO -          dashboard at:           10.6.105.7:42673
2025-09-03 10:52:39,411 - distributed.worker - INFO -          dashboard at:           10.6.105.7:35435
2025-09-03 10:52:39,411 - distributed.worker - INFO -          dashboard at:           10.6.105.7:34545
2025-09-03 10:52:39,411 - distributed.worker - INFO -          dashboard at:           10.6.105.7:36873
2025-09-03 10:52:39,411 - distributed.worker - INFO -          dashboard at:           10.6.105.7:32953
2025-09-03 10:52:39,411 - distributed.worker - INFO -          dashboard at:           10.6.105.7:42729
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO -          dashboard at:           10.6.105.7:36837
2025-09-03 10:52:39,411 - distributed.worker - INFO -          dashboard at:           10.6.105.7:37413
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO -          dashboard at:           10.6.105.7:35325
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO -          dashboard at:           10.6.105.7:36741
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO -          dashboard at:           10.6.105.7:37819
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-e5hqfqgj
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-4kqg9i66
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-m_ka3wfm
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-94mg29_6
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-gxg5enhe
2025-09-03 10:52:39,412 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-fvggxd71
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-4nx9nbiq
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-4lx67xq9
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-fh414fcm
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-as_bjdq5
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-o49v4jv9
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-azszj297
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-3rmuxx_4
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-escrj3x5
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-br0f35_v
2025-09-03 10:52:39,412 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-06qd9uga
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ojv5f01c
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-g4d4pkkc
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-kdi5ca7b
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-77ypn4eo
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ppulc3b4
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-t6_nt7im
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-9th53w7u
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ym75lufb
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-xowf_99z
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-gxxsuw6n
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:36595
2025-09-03 10:52:39,412 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:36595
2025-09-03 10:52:39,412 - distributed.worker - INFO -          dashboard at:           10.6.105.7:33387
2025-09-03 10:52:39,412 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,412 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,412 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:37551
2025-09-03 10:52:39,412 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,413 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:37551
2025-09-03 10:52:39,413 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-gpe3z2vx
2025-09-03 10:52:39,413 - distributed.worker - INFO -          dashboard at:           10.6.105.7:45737
2025-09-03 10:52:39,413 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,413 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,413 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,413 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,413 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,413 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-xry2tvhb
2025-09-03 10:52:39,413 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,441 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:43025
2025-09-03 10:52:39,441 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:43025
2025-09-03 10:52:39,441 - distributed.worker - INFO -          dashboard at:           10.6.105.7:42215
2025-09-03 10:52:39,441 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,441 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,441 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,441 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,441 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-kz2sd0t1
2025-09-03 10:52:39,441 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,524 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:42783
2025-09-03 10:52:39,524 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:42783
2025-09-03 10:52:39,524 - distributed.worker - INFO -          dashboard at:           10.6.105.7:40767
2025-09-03 10:52:39,524 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,524 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,524 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,524 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,524 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-8ix3f633
2025-09-03 10:52:39,524 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,526 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:38071
2025-09-03 10:52:39,526 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:38071
2025-09-03 10:52:39,526 - distributed.worker - INFO -          dashboard at:           10.6.105.7:42851
2025-09-03 10:52:39,526 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,526 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,526 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,526 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,526 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-qeo75fve
2025-09-03 10:52:39,526 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,530 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:44983
2025-09-03 10:52:39,530 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:44983
2025-09-03 10:52:39,530 - distributed.worker - INFO -          dashboard at:           10.6.105.7:34875
2025-09-03 10:52:39,530 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,530 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,530 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,530 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,530 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-lgg6jirr
2025-09-03 10:52:39,530 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,543 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:36429
2025-09-03 10:52:39,543 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:36429
2025-09-03 10:52:39,543 - distributed.worker - INFO -          dashboard at:           10.6.105.7:44433
2025-09-03 10:52:39,543 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,543 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,543 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,543 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,543 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-7eethsmq
2025-09-03 10:52:39,543 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,545 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:36531
2025-09-03 10:52:39,545 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:36531
2025-09-03 10:52:39,546 - distributed.worker - INFO -          dashboard at:           10.6.105.7:36431
2025-09-03 10:52:39,546 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,546 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,546 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,546 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,546 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-e4u_bqr0
2025-09-03 10:52:39,546 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,548 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:43245
2025-09-03 10:52:39,548 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:43245
2025-09-03 10:52:39,548 - distributed.worker - INFO -          dashboard at:           10.6.105.7:46001
2025-09-03 10:52:39,548 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,548 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,548 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,548 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,548 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-h6yilx89
2025-09-03 10:52:39,548 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,605 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:36775
2025-09-03 10:52:39,605 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:36775
2025-09-03 10:52:39,606 - distributed.worker - INFO -          dashboard at:           10.6.105.7:34853
2025-09-03 10:52:39,606 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,606 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,606 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,606 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,606 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-tms6uare
2025-09-03 10:52:39,606 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,611 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:42169
2025-09-03 10:52:39,611 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:42169
2025-09-03 10:52:39,611 - distributed.worker - INFO -          dashboard at:           10.6.105.7:41783
2025-09-03 10:52:39,611 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,611 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,612 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,612 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,612 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-0c5x_7n7
2025-09-03 10:52:39,612 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,766 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:38681
2025-09-03 10:52:39,766 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:38681
2025-09-03 10:52:39,766 - distributed.worker - INFO -          dashboard at:           10.6.105.7:43909
2025-09-03 10:52:39,766 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,766 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,766 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,767 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,767 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ra9qsmnf
2025-09-03 10:52:39,767 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,789 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:41107
2025-09-03 10:52:39,789 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:41107
2025-09-03 10:52:39,789 - distributed.worker - INFO -          dashboard at:           10.6.105.7:40639
2025-09-03 10:52:39,789 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,789 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,789 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,789 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,789 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-jx8rlius
2025-09-03 10:52:39,790 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,792 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:38173
2025-09-03 10:52:39,792 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:38173
2025-09-03 10:52:39,792 - distributed.worker - INFO -          dashboard at:           10.6.105.7:34001
2025-09-03 10:52:39,792 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,792 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,792 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,792 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,792 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-rfa7v5vc
2025-09-03 10:52:39,792 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,826 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:34935
2025-09-03 10:52:39,827 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:34935
2025-09-03 10:52:39,827 - distributed.worker - INFO -          dashboard at:           10.6.105.7:36735
2025-09-03 10:52:39,827 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,827 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,827 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,827 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,827 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-a2yvz28m
2025-09-03 10:52:39,827 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,839 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:45643
2025-09-03 10:52:39,839 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:45643
2025-09-03 10:52:39,839 - distributed.worker - INFO -          dashboard at:           10.6.105.7:39411
2025-09-03 10:52:39,839 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,839 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,839 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,840 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,840 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-71_simpg
2025-09-03 10:52:39,840 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,841 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:38089
2025-09-03 10:52:39,842 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:38089
2025-09-03 10:52:39,842 - distributed.worker - INFO -          dashboard at:           10.6.105.7:46827
2025-09-03 10:52:39,842 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,842 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,842 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,842 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,842 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-we76cnbu
2025-09-03 10:52:39,842 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,896 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:37501
2025-09-03 10:52:39,896 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:37501
2025-09-03 10:52:39,896 - distributed.worker - INFO -          dashboard at:           10.6.105.7:39467
2025-09-03 10:52:39,896 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,896 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,896 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,896 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,896 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-3nlqu9gk
2025-09-03 10:52:39,896 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,949 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:32895
2025-09-03 10:52:39,949 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:32895
2025-09-03 10:52:39,949 - distributed.worker - INFO -          dashboard at:           10.6.105.7:36937
2025-09-03 10:52:39,949 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,949 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,949 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,949 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,949 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-8ibdz23m
2025-09-03 10:52:39,949 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,997 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:36261
2025-09-03 10:52:39,997 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:36261
2025-09-03 10:52:39,997 - distributed.worker - INFO -          dashboard at:           10.6.105.7:36749
2025-09-03 10:52:39,997 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,997 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,997 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,997 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,997 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-jtexx803
2025-09-03 10:52:39,997 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,017 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:33593
2025-09-03 10:52:40,018 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:33593
2025-09-03 10:52:40,018 - distributed.worker - INFO -          dashboard at:           10.6.105.7:39227
2025-09-03 10:52:40,018 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,018 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,018 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,018 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,018 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-bzz8tkgv
2025-09-03 10:52:40,018 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,031 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:38207
2025-09-03 10:52:40,031 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:38207
2025-09-03 10:52:40,032 - distributed.worker - INFO -          dashboard at:           10.6.105.7:39807
2025-09-03 10:52:40,032 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,032 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,032 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,032 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,032 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-jph39klx
2025-09-03 10:52:40,032 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,064 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,065 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,065 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,067 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,078 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,079 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,081 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,092 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,093 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,093 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,095 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,103 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:45933
2025-09-03 10:52:40,104 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:45933
2025-09-03 10:52:40,104 - distributed.worker - INFO -          dashboard at:           10.6.105.7:38389
2025-09-03 10:52:40,104 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,104 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,104 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,104 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,104 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-f0wljirn
2025-09-03 10:52:40,104 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,105 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,105 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,105 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,106 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,120 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,121 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,121 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,122 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,133 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,135 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,135 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,136 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,147 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,148 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,149 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,150 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,161 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,162 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,162 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,164 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,175 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,176 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,176 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,178 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:40611
2025-09-03 10:52:40,178 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:40611
2025-09-03 10:52:40,178 - distributed.worker - INFO -          dashboard at:           10.6.105.7:44481
2025-09-03 10:52:40,178 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,178 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,178 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,178 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,178 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-pt2fs9qb
2025-09-03 10:52:40,178 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,178 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,190 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,191 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,191 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,193 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,194 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:38699
2025-09-03 10:52:40,194 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:38699
2025-09-03 10:52:40,194 - distributed.worker - INFO -          dashboard at:           10.6.105.7:35307
2025-09-03 10:52:40,194 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,194 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,194 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,194 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,194 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-r8xvnw2k
2025-09-03 10:52:40,195 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,203 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,204 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,205 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,206 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,217 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,219 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,219 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,220 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,231 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,233 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,233 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,235 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,246 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,247 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,247 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,248 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,250 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:42797
2025-09-03 10:52:40,251 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:42797
2025-09-03 10:52:40,251 - distributed.worker - INFO -          dashboard at:           10.6.105.7:35933
2025-09-03 10:52:40,251 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,251 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,251 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,251 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,251 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-2tmyvzsm
2025-09-03 10:52:40,251 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,254 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:44989
2025-09-03 10:52:40,254 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:44989
2025-09-03 10:52:40,255 - distributed.worker - INFO -          dashboard at:           10.6.105.7:39403
2025-09-03 10:52:40,255 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,255 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,255 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,255 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,255 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-x7o_mc52
2025-09-03 10:52:40,255 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,259 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:40945
2025-09-03 10:52:40,259 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:40945
2025-09-03 10:52:40,259 - distributed.worker - INFO -          dashboard at:           10.6.105.7:41183
2025-09-03 10:52:40,259 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,259 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,259 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,259 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,259 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-3ys0z1ez
2025-09-03 10:52:40,259 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,259 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,261 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,261 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,263 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,269 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:39091
2025-09-03 10:52:40,269 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:39091
2025-09-03 10:52:40,269 - distributed.worker - INFO -          dashboard at:           10.6.105.7:37735
2025-09-03 10:52:40,269 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,269 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,269 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,269 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,269 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-0q7mgjkq
2025-09-03 10:52:40,269 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,272 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:36823
2025-09-03 10:52:40,272 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:36823
2025-09-03 10:52:40,272 - distributed.worker - INFO -          dashboard at:           10.6.105.7:42927
2025-09-03 10:52:40,272 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,272 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,272 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,272 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,272 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-bjanhzgd
2025-09-03 10:52:40,272 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,274 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,275 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,275 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,276 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,287 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,289 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,289 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,289 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:37177
2025-09-03 10:52:40,289 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:37177
2025-09-03 10:52:40,289 - distributed.worker - INFO -          dashboard at:           10.6.105.7:46643
2025-09-03 10:52:40,289 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,289 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,289 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,289 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,289 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-vrfbef62
2025-09-03 10:52:40,289 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,290 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,298 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:42185
2025-09-03 10:52:40,298 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:42185
2025-09-03 10:52:40,298 - distributed.worker - INFO -          dashboard at:           10.6.105.7:33263
2025-09-03 10:52:40,298 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,299 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,299 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,299 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,299 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-7n3mgzqs
2025-09-03 10:52:40,299 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,302 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:32977
2025-09-03 10:52:40,302 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:32977
2025-09-03 10:52:40,302 - distributed.worker - INFO -          dashboard at:           10.6.105.7:39497
2025-09-03 10:52:40,302 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,302 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,302 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,302 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,302 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,302 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ufw0pedh
2025-09-03 10:52:40,302 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,303 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,303 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,304 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:39405
2025-09-03 10:52:40,304 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:39405
2025-09-03 10:52:40,304 - distributed.worker - INFO -          dashboard at:           10.6.105.7:40607
2025-09-03 10:52:40,305 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,305 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,305 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,305 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,305 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-b6_v3yrx
2025-09-03 10:52:40,305 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,305 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,315 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,316 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,317 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,318 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:43611
2025-09-03 10:52:40,318 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:43611
2025-09-03 10:52:40,318 - distributed.worker - INFO -          dashboard at:           10.6.105.7:39605
2025-09-03 10:52:40,318 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,318 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,318 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,318 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,318 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-27fvgz_l
2025-09-03 10:52:40,318 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,318 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,319 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:41009
2025-09-03 10:52:40,319 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:41009
2025-09-03 10:52:40,319 - distributed.worker - INFO -          dashboard at:           10.6.105.7:36663
2025-09-03 10:52:40,319 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,319 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,319 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,319 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,319 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-h7ifu7ol
2025-09-03 10:52:40,319 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,330 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,331 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,331 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,333 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,344 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,345 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,345 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,347 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,358 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,359 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,359 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,361 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,372 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,373 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,373 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,375 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,386 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,387 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,387 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,389 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,400 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,401 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,401 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,403 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,414 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,415 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,416 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,419 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,428 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,429 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,430 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,431 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,443 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,445 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,446 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,450 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,458 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,460 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,460 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,463 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,468 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:36987
2025-09-03 10:52:40,468 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:36987
2025-09-03 10:52:40,468 - distributed.worker - INFO -          dashboard at:           10.6.105.7:41185
2025-09-03 10:52:40,468 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,468 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,468 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,468 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,468 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-hgh9xlqm
2025-09-03 10:52:40,468 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,488 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:44397
2025-09-03 10:52:40,488 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:44397
2025-09-03 10:52:40,488 - distributed.worker - INFO -          dashboard at:           10.6.105.7:43785
2025-09-03 10:52:40,488 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,488 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,488 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,488 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,488 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-_beyzo79
2025-09-03 10:52:40,488 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,489 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:38753
2025-09-03 10:52:40,490 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:38753
2025-09-03 10:52:40,490 - distributed.worker - INFO -          dashboard at:           10.6.105.7:41847
2025-09-03 10:52:40,490 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,490 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,490 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,490 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,490 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-uc8rjpgb
2025-09-03 10:52:40,490 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,509 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:42177
2025-09-03 10:52:40,509 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:42177
2025-09-03 10:52:40,510 - distributed.worker - INFO -          dashboard at:           10.6.105.7:39913
2025-09-03 10:52:40,510 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,510 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,510 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,510 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,510 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ivq279p3
2025-09-03 10:52:40,510 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,547 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:34219
2025-09-03 10:52:40,547 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:34219
2025-09-03 10:52:40,547 - distributed.worker - INFO -          dashboard at:           10.6.105.7:45409
2025-09-03 10:52:40,547 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,547 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,547 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,548 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-r6c86nry
2025-09-03 10:52:40,548 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,586 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:38167
2025-09-03 10:52:40,586 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:38167
2025-09-03 10:52:40,586 - distributed.worker - INFO -          dashboard at:           10.6.105.7:38099
2025-09-03 10:52:40,586 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,586 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,586 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,586 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,586 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-_yjlh6fd
2025-09-03 10:52:40,586 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,616 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,618 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,618 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,619 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,658 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:42447
2025-09-03 10:52:40,658 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:42447
2025-09-03 10:52:40,658 - distributed.worker - INFO -          dashboard at:           10.6.105.7:33141
2025-09-03 10:52:40,658 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,658 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,658 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,658 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,658 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-c0jn11g5
2025-09-03 10:52:40,658 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,662 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:33221
2025-09-03 10:52:40,662 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:33221
2025-09-03 10:52:40,662 - distributed.worker - INFO -          dashboard at:           10.6.105.7:38179
2025-09-03 10:52:40,662 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,662 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,662 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,662 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,662 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-f_ttbffv
2025-09-03 10:52:40,662 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,673 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,674 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,674 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,676 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,687 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,688 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,688 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,690 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,694 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:37741
2025-09-03 10:52:40,694 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:37741
2025-09-03 10:52:40,694 - distributed.worker - INFO -          dashboard at:           10.6.105.7:33969
2025-09-03 10:52:40,694 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,694 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,694 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,694 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,694 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-kwsb64uc
2025-09-03 10:52:40,694 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,703 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:38483
2025-09-03 10:52:40,703 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:38483
2025-09-03 10:52:40,703 - distributed.worker - INFO -          dashboard at:           10.6.105.7:33989
2025-09-03 10:52:40,703 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,703 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,703 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,703 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,703 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-1vij3g4q
2025-09-03 10:52:40,703 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,715 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:38779
2025-09-03 10:52:40,715 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:38779
2025-09-03 10:52:40,715 - distributed.worker - INFO -          dashboard at:           10.6.105.7:45225
2025-09-03 10:52:40,715 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,715 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,715 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,715 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,715 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-5prj769t
2025-09-03 10:52:40,715 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,717 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:34823
2025-09-03 10:52:40,717 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:34823
2025-09-03 10:52:40,717 - distributed.worker - INFO -          dashboard at:           10.6.105.7:40005
2025-09-03 10:52:40,717 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,717 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,717 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,717 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,717 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-_889tees
2025-09-03 10:52:40,717 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,725 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:44221
2025-09-03 10:52:40,725 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:44221
2025-09-03 10:52:40,725 - distributed.worker - INFO -          dashboard at:           10.6.105.7:33805
2025-09-03 10:52:40,725 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,725 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,725 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,725 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,725 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-hkjlmc4b
2025-09-03 10:52:40,725 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,737 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:44733
2025-09-03 10:52:40,737 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:44733
2025-09-03 10:52:40,737 - distributed.worker - INFO -          dashboard at:           10.6.105.7:44043
2025-09-03 10:52:40,737 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,737 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,737 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,737 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,737 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-k1lhvxp8
2025-09-03 10:52:40,737 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,754 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:35925
2025-09-03 10:52:40,754 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:35925
2025-09-03 10:52:40,754 - distributed.worker - INFO -          dashboard at:           10.6.105.7:33587
2025-09-03 10:52:40,754 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,754 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,754 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,754 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,754 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-s08gp0r9
2025-09-03 10:52:40,755 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,758 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:37439
2025-09-03 10:52:40,758 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:37439
2025-09-03 10:52:40,758 - distributed.worker - INFO -          dashboard at:           10.6.105.7:38277
2025-09-03 10:52:40,758 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,758 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,758 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,758 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,758 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-alzeez49
2025-09-03 10:52:40,758 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,771 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,773 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,773 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,774 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,855 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,856 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,856 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,858 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,883 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,884 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,885 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,886 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,891 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:41765
2025-09-03 10:52:40,891 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:41765
2025-09-03 10:52:40,891 - distributed.worker - INFO -          dashboard at:           10.6.105.7:43751
2025-09-03 10:52:40,891 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,891 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,891 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,891 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,891 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-klbsw_sm
2025-09-03 10:52:40,891 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,914 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:43661
2025-09-03 10:52:40,914 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:43661
2025-09-03 10:52:40,914 - distributed.worker - INFO -          dashboard at:           10.6.105.7:40595
2025-09-03 10:52:40,914 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,914 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,914 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,914 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,914 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-hfd3iz0z
2025-09-03 10:52:40,914 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,926 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:37447
2025-09-03 10:52:40,926 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:37447
2025-09-03 10:52:40,926 - distributed.worker - INFO -          dashboard at:           10.6.105.7:45401
2025-09-03 10:52:40,926 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,926 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,926 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,926 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,926 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-t9y56cu5
2025-09-03 10:52:40,926 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,020 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:45611
2025-09-03 10:52:41,020 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:45611
2025-09-03 10:52:41,020 - distributed.worker - INFO -          dashboard at:           10.6.105.7:33653
2025-09-03 10:52:41,020 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,020 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,020 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,020 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,020 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-65zmp3ie
2025-09-03 10:52:41,020 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,039 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:36825
2025-09-03 10:52:41,039 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:36825
2025-09-03 10:52:41,039 - distributed.worker - INFO -          dashboard at:           10.6.105.7:43249
2025-09-03 10:52:41,039 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,039 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,039 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,039 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,039 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-cbhdg3sq
2025-09-03 10:52:41,039 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,039 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:45441
2025-09-03 10:52:41,039 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:45441
2025-09-03 10:52:41,039 - distributed.worker - INFO -          dashboard at:           10.6.105.7:39543
2025-09-03 10:52:41,039 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,040 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,040 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,040 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,040 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-be6_e8ka
2025-09-03 10:52:41,040 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,043 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:42663
2025-09-03 10:52:41,043 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:42663
2025-09-03 10:52:41,043 - distributed.worker - INFO -          dashboard at:           10.6.105.7:42023
2025-09-03 10:52:41,043 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,043 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,043 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,043 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,043 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-14kwfgxb
2025-09-03 10:52:41,043 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,045 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:39199
2025-09-03 10:52:41,045 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:39199
2025-09-03 10:52:41,045 - distributed.worker - INFO -          dashboard at:           10.6.105.7:37541
2025-09-03 10:52:41,045 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,045 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,045 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,045 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,045 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-aeq82f41
2025-09-03 10:52:41,045 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,045 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:33563
2025-09-03 10:52:41,045 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:33563
2025-09-03 10:52:41,045 - distributed.worker - INFO -          dashboard at:           10.6.105.7:39369
2025-09-03 10:52:41,045 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,045 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,045 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,045 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,045 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-7jptsrl4
2025-09-03 10:52:41,045 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,047 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:41603
2025-09-03 10:52:41,047 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:41603
2025-09-03 10:52:41,048 - distributed.worker - INFO -          dashboard at:           10.6.105.7:39335
2025-09-03 10:52:41,048 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,048 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,048 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,048 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,048 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-iogykf9l
2025-09-03 10:52:41,048 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,054 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:38969
2025-09-03 10:52:41,054 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:38969
2025-09-03 10:52:41,054 - distributed.worker - INFO -          dashboard at:           10.6.105.7:41787
2025-09-03 10:52:41,054 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,054 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,054 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,054 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,054 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-wf_67byz
2025-09-03 10:52:41,054 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,056 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:44423
2025-09-03 10:52:41,056 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:44423
2025-09-03 10:52:41,056 - distributed.worker - INFO -          dashboard at:           10.6.105.7:33393
2025-09-03 10:52:41,056 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,056 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,056 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,056 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,056 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-bhug0jl8
2025-09-03 10:52:41,056 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:46209
2025-09-03 10:52:41,057 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:46209
2025-09-03 10:52:41,057 - distributed.worker - INFO -          dashboard at:           10.6.105.7:40733
2025-09-03 10:52:41,057 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,057 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,057 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,057 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,057 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ynixbanr
2025-09-03 10:52:41,057 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,059 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:46655
2025-09-03 10:52:41,059 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:46655
2025-09-03 10:52:41,059 - distributed.worker - INFO -          dashboard at:           10.6.105.7:44857
2025-09-03 10:52:41,059 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,059 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,059 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-h_c5ilas
2025-09-03 10:52:41,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,059 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:39723
2025-09-03 10:52:41,060 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:39723
2025-09-03 10:52:41,060 - distributed.worker - INFO -          dashboard at:           10.6.105.7:34329
2025-09-03 10:52:41,060 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,060 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,060 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,060 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,060 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-wuyizwn6
2025-09-03 10:52:41,060 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,068 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:37821
2025-09-03 10:52:41,068 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:37821
2025-09-03 10:52:41,068 - distributed.worker - INFO -          dashboard at:           10.6.105.7:40645
2025-09-03 10:52:41,068 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,068 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,068 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,068 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,068 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-h5uvtrvb
2025-09-03 10:52:41,068 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,075 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:42857
2025-09-03 10:52:41,075 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:42857
2025-09-03 10:52:41,075 - distributed.worker - INFO -          dashboard at:           10.6.105.7:41011
2025-09-03 10:52:41,075 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,075 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,075 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,075 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,075 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-nwxwi0w9
2025-09-03 10:52:41,075 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,077 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:38695
2025-09-03 10:52:41,077 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:38695
2025-09-03 10:52:41,077 - distributed.worker - INFO -          dashboard at:           10.6.105.7:45223
2025-09-03 10:52:41,077 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,077 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,077 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,077 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,077 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-a31hit_z
2025-09-03 10:52:41,077 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,079 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:43865
2025-09-03 10:52:41,079 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:43865
2025-09-03 10:52:41,079 - distributed.worker - INFO -          dashboard at:           10.6.105.7:42713
2025-09-03 10:52:41,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,079 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,079 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,079 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-85cgsj83
2025-09-03 10:52:41,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,079 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:37789
2025-09-03 10:52:41,079 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:37789
2025-09-03 10:52:41,079 - distributed.worker - INFO -          dashboard at:           10.6.105.7:33833
2025-09-03 10:52:41,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,080 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,080 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,080 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-d7_x9mda
2025-09-03 10:52:41,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,084 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:39707
2025-09-03 10:52:41,084 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:39707
2025-09-03 10:52:41,084 - distributed.worker - INFO -          dashboard at:           10.6.105.7:32983
2025-09-03 10:52:41,084 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,084 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,084 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,084 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,084 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-rkwb3q9d
2025-09-03 10:52:41,084 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,084 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:41373
2025-09-03 10:52:41,084 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:41373
2025-09-03 10:52:41,084 - distributed.worker - INFO -          dashboard at:           10.6.105.7:33835
2025-09-03 10:52:41,084 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,084 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,084 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,084 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,084 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-zwup85xo
2025-09-03 10:52:41,084 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,088 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:44333
2025-09-03 10:52:41,088 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:44333
2025-09-03 10:52:41,088 - distributed.worker - INFO -          dashboard at:           10.6.105.7:42577
2025-09-03 10:52:41,088 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,088 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,088 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,088 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,088 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ghxfs3pl
2025-09-03 10:52:41,088 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,095 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,096 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,096 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,097 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:33681
2025-09-03 10:52:41,097 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:33681
2025-09-03 10:52:41,097 - distributed.worker - INFO -          dashboard at:           10.6.105.7:32987
2025-09-03 10:52:41,097 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,097 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,097 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,097 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,097 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-nm8fihzi
2025-09-03 10:52:41,097 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,098 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:41,107 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:36269
2025-09-03 10:52:41,107 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:36269
2025-09-03 10:52:41,107 - distributed.worker - INFO -          dashboard at:           10.6.105.7:42259
2025-09-03 10:52:41,107 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,107 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,107 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,107 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,107 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-j4fkir8a
2025-09-03 10:52:41,107 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,172 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:44467
2025-09-03 10:52:41,173 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:44467
2025-09-03 10:52:41,173 - distributed.worker - INFO -          dashboard at:           10.6.105.7:37387
2025-09-03 10:52:41,173 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,173 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,173 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,173 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,173 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-9_xbhyb3
2025-09-03 10:52:41,173 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,379 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,381 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,381 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,383 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:41,409 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,410 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,410 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,413 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:41,487 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,489 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,489 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,491 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:41,630 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,632 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,632 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,634 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:41,731 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,732 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,732 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,734 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:41,760 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,762 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,762 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,764 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:41,817 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,819 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,819 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,821 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:41,831 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,833 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,833 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,834 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:41,846 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,848 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,848 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,850 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:41,875 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,876 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,876 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,879 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:41,889 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,891 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,891 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,893 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:41,947 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,948 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,948 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,950 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:41,990 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,991 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,991 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,993 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,004 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,005 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,006 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,008 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,032 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,033 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,034 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,035 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,090 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,091 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,091 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,093 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,104 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,105 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,106 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,108 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,490 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,491 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,491 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,493 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,519 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,520 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,521 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,522 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,739 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,740 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,740 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,742 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,913 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,915 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,915 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,917 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:43,533 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:43,536 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:43,536 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:43,541 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:43,560 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:43,561 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:43,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:43,564 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:45,133 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:45,134 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:45,134 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:45,137 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:45,297 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:45,298 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:45,299 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:45,301 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:45,311 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:45,312 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:45,313 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:45,314 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:45,759 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:45,760 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:45,761 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:45,762 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:45,895 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:45,896 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:45,896 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:45,898 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:45,910 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:45,911 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:45,911 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:45,913 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:45,924 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:45,926 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:45,926 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:45,928 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:45,945 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:45,949 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:45,949 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:45,955 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:45,955 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:45,956 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:45,956 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:45,958 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:45,970 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:45,971 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:45,971 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:45,973 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:45,985 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:45,986 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:45,986 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:45,988 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,000 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,001 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,001 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,003 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,015 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,016 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,016 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,018 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,030 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,031 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,031 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,033 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,044 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,045 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,045 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,047 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,060 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,061 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,061 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,063 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,074 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,075 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,076 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,077 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,089 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,090 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,090 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,092 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,104 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,105 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,105 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,107 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,119 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,120 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,120 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,122 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,134 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,135 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,135 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,137 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,148 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,150 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,150 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,151 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,164 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,165 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,165 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,167 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,793 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,797 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,800 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,800 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,802 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,807 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,808 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,809 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,811 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,811 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,812 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,915 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,916 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,917 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,918 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,931 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,932 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,932 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,934 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,946 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,947 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,947 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,949 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,961 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,962 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,962 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,964 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,976 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,977 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,977 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,979 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,991 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,992 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,992 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,994 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:47,006 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:47,007 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:47,007 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:47,009 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:50,001 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:50,002 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:50,002 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:50,004 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:09,526 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:53:09,528 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:53:09,532 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:53:09,545 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:53:09,546 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:53:09,549 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:53:09,607 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:53:09,613 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:53:10,893 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:53:10,915 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:53:10,929 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:53:11,775 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:16,900 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:16,914 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:17,005 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:17,021 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:17,036 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:17,050 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:17,066 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:17,081 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:19,259 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:19,260 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:19,260 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:19,261 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:19,277 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:19,278 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:19,278 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:19,279 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:19,382 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:19,383 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:19,383 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:19,385 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:19,505 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:19,506 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:19,506 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:19,508 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:19,522 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:19,523 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:19,524 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:19,525 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:19,539 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:19,541 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:19,541 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:19,542 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:22,208 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:22,210 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:22,210 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:22,212 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:39,709 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:53:39,715 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:53:40,717 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:40,718 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:40,718 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:40,720 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:40,753 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:40,754 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:40,754 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:40,756 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:41,016 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:53:41,032 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:53:42,416 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:42,417 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:42,417 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:42,419 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:42,508 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:42,510 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:42,511 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:42,516 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:42,777 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:56:38,259 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:38,261 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:38,282 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:38,288 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:38,682 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:38,687 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:39,369 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:39,370 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:39,384 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:39,386 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:39,562 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:39,564 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:39,647 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:39,653 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:39,681 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:39,687 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,356 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,359 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,583 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,588 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,845 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,844 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,850 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,852 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,852 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,856 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,959 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,961 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,058 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,059 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,084 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,085 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,087 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,093 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,183 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,188 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,761 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,766 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:42,261 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,263 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:42,898 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,903 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:42,910 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,912 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:43,175 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:43,178 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:43,396 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:43,407 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:43,410 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:43,415 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:43,850 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:43,856 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:43,904 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:43,905 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:44,091 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:44,092 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:44,161 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:44,163 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:44,182 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:44,187 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:44,311 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:44,313 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:44,497 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:44,499 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:44,520 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:44,521 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:44,585 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:44,586 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:44,845 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:44,852 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:44,948 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:44,950 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,085 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,086 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,521 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,527 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,655 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,660 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,749 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,754 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:46,050 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:46,056 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:46,084 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:46,089 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:46,089 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:46,094 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:46,240 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:46,246 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:46,435 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:46,439 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:46,493 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:46,495 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,079 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,083 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,216 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,217 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,256 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,259 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,522 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,526 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,577 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,583 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:48,124 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:48,128 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:48,397 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:48,402 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:48,501 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:48,506 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:48,623 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:48,629 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:48,881 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:48,883 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,288 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,289 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,295 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,301 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,457 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,461 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,211 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,216 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,407 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,409 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,524 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,526 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,746 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,753 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,754 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,758 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,261 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,262 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,303 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,305 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,353 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,358 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,853 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,854 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,930 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,931 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,933 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,934 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,979 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,985 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,991 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,993 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,045 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,052 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,310 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,311 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,488 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,489 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,539 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,544 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,614 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,616 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,766 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,771 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,830 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,832 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,979 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,981 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,096 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,097 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,253 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,260 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,324 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,331 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,343 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,347 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,821 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,824 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,831 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,838 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:54,012 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:54,013 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:54,200 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:54,206 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:54,363 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:54,364 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:54,441 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:54,442 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:55,556 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:55,561 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:55,757 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:55,758 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:55,914 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:55,919 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:56,151 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:56,156 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:56,761 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:56,766 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:57,270 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:57,276 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:58,093 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:58,095 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:58,769 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:58,775 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:59,091 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:59,092 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:00,681 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:00,683 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:00,973 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:00,974 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:01,631 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:01,633 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:01,646 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:01,649 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:04,407 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:04,413 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:08,461 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,463 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,465 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,465 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,467 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,467 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,468 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,468 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,469 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,469 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,467 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,470 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,471 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,470 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,472 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,473 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,473 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,475 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,475 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,476 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,476 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,477 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,479 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,479 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,479 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,481 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,480 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,480 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,481 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,483 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,483 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,483 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,483 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,483 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,483 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,484 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,484 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,485 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,485 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,485 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,486 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,485 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,486 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,486 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,486 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,487 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,485 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,487 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,487 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,487 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,488 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,488 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,488 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,489 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,489 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,489 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,490 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,490 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,490 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,490 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,490 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,490 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,490 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,490 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,490 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,492 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,490 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,491 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,491 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,490 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,492 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,492 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,492 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,492 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,493 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,493 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,493 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,492 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,492 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,493 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,493 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,493 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,493 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,493 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,493 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,493 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,493 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,493 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,493 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,494 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,494 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,494 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,492 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,492 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,494 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,492 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,495 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,494 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,494 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,494 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,495 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,492 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,495 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,493 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,495 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,494 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,495 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,495 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,495 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,495 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,495 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,495 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,495 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,496 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,496 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,496 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,496 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,496 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,496 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,496 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,497 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,494 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,497 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,496 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,496 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,496 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,497 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,497 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,497 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,497 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,497 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,496 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,497 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,497 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,497 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,497 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,497 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,497 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,496 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,497 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,498 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,497 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,498 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,498 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,498 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,498 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,498 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,498 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,498 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,498 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,498 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,499 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,498 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,498 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,499 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,499 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,497 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,500 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,500 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,500 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,500 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,500 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,498 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,500 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,500 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,500 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,500 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,501 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,501 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,501 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,501 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,501 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,501 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,501 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,501 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,501 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,502 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,502 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,500 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,502 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,502 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,500 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,503 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,500 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:08,502 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,505 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,505 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:08,506 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,341 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,344 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,367 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,372 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,878 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,881 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,897 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,899 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,519 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,524 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,602 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,608 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,619 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,621 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,641 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,646 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,180 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,185 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,854 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,856 - distributed.utils - INFO - Reload module qme_vars from .py file
