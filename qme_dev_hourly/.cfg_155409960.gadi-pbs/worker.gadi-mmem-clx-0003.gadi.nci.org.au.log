Loading singularity
Loading conda/analysis3-25.06

Loading gadi_jupyterlab/23.02
  Module ERROR: invalid command name "::tclPkgUnknown"
    In '/g/data/dk92/apps/Modules/modulefiles/gadi_jupyterlab/23.02'
    Please contact <root@localhost>
2025-11-26 15:24:15,721 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:42795'
2025-11-26 15:24:15,727 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:34075'
2025-11-26 15:24:15,731 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:34901'
2025-11-26 15:24:15,736 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:44007'
2025-11-26 15:24:15,740 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:44781'
2025-11-26 15:24:15,745 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:41893'
2025-11-26 15:24:15,752 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:38775'
2025-11-26 15:24:15,755 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:40099'
2025-11-26 15:24:15,760 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:42071'
2025-11-26 15:24:15,765 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:40487'
2025-11-26 15:24:15,769 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:36403'
2025-11-26 15:24:15,774 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:44865'
2025-11-26 15:24:15,778 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:32901'
2025-11-26 15:24:15,782 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:35631'
2025-11-26 15:24:15,786 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:41115'
2025-11-26 15:24:15,789 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:33045'
2025-11-26 15:24:15,793 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:44235'
2025-11-26 15:24:15,797 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:37831'
2025-11-26 15:24:15,803 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:42277'
2025-11-26 15:24:15,806 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:38217'
2025-11-26 15:24:15,811 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:36405'
2025-11-26 15:24:15,960 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:41193'
2025-11-26 15:24:15,964 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:35905'
2025-11-26 15:24:15,969 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:38235'
2025-11-26 15:24:15,973 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:38371'
2025-11-26 15:24:15,977 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:34989'
2025-11-26 15:24:15,982 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:36113'
2025-11-26 15:24:15,986 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:46665'
2025-11-26 15:24:15,990 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:39081'
2025-11-26 15:24:15,994 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:44087'
2025-11-26 15:24:15,999 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:42901'
2025-11-26 15:24:16,003 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:33961'
2025-11-26 15:24:16,007 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:39599'
2025-11-26 15:24:16,012 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:40313'
2025-11-26 15:24:16,017 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:42853'
2025-11-26 15:24:16,022 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:43369'
2025-11-26 15:24:16,025 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:34113'
2025-11-26 15:24:16,030 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:39859'
2025-11-26 15:24:16,033 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:39089'
2025-11-26 15:24:16,038 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:40717'
2025-11-26 15:24:16,042 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:42699'
2025-11-26 15:24:16,047 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:43285'
2025-11-26 15:24:16,052 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:44361'
2025-11-26 15:24:16,058 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:35533'
2025-11-26 15:24:16,063 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:39447'
2025-11-26 15:24:16,068 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:43299'
2025-11-26 15:24:16,072 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:43419'
2025-11-26 15:24:16,075 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.30:40401'
2025-11-26 15:24:17,180 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:37887
2025-11-26 15:24:17,180 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:34165
2025-11-26 15:24:17,180 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:33675
2025-11-26 15:24:17,180 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:37887
2025-11-26 15:24:17,180 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:37061
2025-11-26 15:24:17,180 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:34165
2025-11-26 15:24:17,180 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:33675
2025-11-26 15:24:17,180 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:46807
2025-11-26 15:24:17,180 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:44005
2025-11-26 15:24:17,180 - distributed.worker - INFO -          dashboard at:            10.6.5.30:33291
2025-11-26 15:24:17,180 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:43265
2025-11-26 15:24:17,180 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:44791
2025-11-26 15:24:17,180 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:37061
2025-11-26 15:24:17,180 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:37845
2025-11-26 15:24:17,180 - distributed.worker - INFO -          dashboard at:            10.6.5.30:40051
2025-11-26 15:24:17,180 - distributed.worker - INFO -          dashboard at:            10.6.5.30:41609
2025-11-26 15:24:17,180 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:46807
2025-11-26 15:24:17,180 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,180 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:44005
2025-11-26 15:24:17,180 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:43265
2025-11-26 15:24:17,180 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:37883
2025-11-26 15:24:17,180 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:44791
2025-11-26 15:24:17,180 - distributed.worker - INFO -          dashboard at:            10.6.5.30:35567
2025-11-26 15:24:17,180 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,180 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:37845
2025-11-26 15:24:17,180 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,180 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,180 - distributed.worker - INFO -          dashboard at:            10.6.5.30:42721
2025-11-26 15:24:17,180 - distributed.worker - INFO -          dashboard at:            10.6.5.30:44113
2025-11-26 15:24:17,180 - distributed.worker - INFO -          dashboard at:            10.6.5.30:35619
2025-11-26 15:24:17,180 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:37883
2025-11-26 15:24:17,180 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,180 - distributed.worker - INFO -          dashboard at:            10.6.5.30:46591
2025-11-26 15:24:17,180 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,180 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,180 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,180 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,180 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,180 - distributed.worker - INFO -          dashboard at:            10.6.5.30:38029
2025-11-26 15:24:17,180 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,180 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,180 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:39115
2025-11-26 15:24:17,180 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,180 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,180 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,180 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,180 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:40455
2025-11-26 15:24:17,180 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,180 - distributed.worker - INFO -          dashboard at:            10.6.5.30:41963
2025-11-26 15:24:17,180 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-i9oaaeou
2025-11-26 15:24:17,180 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,180 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,180 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,180 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:39115
2025-11-26 15:24:17,180 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,180 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,180 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-2eh6rtyi
2025-11-26 15:24:17,180 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,180 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,180 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:40455
2025-11-26 15:24:17,181 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,181 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,181 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,181 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,181 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,181 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,181 - distributed.worker - INFO -          dashboard at:            10.6.5.30:39215
2025-11-26 15:24:17,181 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,181 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,181 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,181 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,181 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,181 - distributed.worker - INFO -          dashboard at:            10.6.5.30:42773
2025-11-26 15:24:17,181 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-qk62ptgl
2025-11-26 15:24:17,181 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-4nyzay9z
2025-11-26 15:24:17,181 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,181 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,181 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,181 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-fp_bakvo
2025-11-26 15:24:17,181 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,181 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,181 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,181 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,181 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,181 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,181 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,181 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,181 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-sglt6enf
2025-11-26 15:24:17,181 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,181 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,181 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,181 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-vs6toys_
2025-11-26 15:24:17,181 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-8bk3gd5r
2025-11-26 15:24:17,181 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,181 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-_48a_ml4
2025-11-26 15:24:17,181 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,181 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,181 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-wt1inv59
2025-11-26 15:24:17,181 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,181 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,181 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,181 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,181 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,181 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,181 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-1thoq669
2025-11-26 15:24:17,181 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-xbnhq8nc
2025-11-26 15:24:17,181 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,181 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,182 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:36361
2025-11-26 15:24:17,182 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:36361
2025-11-26 15:24:17,182 - distributed.worker - INFO -          dashboard at:            10.6.5.30:45965
2025-11-26 15:24:17,182 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,182 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,182 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,182 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,182 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-5i0gkxzu
2025-11-26 15:24:17,183 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,183 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:35201
2025-11-26 15:24:17,184 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:35201
2025-11-26 15:24:17,184 - distributed.worker - INFO -          dashboard at:            10.6.5.30:36141
2025-11-26 15:24:17,184 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,184 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,184 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,184 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,184 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-cockp_l9
2025-11-26 15:24:17,184 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,186 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:36747
2025-11-26 15:24:17,186 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:36747
2025-11-26 15:24:17,186 - distributed.worker - INFO -          dashboard at:            10.6.5.30:40461
2025-11-26 15:24:17,186 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,186 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,186 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,186 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,186 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-c3jaxqtf
2025-11-26 15:24:17,187 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,187 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:37011
2025-11-26 15:24:17,187 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:37011
2025-11-26 15:24:17,187 - distributed.worker - INFO -          dashboard at:            10.6.5.30:35041
2025-11-26 15:24:17,188 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,188 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,188 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,188 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,188 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-sw25tf1k
2025-11-26 15:24:17,188 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,194 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,194 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,194 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,195 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,195 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,195 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,195 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,196 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,196 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,197 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,197 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,197 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,198 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,198 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,198 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,199 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,199 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,199 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,199 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,200 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,200 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,200 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,200 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,201 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,201 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,201 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,201 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,202 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,202 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,202 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,203 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,203 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,203 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,204 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,204 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,205 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,205 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,205 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,205 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,206 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,206 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,206 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,206 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,206 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,207 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,207 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,207 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,207 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,208 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,208 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,208 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,208 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,208 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,209 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,209 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,209 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,209 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,210 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,210 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,210 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,210 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,210 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,211 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,211 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,219 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:46141
2025-11-26 15:24:17,220 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:46141
2025-11-26 15:24:17,220 - distributed.worker - INFO -          dashboard at:            10.6.5.30:35643
2025-11-26 15:24:17,220 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,220 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,220 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,220 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,220 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-uauxcgrv
2025-11-26 15:24:17,220 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,220 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:39865
2025-11-26 15:24:17,220 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:39865
2025-11-26 15:24:17,220 - distributed.worker - INFO -          dashboard at:            10.6.5.30:44523
2025-11-26 15:24:17,220 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,220 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,220 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,220 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,220 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-xobxdai_
2025-11-26 15:24:17,221 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,230 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,231 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,231 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,232 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,237 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,238 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,238 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,239 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,262 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:44349
2025-11-26 15:24:17,262 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:44349
2025-11-26 15:24:17,262 - distributed.worker - INFO -          dashboard at:            10.6.5.30:40793
2025-11-26 15:24:17,262 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,262 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,262 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,262 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,262 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-11t4t_z4
2025-11-26 15:24:17,262 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,283 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,284 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,284 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,285 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,419 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:37803
2025-11-26 15:24:17,420 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:37803
2025-11-26 15:24:17,420 - distributed.worker - INFO -          dashboard at:            10.6.5.30:40551
2025-11-26 15:24:17,420 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,420 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,420 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,420 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,420 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-86r3xc_1
2025-11-26 15:24:17,420 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,440 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,441 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,441 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,443 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,494 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:36507
2025-11-26 15:24:17,494 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:36507
2025-11-26 15:24:17,494 - distributed.worker - INFO -          dashboard at:            10.6.5.30:40071
2025-11-26 15:24:17,494 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,494 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,494 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,495 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,495 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-nyqjsk8x
2025-11-26 15:24:17,495 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,501 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:43987
2025-11-26 15:24:17,501 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:43987
2025-11-26 15:24:17,501 - distributed.worker - INFO -          dashboard at:            10.6.5.30:44903
2025-11-26 15:24:17,501 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,501 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,502 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,502 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,502 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-wnprtiir
2025-11-26 15:24:17,502 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,505 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:45245
2025-11-26 15:24:17,505 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:45245
2025-11-26 15:24:17,505 - distributed.worker - INFO -          dashboard at:            10.6.5.30:45563
2025-11-26 15:24:17,506 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,506 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,506 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,506 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,506 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-a4ui1wp1
2025-11-26 15:24:17,506 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,513 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,513 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,513 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,514 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,516 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,517 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,517 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,518 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,525 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,526 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,526 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:41123
2025-11-26 15:24:17,526 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:40151
2025-11-26 15:24:17,526 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:41123
2025-11-26 15:24:17,526 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,526 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:40151
2025-11-26 15:24:17,526 - distributed.worker - INFO -          dashboard at:            10.6.5.30:36715
2025-11-26 15:24:17,526 - distributed.worker - INFO -          dashboard at:            10.6.5.30:38487
2025-11-26 15:24:17,526 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,526 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,526 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,526 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,526 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,526 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,526 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,526 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,526 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-gx_5gj3h
2025-11-26 15:24:17,526 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-4f7x6s9d
2025-11-26 15:24:17,526 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,526 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,527 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,529 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:42869
2025-11-26 15:24:17,530 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:42869
2025-11-26 15:24:17,530 - distributed.worker - INFO -          dashboard at:            10.6.5.30:45267
2025-11-26 15:24:17,530 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,530 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,530 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,530 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,530 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-0sa9g9l7
2025-11-26 15:24:17,530 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,530 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:39365
2025-11-26 15:24:17,530 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:39365
2025-11-26 15:24:17,531 - distributed.worker - INFO -          dashboard at:            10.6.5.30:37059
2025-11-26 15:24:17,531 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,531 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,531 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,531 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,531 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-dwcsv9e6
2025-11-26 15:24:17,531 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,535 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:39231
2025-11-26 15:24:17,535 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:39231
2025-11-26 15:24:17,535 - distributed.worker - INFO -          dashboard at:            10.6.5.30:40259
2025-11-26 15:24:17,536 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,536 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,536 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,536 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,536 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-b3f39_g4
2025-11-26 15:24:17,536 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,536 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:43217
2025-11-26 15:24:17,536 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:43217
2025-11-26 15:24:17,537 - distributed.worker - INFO -          dashboard at:            10.6.5.30:39593
2025-11-26 15:24:17,537 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,537 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,537 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,537 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,537 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-cpogyyw3
2025-11-26 15:24:17,537 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,542 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,543 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,543 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,544 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,545 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,545 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,545 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,546 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,547 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,548 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,548 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,549 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,549 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,549 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,549 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,550 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,552 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,553 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,553 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,555 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,556 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,557 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,557 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,558 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:45453
2025-11-26 15:24:17,558 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:45453
2025-11-26 15:24:17,558 - distributed.worker - INFO -          dashboard at:            10.6.5.30:40969
2025-11-26 15:24:17,558 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,558 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,558 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,558 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,558 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-7ms9ovf3
2025-11-26 15:24:17,558 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,558 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,565 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:44733
2025-11-26 15:24:17,565 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:44733
2025-11-26 15:24:17,565 - distributed.worker - INFO -          dashboard at:            10.6.5.30:46257
2025-11-26 15:24:17,565 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,565 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,565 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,565 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,565 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-l5j7wuv9
2025-11-26 15:24:17,565 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,571 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:37377
2025-11-26 15:24:17,571 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:37377
2025-11-26 15:24:17,571 - distributed.worker - INFO -          dashboard at:            10.6.5.30:45921
2025-11-26 15:24:17,571 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,571 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,571 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,571 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,571 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-9ckwes2j
2025-11-26 15:24:17,572 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,572 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:46475
2025-11-26 15:24:17,572 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:46475
2025-11-26 15:24:17,572 - distributed.worker - INFO -          dashboard at:            10.6.5.30:32919
2025-11-26 15:24:17,572 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,572 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,572 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,572 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,572 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-gs4q5bsl
2025-11-26 15:24:17,572 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,575 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:36535
2025-11-26 15:24:17,575 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:36535
2025-11-26 15:24:17,575 - distributed.worker - INFO -          dashboard at:            10.6.5.30:45079
2025-11-26 15:24:17,575 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,575 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,575 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,575 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,575 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-lavcj7jw
2025-11-26 15:24:17,575 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,577 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,577 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,577 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,578 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,579 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,579 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,579 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,579 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,581 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:43319
2025-11-26 15:24:17,581 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:43319
2025-11-26 15:24:17,581 - distributed.worker - INFO -          dashboard at:            10.6.5.30:36371
2025-11-26 15:24:17,581 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,581 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,581 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,582 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,582 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-jmpie69e
2025-11-26 15:24:17,582 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,589 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,590 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,590 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,590 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,592 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,592 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,593 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,593 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,594 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,594 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,594 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,596 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,601 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,602 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,602 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,602 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:36145
2025-11-26 15:24:17,602 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:36145
2025-11-26 15:24:17,603 - distributed.worker - INFO -          dashboard at:            10.6.5.30:38355
2025-11-26 15:24:17,603 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,603 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,603 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,603 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,603 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-bwhwx9ni
2025-11-26 15:24:17,603 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,603 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,613 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:46625
2025-11-26 15:24:17,613 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:46625
2025-11-26 15:24:17,613 - distributed.worker - INFO -          dashboard at:            10.6.5.30:34319
2025-11-26 15:24:17,613 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,613 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,613 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,613 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,613 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-0hs6001j
2025-11-26 15:24:17,613 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,619 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,620 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,620 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,621 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,624 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:35917
2025-11-26 15:24:17,624 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:35917
2025-11-26 15:24:17,624 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:34935
2025-11-26 15:24:17,624 - distributed.worker - INFO -          dashboard at:            10.6.5.30:36039
2025-11-26 15:24:17,624 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:34935
2025-11-26 15:24:17,624 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,624 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,624 - distributed.worker - INFO -          dashboard at:            10.6.5.30:45041
2025-11-26 15:24:17,624 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,624 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,624 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,624 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,624 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:33333
2025-11-26 15:24:17,624 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,624 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-hs0tbpgg
2025-11-26 15:24:17,624 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,624 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:33333
2025-11-26 15:24:17,624 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,624 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-f23cc_8j
2025-11-26 15:24:17,624 - distributed.worker - INFO -          dashboard at:            10.6.5.30:44371
2025-11-26 15:24:17,624 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,624 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,624 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,624 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,624 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,624 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-u473c9xj
2025-11-26 15:24:17,624 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,625 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:41633
2025-11-26 15:24:17,625 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:41633
2025-11-26 15:24:17,625 - distributed.worker - INFO -          dashboard at:            10.6.5.30:46355
2025-11-26 15:24:17,625 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,625 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,625 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,625 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,625 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-fl0bvym7
2025-11-26 15:24:17,625 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,625 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:36545
2025-11-26 15:24:17,625 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:36545
2025-11-26 15:24:17,625 - distributed.worker - INFO -          dashboard at:            10.6.5.30:37381
2025-11-26 15:24:17,626 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,626 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,626 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,626 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,626 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-1tl64yrg
2025-11-26 15:24:17,626 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,626 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:43945
2025-11-26 15:24:17,626 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:43945
2025-11-26 15:24:17,626 - distributed.worker - INFO -          dashboard at:            10.6.5.30:39585
2025-11-26 15:24:17,627 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,627 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,627 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,627 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,627 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-1s_aatem
2025-11-26 15:24:17,627 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,628 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:38321
2025-11-26 15:24:17,628 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:38321
2025-11-26 15:24:17,628 - distributed.worker - INFO -          dashboard at:            10.6.5.30:43223
2025-11-26 15:24:17,628 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,628 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,628 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,628 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,628 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-yhqydw9m
2025-11-26 15:24:17,628 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,629 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:39971
2025-11-26 15:24:17,629 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:39971
2025-11-26 15:24:17,629 - distributed.worker - INFO -          dashboard at:            10.6.5.30:45459
2025-11-26 15:24:17,629 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,629 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,629 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,629 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,629 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-61yng8ii
2025-11-26 15:24:17,629 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,633 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,634 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,634 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,635 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,637 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,638 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,638 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,638 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:38001
2025-11-26 15:24:17,638 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:38001
2025-11-26 15:24:17,638 - distributed.worker - INFO -          dashboard at:            10.6.5.30:33747
2025-11-26 15:24:17,638 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,638 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,638 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,638 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,638 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-zpgumcvl
2025-11-26 15:24:17,638 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,638 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,640 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,640 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,640 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,641 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,642 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,642 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,642 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,643 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,645 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,645 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,646 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,646 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,647 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,647 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,647 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,648 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:41461
2025-11-26 15:24:17,648 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:41461
2025-11-26 15:24:17,648 - distributed.worker - INFO -          dashboard at:            10.6.5.30:39385
2025-11-26 15:24:17,648 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,648 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,648 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,648 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,648 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,648 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-vc6nwys0
2025-11-26 15:24:17,648 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,649 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,649 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,649 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,650 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,650 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,651 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,651 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,651 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,652 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,652 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,652 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,653 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,659 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,660 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,660 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,660 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,661 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,661 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,661 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,661 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.30:33965
2025-11-26 15:24:17,662 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.30:33965
2025-11-26 15:24:17,662 - distributed.worker - INFO -          dashboard at:            10.6.5.30:39109
2025-11-26 15:24:17,662 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:17,662 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,662 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,662 - distributed.worker - INFO -               Threads:                          1
2025-11-26 15:24:17,662 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-11-26 15:24:17,662 - distributed.worker - INFO -       Local Directory: /jobfs/155409960.gadi-pbs/dask-scratch-space/worker-gi1iuro3
2025-11-26 15:24:17,662 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,680 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-11-26 15:24:17,680 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.29:8754
2025-11-26 15:24:17,680 - distributed.worker - INFO - -------------------------------------------------
2025-11-26 15:24:17,681 - distributed.core - INFO - Starting established connection to tcp://10.6.5.29:8754
2025-11-26 15:24:23,243 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,244 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,244 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,244 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,244 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,244 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,245 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,245 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,245 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,245 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,245 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,245 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,245 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,245 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,245 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,245 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,246 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,246 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,246 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,246 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,246 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,246 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,246 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,246 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,247 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,247 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,247 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,247 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,247 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,247 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,247 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,247 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,247 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,247 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,247 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,248 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,248 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,248 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,248 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,248 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,248 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,248 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,247 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,249 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,249 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,249 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,249 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,249 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,249 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,249 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,249 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,249 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,249 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,249 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,249 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,249 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,250 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,250 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,250 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,250 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,250 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,250 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,250 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,250 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,250 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,251 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,251 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,251 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,251 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,251 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,251 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,251 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,251 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,252 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,252 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,252 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,252 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,252 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,252 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,252 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,252 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,252 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,252 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,252 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,253 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,253 - distributed.worker - INFO - Starting Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-26 15:24:23,253 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,253 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,253 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,253 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,253 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,253 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,253 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,253 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,254 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:23,255 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-11-26 15:24:25,635 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,635 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,635 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,635 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,636 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,636 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,636 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,636 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,637 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,637 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,637 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,638 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,637 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,637 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,638 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,638 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,638 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,638 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,638 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,638 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,638 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,638 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,638 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,638 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,638 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,638 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,638 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,639 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,639 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,639 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,639 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,639 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,640 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,639 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,640 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,639 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,639 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,640 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,640 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,640 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,640 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,640 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,641 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,640 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,640 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,641 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,641 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,641 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,641 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,641 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,641 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,641 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,642 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,641 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,642 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,642 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,642 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,642 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,642 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,642 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,642 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,643 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,642 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,643 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,642 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,643 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,643 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,643 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,644 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,643 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,643 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,644 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,644 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,644 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,645 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,644 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,644 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,645 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,645 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,644 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,645 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,645 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,645 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,646 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,646 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,645 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,646 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,644 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,647 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,647 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,644 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,648 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,648 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,648 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,646 - distributed.worker - INFO - Starting Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-26 15:24:25,654 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-11-26 15:24:25,765 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,766 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,767 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,767 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,767 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,768 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,768 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,769 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,769 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,769 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,770 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,770 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,770 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,770 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,770 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,771 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,771 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,771 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,771 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,772 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,772 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,772 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,772 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,773 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,773 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,773 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,773 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,774 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,774 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,774 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,774 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,774 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,774 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,774 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,775 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,775 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,775 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,775 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,775 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,776 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,776 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,776 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,776 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,776 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,777 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,777 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,777 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,777 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,777 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,777 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,778 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,778 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,778 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,778 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,779 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,779 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,779 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,779 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,779 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,779 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,779 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,779 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,779 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,780 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,780 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,780 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,780 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,781 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,781 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,781 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,781 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,781 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,781 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,781 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,781 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,782 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,782 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,782 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,782 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,782 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,783 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,783 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,783 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,783 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,783 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,783 - distributed.worker - INFO - Starting Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-26 15:24:25,784 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,784 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,784 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,784 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,785 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,785 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,785 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,785 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,785 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,785 - distributed.utils - INFO - Reload module qme_train from .py file
2025-11-26 15:24:25,866 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,866 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,866 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,866 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,866 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,867 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,867 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,867 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,867 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,867 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,867 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,867 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,867 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,867 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,867 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,868 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,868 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,868 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,868 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,868 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,868 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,868 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,868 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,868 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,869 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,869 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,869 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,869 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,869 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,869 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,869 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,869 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,869 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,869 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,870 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,870 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,870 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,870 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,870 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,870 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,870 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,870 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,870 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,870 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,870 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,871 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,871 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,871 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,871 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,871 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,871 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,871 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,871 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,871 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,872 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,872 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,872 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,872 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,872 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,872 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,872 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,872 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,872 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,872 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,872 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,873 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,873 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,873 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,873 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,873 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,873 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,873 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,873 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,873 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,873 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,873 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,874 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,874 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,874 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,874 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,874 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,874 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,874 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,874 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,874 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,874 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,874 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,875 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,875 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,875 - distributed.worker - INFO - Starting Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-26 15:24:25,875 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,875 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,875 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,875 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,876 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:24:25,876 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-11-26 15:27:15,449 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:15,449 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:15,449 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:15,450 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:15,451 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:15,451 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:15,451 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:15,451 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:15,452 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:15,452 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:15,453 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:15,453 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:15,453 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:15,454 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:15,454 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:15,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:15,456 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:15,459 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:15,459 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:15,463 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:27:26,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 76.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:29:13,114 - distributed.core - INFO - Event loop was unresponsive in Worker for 112.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:29:13,279 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:29:13,283 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:29:13,284 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:29:13,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 74.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:29:15,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 98.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:29:15,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 94.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:29:15,561 - distributed.core - INFO - Event loop was unresponsive in Worker for 84.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:29:24,303 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:29:24,321 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:29:24,335 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:29:24,337 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:29:24,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,599 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,600 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,600 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,600 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,601 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,601 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,605 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,607 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,607 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,607 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,609 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,609 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,610 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,611 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,611 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,613 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,617 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:04,617 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:17,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:17,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:17,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:17,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:17,754 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:17,755 - distributed.core - INFO - Event loop was unresponsive in Worker for 38.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:17,757 - distributed.core - INFO - Event loop was unresponsive in Worker for 38.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:36,502 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:36,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:36,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:54,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:54,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:54,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:58,171 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:58,171 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:58,174 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:58,174 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:58,174 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:58,174 - distributed.core - INFO - Event loop was unresponsive in Worker for 47.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:58,175 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:58,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:58,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:58,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 47.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:58,285 - distributed.core - INFO - Event loop was unresponsive in Worker for 47.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:58,285 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:58,286 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:58,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 49.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:58,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:58,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:58,299 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:30:58,305 - distributed.core - INFO - Event loop was unresponsive in Worker for 49.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:04,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:04,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:35,122 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:35,122 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:35,122 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:35,123 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:35,125 - distributed.core - INFO - Event loop was unresponsive in Worker for 30.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 35.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 35.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 35.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,865 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 35.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 35.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 35.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,886 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,889 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,890 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,890 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,900 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:31:41,951 - distributed.core - INFO - Event loop was unresponsive in Worker for 35.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:32:52,390 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:32:52,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:32:52,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:32:52,400 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:32:52,408 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:32:52,573 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:32:52,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:32:52,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:09,162 - distributed.core - INFO - Event loop was unresponsive in Worker for 98.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:09,163 - distributed.core - INFO - Event loop was unresponsive in Worker for 98.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:09,163 - distributed.core - INFO - Event loop was unresponsive in Worker for 98.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:09,163 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:09,163 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:09,163 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:09,163 - distributed.core - INFO - Event loop was unresponsive in Worker for 98.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:09,164 - distributed.core - INFO - Event loop was unresponsive in Worker for 98.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:09,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:09,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 98.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:09,166 - distributed.core - INFO - Event loop was unresponsive in Worker for 98.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:09,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:09,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 98.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:09,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:09,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:09,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 98.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:09,248 - distributed.core - INFO - Event loop was unresponsive in Worker for 98.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:09,250 - distributed.core - INFO - Event loop was unresponsive in Worker for 98.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:09,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 98.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:34:26,547 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:33,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 42.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:33,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 42.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:33,281 - distributed.core - INFO - Event loop was unresponsive in Worker for 42.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:33,282 - distributed.core - INFO - Event loop was unresponsive in Worker for 42.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:33,283 - distributed.core - INFO - Event loop was unresponsive in Worker for 42.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:33,283 - distributed.core - INFO - Event loop was unresponsive in Worker for 42.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:33,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 42.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:33,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 42.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:33,334 - distributed.core - INFO - Event loop was unresponsive in Worker for 42.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:33,337 - distributed.core - INFO - Event loop was unresponsive in Worker for 42.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:47,867 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:47,867 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:47,867 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:47,868 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:47,868 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:47,868 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:47,868 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:47,868 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:47,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,463 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,463 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,464 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,464 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,464 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,464 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,464 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,465 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,465 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,465 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,467 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,470 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,469 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,470 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,473 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,474 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:35:48,476 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,230 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,232 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,264 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,264 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,265 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,265 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,265 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,265 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,266 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,266 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,266 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,267 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,272 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,272 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,272 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,273 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,274 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,281 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,282 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,283 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,282 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,285 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:36:32,296 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:09,836 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:09,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,523 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,524 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,571 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,571 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,572 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,572 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,572 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,574 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,575 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,574 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,578 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,578 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,661 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,662 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,662 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,662 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,662 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,663 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,663 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,663 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,663 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,663 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,664 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,665 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,665 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,668 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 71.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:37:58,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:38:33,214 - distributed.core - INFO - Event loop was unresponsive in Worker for 46.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:38:33,215 - distributed.core - INFO - Event loop was unresponsive in Worker for 46.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:38:33,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 46.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:38:33,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 46.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:38:33,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 46.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:38:33,217 - distributed.core - INFO - Event loop was unresponsive in Worker for 46.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:38:33,218 - distributed.core - INFO - Event loop was unresponsive in Worker for 46.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:38:33,224 - distributed.core - INFO - Event loop was unresponsive in Worker for 46.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:07,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 81.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:07,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 84.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:07,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 81.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:07,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 84.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:07,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 84.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:07,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 84.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:07,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 81.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:07,672 - distributed.core - INFO - Event loop was unresponsive in Worker for 84.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:07,672 - distributed.core - INFO - Event loop was unresponsive in Worker for 84.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:07,674 - distributed.core - INFO - Event loop was unresponsive in Worker for 84.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,740 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,741 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,742 - distributed.core - INFO - Event loop was unresponsive in Worker for 86.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,742 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,743 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,743 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,746 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,748 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,755 - distributed.core - INFO - Event loop was unresponsive in Worker for 86.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,841 - distributed.core - INFO - Event loop was unresponsive in Worker for 86.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,866 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,868 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,871 - distributed.core - INFO - Event loop was unresponsive in Worker for 86.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,872 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:12,875 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:40:21,087 - distributed.core - INFO - Event loop was unresponsive in Worker for 94.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:41:33,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 72.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:42:22,420 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:42:22,424 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:42:22,425 - distributed.core - INFO - Event loop was unresponsive in Worker for 85.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:42:22,433 - distributed.core - INFO - Event loop was unresponsive in Worker for 81.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:42:22,437 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:35,888 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:35,888 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:56,638 - distributed.core - INFO - Event loop was unresponsive in Worker for 117.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:56,639 - distributed.core - INFO - Event loop was unresponsive in Worker for 117.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:56,639 - distributed.core - INFO - Event loop was unresponsive in Worker for 117.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:56,639 - distributed.core - INFO - Event loop was unresponsive in Worker for 117.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:56,640 - distributed.core - INFO - Event loop was unresponsive in Worker for 117.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:56,640 - distributed.core - INFO - Event loop was unresponsive in Worker for 117.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:56,640 - distributed.core - INFO - Event loop was unresponsive in Worker for 117.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:56,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 117.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:56,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 117.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:56,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 117.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:56,642 - distributed.core - INFO - Event loop was unresponsive in Worker for 117.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:56,643 - distributed.core - INFO - Event loop was unresponsive in Worker for 117.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:56,643 - distributed.core - INFO - Event loop was unresponsive in Worker for 117.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:58,251 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:58,252 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:58,252 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:58,252 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:58,253 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:58,253 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:58,253 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:58,253 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:58,253 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:58,255 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:44:58,258 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:45:03,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:45:03,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:45:03,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:45:03,617 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:45:03,617 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:45:03,617 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:45:03,618 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:45:03,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:45:03,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:45:03,621 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:19,989 - distributed.core - INFO - Event loop was unresponsive in Worker for 38.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:19,991 - distributed.core - INFO - Event loop was unresponsive in Worker for 44.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:19,991 - distributed.core - INFO - Event loop was unresponsive in Worker for 42.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:19,992 - distributed.core - INFO - Event loop was unresponsive in Worker for 44.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:19,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 44.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:19,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 44.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:19,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 44.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:19,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 44.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:19,995 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:19,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 44.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:20,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:20,125 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:20,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:20,127 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:20,127 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:20,127 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:20,133 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:20,148 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:53,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:53,033 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:46:53,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:47:08,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:47:08,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:47:10,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,733 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,733 - distributed.core - INFO - Event loop was unresponsive in Worker for 55.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,735 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,737 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,737 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,739 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,741 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,761 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,761 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,761 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,762 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,762 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,763 - distributed.core - INFO - Event loop was unresponsive in Worker for 54.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,762 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,764 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,764 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,764 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,764 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,763 - distributed.core - INFO - Event loop was unresponsive in Worker for 55.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,765 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,766 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,853 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,853 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,854 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:15,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 55.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:16,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:16,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:16,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:16,366 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:29,605 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:29,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:29,607 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:29,610 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:29,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:48:57,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:49:36,009 - distributed.core - INFO - Event loop was unresponsive in Worker for 40.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:49:36,010 - distributed.core - INFO - Event loop was unresponsive in Worker for 40.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:49:36,012 - distributed.core - INFO - Event loop was unresponsive in Worker for 40.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,747 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,748 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,750 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,750 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,751 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,751 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,751 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,751 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,751 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,751 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,754 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,754 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,755 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,756 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,756 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,761 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:50:52,764 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:31,080 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:50,033 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,323 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,323 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,325 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,327 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,328 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,328 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,328 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,328 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,330 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,748 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,748 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,750 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,750 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,751 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,751 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:52:52,757 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:53:59,708 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:53:59,710 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:53:59,710 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:53:59,710 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,401 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,401 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,403 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,403 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,406 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,406 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,409 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,408 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,409 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,409 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,409 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,411 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,409 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,414 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,418 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,420 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,424 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,427 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:54:00,437 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:07,998 - distributed.core - INFO - Event loop was unresponsive in Worker for 105.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:08,002 - distributed.core - INFO - Event loop was unresponsive in Worker for 105.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:08,004 - distributed.core - INFO - Event loop was unresponsive in Worker for 105.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:08,007 - distributed.core - INFO - Event loop was unresponsive in Worker for 105.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,956 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,957 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,957 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,958 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,958 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,960 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,960 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,960 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,972 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,972 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,976 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,976 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,978 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:42,980 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:49,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 146.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:56:49,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 146.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:00,489 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:00,491 - distributed.core - INFO - Event loop was unresponsive in Worker for 35.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:00,492 - distributed.core - INFO - Event loop was unresponsive in Worker for 35.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:00,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 33.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:00,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 33.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:00,494 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:00,494 - distributed.core - INFO - Event loop was unresponsive in Worker for 33.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:00,495 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:00,495 - distributed.core - INFO - Event loop was unresponsive in Worker for 33.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:18,183 - distributed.core - INFO - Event loop was unresponsive in Worker for 40.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:18,184 - distributed.core - INFO - Event loop was unresponsive in Worker for 40.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:18,184 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:18,185 - distributed.core - INFO - Event loop was unresponsive in Worker for 40.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:18,185 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:18,185 - distributed.core - INFO - Event loop was unresponsive in Worker for 40.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:18,186 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:18,186 - distributed.core - INFO - Event loop was unresponsive in Worker for 40.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:18,187 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:18,188 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:18,188 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,228 - distributed.core - INFO - Event loop was unresponsive in Worker for 79.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,228 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 79.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,228 - distributed.core - INFO - Event loop was unresponsive in Worker for 90.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 79.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,230 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,230 - distributed.core - INFO - Event loop was unresponsive in Worker for 79.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 90.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 90.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 79.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,234 - distributed.core - INFO - Event loop was unresponsive in Worker for 79.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,236 - distributed.core - INFO - Event loop was unresponsive in Worker for 79.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,235 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,236 - distributed.core - INFO - Event loop was unresponsive in Worker for 79.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 79.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,421 - distributed.core - INFO - Event loop was unresponsive in Worker for 79.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,421 - distributed.core - INFO - Event loop was unresponsive in Worker for 79.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,421 - distributed.core - INFO - Event loop was unresponsive in Worker for 90.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,423 - distributed.core - INFO - Event loop was unresponsive in Worker for 79.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:58:57,423 - distributed.core - INFO - Event loop was unresponsive in Worker for 90.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:59:49,427 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:59:49,427 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:59:49,428 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:59:49,430 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:59:49,430 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:59:49,431 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:59:49,433 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:59:49,434 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:59:49,436 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:59:49,436 - distributed.core - INFO - Event loop was unresponsive in Worker for 40.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 15:59:49,465 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:27,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:27,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:27,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:27,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:27,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:27,368 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:27,369 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:27,372 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:27,383 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:27,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:27,385 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:27,385 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:27,385 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:27,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:27,390 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:27,390 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:27,392 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:51,266 - distributed.core - INFO - Event loop was unresponsive in Worker for 34.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:51,266 - distributed.core - INFO - Event loop was unresponsive in Worker for 34.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:51,267 - distributed.core - INFO - Event loop was unresponsive in Worker for 34.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:51,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 34.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:51,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 34.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:51,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 34.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:51,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 34.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:51,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 34.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:51,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 34.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:51,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 34.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:51,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 34.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:51,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 34.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:51,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 34.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:51,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 34.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:51,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 34.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:51,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 34.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:00:51,295 - distributed.core - INFO - Event loop was unresponsive in Worker for 34.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:01:08,976 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:01:08,976 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:01:08,976 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:01:08,977 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:01:08,977 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:01:08,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:01:08,988 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:22,102 - distributed.core - INFO - Event loop was unresponsive in Worker for 63.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:22,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:22,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 63.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:22,104 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:22,104 - distributed.core - INFO - Event loop was unresponsive in Worker for 63.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:22,104 - distributed.core - INFO - Event loop was unresponsive in Worker for 63.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:22,105 - distributed.core - INFO - Event loop was unresponsive in Worker for 63.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:22,104 - distributed.core - INFO - Event loop was unresponsive in Worker for 63.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:22,106 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:24,750 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:24,751 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:24,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:24,756 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:24,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:24,763 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:31,875 - distributed.core - INFO - Event loop was unresponsive in Worker for 72.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:31,878 - distributed.core - INFO - Event loop was unresponsive in Worker for 72.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:31,878 - distributed.core - INFO - Event loop was unresponsive in Worker for 72.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:31,879 - distributed.core - INFO - Event loop was unresponsive in Worker for 72.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:31,880 - distributed.core - INFO - Event loop was unresponsive in Worker for 72.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:31,880 - distributed.core - INFO - Event loop was unresponsive in Worker for 63.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:31,882 - distributed.core - INFO - Event loop was unresponsive in Worker for 72.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:31,882 - distributed.core - INFO - Event loop was unresponsive in Worker for 72.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:31,881 - distributed.core - INFO - Event loop was unresponsive in Worker for 72.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:31,883 - distributed.core - INFO - Event loop was unresponsive in Worker for 70.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:31,883 - distributed.core - INFO - Event loop was unresponsive in Worker for 63.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:31,884 - distributed.core - INFO - Event loop was unresponsive in Worker for 72.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:31,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 72.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:31,889 - distributed.core - INFO - Event loop was unresponsive in Worker for 72.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:31,888 - distributed.core - INFO - Event loop was unresponsive in Worker for 63.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:31,897 - distributed.core - INFO - Event loop was unresponsive in Worker for 72.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:47,596 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:02:47,597 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:01,664 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:01,664 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:01,664 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:01,664 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:01,665 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:01,665 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:01,666 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:01,667 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:01,668 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:01,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:02,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:02,093 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:02,093 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:02,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:02,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:02,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:02,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:02,098 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:02,101 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:02,105 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:33,278 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:33,278 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:33,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:33,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:33,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:33,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:33,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:33,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:33,281 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:33,281 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:34,058 - distributed.core - INFO - Event loop was unresponsive in Worker for 97.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:34,058 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:34,059 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:34,060 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:34,062 - distributed.core - INFO - Event loop was unresponsive in Worker for 97.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:34,507 - distributed.core - INFO - Event loop was unresponsive in Worker for 97.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:34,508 - distributed.core - INFO - Event loop was unresponsive in Worker for 97.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:34,509 - distributed.core - INFO - Event loop was unresponsive in Worker for 97.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:34,509 - distributed.core - INFO - Event loop was unresponsive in Worker for 97.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:34,510 - distributed.core - INFO - Event loop was unresponsive in Worker for 97.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:34,510 - distributed.core - INFO - Event loop was unresponsive in Worker for 97.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:34,512 - distributed.core - INFO - Event loop was unresponsive in Worker for 97.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:34,515 - distributed.core - INFO - Event loop was unresponsive in Worker for 97.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:34,517 - distributed.core - INFO - Event loop was unresponsive in Worker for 97.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:34,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 97.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:34,621 - distributed.core - INFO - Event loop was unresponsive in Worker for 97.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:04:34,624 - distributed.core - INFO - Event loop was unresponsive in Worker for 97.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:14,893 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,293 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,295 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,296 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,296 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,296 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,296 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,297 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,297 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,298 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,299 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,299 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,300 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,300 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,300 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,302 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,303 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,303 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,303 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,304 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,311 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,312 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,325 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,337 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:46,423 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:53,446 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:53,449 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:53,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:06:53,714 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:24,054 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:24,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:24,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 94.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:24,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:24,058 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:24,058 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:24,060 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:24,061 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:24,061 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:24,062 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:24,063 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:24,064 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:24,065 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:24,072 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:24,073 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:25,853 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:25,854 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:25,855 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:25,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:25,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:25,862 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:26,727 - distributed.core - INFO - Event loop was unresponsive in Worker for 79.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:26,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 71.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:26,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 79.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:26,729 - distributed.core - INFO - Event loop was unresponsive in Worker for 79.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:26,731 - distributed.core - INFO - Event loop was unresponsive in Worker for 71.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:26,738 - distributed.core - INFO - Event loop was unresponsive in Worker for 79.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:08:50,297 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,678 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,678 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,678 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,679 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,680 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,681 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,681 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,681 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,681 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,682 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,682 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,682 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,684 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,684 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,684 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,685 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,689 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,700 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:12:56,726 - distributed.core - INFO - Event loop was unresponsive in Worker for 211.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:13:05,430 - distributed.core - INFO - Event loop was unresponsive in Worker for 218.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:13:05,431 - distributed.core - INFO - Event loop was unresponsive in Worker for 218.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:13:28,537 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:18,474 - distributed.core - INFO - Event loop was unresponsive in Worker for 131.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:18,475 - distributed.core - INFO - Event loop was unresponsive in Worker for 131.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:18,481 - distributed.core - INFO - Event loop was unresponsive in Worker for 137.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:18,513 - distributed.core - INFO - Event loop was unresponsive in Worker for 137.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:18,514 - distributed.core - INFO - Event loop was unresponsive in Worker for 131.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:18,514 - distributed.core - INFO - Event loop was unresponsive in Worker for 131.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:18,516 - distributed.core - INFO - Event loop was unresponsive in Worker for 131.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:18,518 - distributed.core - INFO - Event loop was unresponsive in Worker for 131.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:18,518 - distributed.core - INFO - Event loop was unresponsive in Worker for 137.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:18,525 - distributed.core - INFO - Event loop was unresponsive in Worker for 137.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:20,490 - distributed.core - INFO - Event loop was unresponsive in Worker for 118.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:20,491 - distributed.core - INFO - Event loop was unresponsive in Worker for 133.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:20,492 - distributed.core - INFO - Event loop was unresponsive in Worker for 133.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:20,492 - distributed.core - INFO - Event loop was unresponsive in Worker for 133.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:20,492 - distributed.core - INFO - Event loop was unresponsive in Worker for 133.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:20,492 - distributed.core - INFO - Event loop was unresponsive in Worker for 118.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:20,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 118.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:20,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 118.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:20,495 - distributed.core - INFO - Event loop was unresponsive in Worker for 118.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:20,496 - distributed.core - INFO - Event loop was unresponsive in Worker for 118.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:20,497 - distributed.core - INFO - Event loop was unresponsive in Worker for 118.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:20,498 - distributed.core - INFO - Event loop was unresponsive in Worker for 133.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:20,499 - distributed.core - INFO - Event loop was unresponsive in Worker for 118.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:23,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 136.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:23,371 - distributed.core - INFO - Event loop was unresponsive in Worker for 120.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:23,372 - distributed.core - INFO - Event loop was unresponsive in Worker for 136.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:23,373 - distributed.core - INFO - Event loop was unresponsive in Worker for 136.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:23,374 - distributed.core - INFO - Event loop was unresponsive in Worker for 120.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:23,374 - distributed.core - INFO - Event loop was unresponsive in Worker for 136.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:23,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 136.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:36,361 - distributed.core - INFO - Event loop was unresponsive in Worker for 133.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:36,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 133.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:36,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 133.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:15:36,366 - distributed.core - INFO - Event loop was unresponsive in Worker for 133.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:16:27,360 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:16:27,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:16:27,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:16:27,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:16:27,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:16:27,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:16:36,351 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:16:36,351 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:16:36,352 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:16:36,352 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:16:36,352 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:16:36,353 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:16:36,353 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:16:36,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:16:36,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:03,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 30.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:03,762 - distributed.core - INFO - Event loop was unresponsive in Worker for 30.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:03,761 - distributed.core - INFO - Event loop was unresponsive in Worker for 30.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:08,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 35.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:08,719 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:08,719 - distributed.core - INFO - Event loop was unresponsive in Worker for 35.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:08,720 - distributed.core - INFO - Event loop was unresponsive in Worker for 35.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:08,721 - distributed.core - INFO - Event loop was unresponsive in Worker for 35.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:08,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:08,724 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,254 - distributed.core - INFO - Event loop was unresponsive in Worker for 70.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,254 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,254 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,255 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,255 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,256 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,257 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,257 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,259 - distributed.core - INFO - Event loop was unresponsive in Worker for 70.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,261 - distributed.core - INFO - Event loop was unresponsive in Worker for 70.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 70.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,333 - distributed.core - INFO - Event loop was unresponsive in Worker for 70.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,333 - distributed.core - INFO - Event loop was unresponsive in Worker for 70.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,334 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,334 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,334 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,335 - distributed.core - INFO - Event loop was unresponsive in Worker for 70.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,336 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,338 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,339 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,863 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:17:33,863 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:18:48,640 - distributed.core - INFO - Event loop was unresponsive in Worker for 67.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:18:48,640 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:18:48,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 67.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:18:48,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 71.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:18:48,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 67.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:18:48,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 71.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:18:48,642 - distributed.core - INFO - Event loop was unresponsive in Worker for 67.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:18:48,644 - distributed.core - INFO - Event loop was unresponsive in Worker for 67.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:18:48,644 - distributed.core - INFO - Event loop was unresponsive in Worker for 67.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:18:48,649 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:55,958 - distributed.core - INFO - Event loop was unresponsive in Worker for 134.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:55,959 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:55,959 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:55,962 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:55,962 - distributed.core - INFO - Event loop was unresponsive in Worker for 134.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:55,966 - distributed.core - INFO - Event loop was unresponsive in Worker for 134.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:55,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:55,994 - distributed.core - INFO - Event loop was unresponsive in Worker for 134.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:55,995 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:55,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 134.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:56,002 - distributed.core - INFO - Event loop was unresponsive in Worker for 134.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:56,074 - distributed.core - INFO - Event loop was unresponsive in Worker for 141.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:56,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 141.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:56,104 - distributed.core - INFO - Event loop was unresponsive in Worker for 141.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:56,114 - distributed.core - INFO - Event loop was unresponsive in Worker for 141.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:56,360 - distributed.core - INFO - Event loop was unresponsive in Worker for 139.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:56,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 141.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:56,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 139.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:56,368 - distributed.core - INFO - Event loop was unresponsive in Worker for 141.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:56,372 - distributed.core - INFO - Event loop was unresponsive in Worker for 141.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:56,587 - distributed.core - INFO - Event loop was unresponsive in Worker for 135.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:56,589 - distributed.core - INFO - Event loop was unresponsive in Worker for 135.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:19:56,592 - distributed.core - INFO - Event loop was unresponsive in Worker for 135.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:20:02,474 - distributed.core - INFO - Event loop was unresponsive in Worker for 141.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:20:02,474 - distributed.core - INFO - Event loop was unresponsive in Worker for 141.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:20:02,477 - distributed.core - INFO - Event loop was unresponsive in Worker for 141.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,252 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,254 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,255 - distributed.core - INFO - Event loop was unresponsive in Worker for 130.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,255 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,255 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,261 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,267 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 130.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,272 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,273 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,278 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,279 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,284 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,284 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,284 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,285 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,285 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,286 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:22:21,299 - distributed.core - INFO - Event loop was unresponsive in Worker for 138.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,398 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,399 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,399 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,399 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,400 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,400 - distributed.core - INFO - Event loop was unresponsive in Worker for 27.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,401 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,403 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,403 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,403 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,404 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,404 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,411 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,413 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,413 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,414 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,416 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,748 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:14,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:57,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:57,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:57,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:57,053 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:57,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:23:57,111 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:24:07,496 - distributed.core - INFO - Event loop was unresponsive in Worker for 47.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:24:12,831 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:24:12,837 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:12,730 - distributed.core - INFO - Event loop was unresponsive in Worker for 48.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:12,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:12,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:12,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:12,733 - distributed.core - INFO - Event loop was unresponsive in Worker for 49.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:12,733 - distributed.core - INFO - Event loop was unresponsive in Worker for 48.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:12,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:12,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 49.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:12,735 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:12,737 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:12,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 48.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:12,746 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:13,119 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:13,119 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:13,120 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:13,120 - distributed.core - INFO - Event loop was unresponsive in Worker for 48.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:13,121 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:13,122 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:13,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:13,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:13,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:13,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 48.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:13,135 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:36,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 71.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:36,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:36,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 71.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:36,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:36,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:36,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:36,247 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:36,247 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:36,249 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:48,085 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:48,085 - distributed.core - INFO - Event loop was unresponsive in Worker for 85.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:48,085 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:48,085 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:48,085 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:48,086 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:48,086 - distributed.core - INFO - Event loop was unresponsive in Worker for 85.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:48,086 - distributed.core - INFO - Event loop was unresponsive in Worker for 85.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:48,086 - distributed.core - INFO - Event loop was unresponsive in Worker for 85.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:48,089 - distributed.core - INFO - Event loop was unresponsive in Worker for 85.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:48,089 - distributed.core - INFO - Event loop was unresponsive in Worker for 85.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:48,090 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:48,093 - distributed.core - INFO - Event loop was unresponsive in Worker for 85.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:25:48,093 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:27:47,669 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:27:47,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:27:48,519 - distributed.core - INFO - Event loop was unresponsive in Worker for 94.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:27:48,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 94.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:27:48,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:27:48,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:27:48,524 - distributed.core - INFO - Event loop was unresponsive in Worker for 94.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:27:48,527 - distributed.core - INFO - Event loop was unresponsive in Worker for 94.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:27:48,533 - distributed.core - INFO - Event loop was unresponsive in Worker for 94.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,604 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,605 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,711 - distributed.core - INFO - Event loop was unresponsive in Worker for 109.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,712 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,712 - distributed.core - INFO - Event loop was unresponsive in Worker for 109.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,714 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,715 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,717 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 109.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,791 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,793 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,809 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,810 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,811 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,811 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,811 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,811 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,819 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,819 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,820 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,820 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,832 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:00,994 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:01,001 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:01,014 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:18,631 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:18,632 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:18,634 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:18,650 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:18,650 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:18,680 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:28:21,587 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,306 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,308 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,309 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,309 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,310 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,310 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,310 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,313 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,314 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,318 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,321 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,485 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,485 - distributed.core - INFO - Event loop was unresponsive in Worker for 49.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,487 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,487 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,489 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,489 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,494 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,495 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,495 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,496 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,497 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,534 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,539 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:12,542 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:47,818 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:58,227 - distributed.core - INFO - Event loop was unresponsive in Worker for 33.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:58,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 33.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:58,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 33.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:58,234 - distributed.core - INFO - Event loop was unresponsive in Worker for 33.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:58,237 - distributed.core - INFO - Event loop was unresponsive in Worker for 33.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:58,238 - distributed.core - INFO - Event loop was unresponsive in Worker for 33.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:58,239 - distributed.core - INFO - Event loop was unresponsive in Worker for 33.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:58,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 33.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:29:58,250 - distributed.core - INFO - Event loop was unresponsive in Worker for 33.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,691 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,691 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,691 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,693 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,693 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,694 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,696 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,698 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,696 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,698 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,698 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,699 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,699 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,699 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,700 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,700 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,701 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,701 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,701 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,702 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,702 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,702 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,702 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,703 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,703 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,703 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,704 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,704 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,706 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,707 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,708 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,709 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,710 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,708 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,710 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,712 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,712 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,719 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:22,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:26,413 - distributed.core - INFO - Event loop was unresponsive in Worker for 87.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:26,413 - distributed.core - INFO - Event loop was unresponsive in Worker for 87.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:26,414 - distributed.core - INFO - Event loop was unresponsive in Worker for 87.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:26,414 - distributed.core - INFO - Event loop was unresponsive in Worker for 87.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:26,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 87.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:26,420 - distributed.core - INFO - Event loop was unresponsive in Worker for 87.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:26,421 - distributed.core - INFO - Event loop was unresponsive in Worker for 87.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:31:28,149 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:50,947 - distributed.core - INFO - Event loop was unresponsive in Worker for 66.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:50,948 - distributed.core - INFO - Event loop was unresponsive in Worker for 66.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:50,948 - distributed.core - INFO - Event loop was unresponsive in Worker for 66.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:50,949 - distributed.core - INFO - Event loop was unresponsive in Worker for 66.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:50,952 - distributed.core - INFO - Event loop was unresponsive in Worker for 66.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:50,952 - distributed.core - INFO - Event loop was unresponsive in Worker for 66.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:50,957 - distributed.core - INFO - Event loop was unresponsive in Worker for 66.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:50,965 - distributed.core - INFO - Event loop was unresponsive in Worker for 66.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:50,981 - distributed.core - INFO - Event loop was unresponsive in Worker for 66.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:50,982 - distributed.core - INFO - Event loop was unresponsive in Worker for 81.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:50,983 - distributed.core - INFO - Event loop was unresponsive in Worker for 81.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:50,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 81.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:50,987 - distributed.core - INFO - Event loop was unresponsive in Worker for 81.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:50,987 - distributed.core - INFO - Event loop was unresponsive in Worker for 66.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:50,990 - distributed.core - INFO - Event loop was unresponsive in Worker for 81.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:51,042 - distributed.core - INFO - Event loop was unresponsive in Worker for 66.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:51,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 66.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:51,046 - distributed.core - INFO - Event loop was unresponsive in Worker for 66.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:53,476 - distributed.core - INFO - Event loop was unresponsive in Worker for 84.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:53,490 - distributed.core - INFO - Event loop was unresponsive in Worker for 68.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:53,494 - distributed.core - INFO - Event loop was unresponsive in Worker for 68.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:53,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 68.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:53,657 - distributed.core - INFO - Event loop was unresponsive in Worker for 68.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:53,658 - distributed.core - INFO - Event loop was unresponsive in Worker for 68.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:32:53,660 - distributed.core - INFO - Event loop was unresponsive in Worker for 68.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:04,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 112.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:04,276 - distributed.core - INFO - Event loop was unresponsive in Worker for 117.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:04,276 - distributed.core - INFO - Event loop was unresponsive in Worker for 112.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:04,282 - distributed.core - INFO - Event loop was unresponsive in Worker for 112.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:04,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 117.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:04,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 112.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:04,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 117.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:04,303 - distributed.core - INFO - Event loop was unresponsive in Worker for 112.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:06,382 - distributed.core - INFO - Event loop was unresponsive in Worker for 114.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:06,383 - distributed.core - INFO - Event loop was unresponsive in Worker for 114.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:06,383 - distributed.core - INFO - Event loop was unresponsive in Worker for 114.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:06,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 114.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:06,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 114.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:06,386 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:06,386 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:06,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 114.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:06,390 - distributed.core - INFO - Event loop was unresponsive in Worker for 114.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:06,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 114.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:06,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:16,503 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:16,505 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:16,505 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:21,337 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:21,347 - distributed.core - INFO - Event loop was unresponsive in Worker for 134.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:35:22,621 - distributed.core - INFO - Event loop was unresponsive in Worker for 131.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:36:28,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:36:28,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:36:28,974 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:36:28,977 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:36:28,982 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:36:28,984 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:36:28,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:36:28,991 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:36:28,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:36:28,994 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:37,254 - distributed.core - INFO - Event loop was unresponsive in Worker for 132.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:37,257 - distributed.core - INFO - Event loop was unresponsive in Worker for 126.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:37,258 - distributed.core - INFO - Event loop was unresponsive in Worker for 134.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:37,258 - distributed.core - INFO - Event loop was unresponsive in Worker for 152.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:37,261 - distributed.core - INFO - Event loop was unresponsive in Worker for 152.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:37,347 - distributed.core - INFO - Event loop was unresponsive in Worker for 152.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:37,348 - distributed.core - INFO - Event loop was unresponsive in Worker for 134.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:37,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 126.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:37,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 134.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:37,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 134.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:37,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 126.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:37,351 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,687 - distributed.core - INFO - Event loop was unresponsive in Worker for 158.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,687 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,688 - distributed.core - INFO - Event loop was unresponsive in Worker for 132.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,688 - distributed.core - INFO - Event loop was unresponsive in Worker for 158.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,688 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,689 - distributed.core - INFO - Event loop was unresponsive in Worker for 158.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,694 - distributed.core - INFO - Event loop was unresponsive in Worker for 132.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,719 - distributed.core - INFO - Event loop was unresponsive in Worker for 158.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,719 - distributed.core - INFO - Event loop was unresponsive in Worker for 158.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 158.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 132.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 158.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 158.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,725 - distributed.core - INFO - Event loop was unresponsive in Worker for 158.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,725 - distributed.core - INFO - Event loop was unresponsive in Worker for 158.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,726 - distributed.core - INFO - Event loop was unresponsive in Worker for 158.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,743 - distributed.core - INFO - Event loop was unresponsive in Worker for 158.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 158.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 158.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 140.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,746 - distributed.core - INFO - Event loop was unresponsive in Worker for 146.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,747 - distributed.core - INFO - Event loop was unresponsive in Worker for 158.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,747 - distributed.core - INFO - Event loop was unresponsive in Worker for 132.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:43,755 - distributed.core - INFO - Event loop was unresponsive in Worker for 158.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:45,337 - distributed.core - INFO - Event loop was unresponsive in Worker for 134.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:40:45,348 - distributed.core - INFO - Event loop was unresponsive in Worker for 142.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:00,038 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:00,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:00,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:00,107 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:53,918 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:53,919 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:53,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:53,923 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:53,924 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:53,924 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:53,924 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:53,927 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:53,940 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:58,162 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:58,163 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:58,164 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:58,181 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:59,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:59,419 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:59,423 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:41:59,423 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:43:05,567 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:43:06,320 - distributed.core - INFO - Event loop was unresponsive in Worker for 71.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:43:06,321 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:43:06,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:43:06,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 71.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:43:06,325 - distributed.core - INFO - Event loop was unresponsive in Worker for 71.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:43:06,326 - distributed.core - INFO - Event loop was unresponsive in Worker for 71.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:43:06,328 - distributed.core - INFO - Event loop was unresponsive in Worker for 71.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:43:06,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 71.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:43:06,330 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:43:12,588 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:43:12,588 - distributed.core - INFO - Event loop was unresponsive in Worker for 75.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:43:12,589 - distributed.core - INFO - Event loop was unresponsive in Worker for 75.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:43:12,590 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:43:12,590 - distributed.core - INFO - Event loop was unresponsive in Worker for 77.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:43:12,596 - distributed.core - INFO - Event loop was unresponsive in Worker for 95.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:43:22,712 - distributed.core - INFO - Event loop was unresponsive in Worker for 87.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,896 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,896 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,897 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,897 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,896 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,897 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,900 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,900 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,900 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,900 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,900 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,902 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,902 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,903 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,902 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,904 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,905 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,906 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,906 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,907 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,908 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,909 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,911 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,917 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,926 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:44:22,941 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:06,979 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:06,980 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:07,016 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:07,017 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,125 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,125 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,127 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,136 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,138 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,143 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:51,140 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:53,198 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:53,198 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:45:59,422 - distributed.core - INFO - Event loop was unresponsive in Worker for 30.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:46:03,643 - distributed.core - INFO - Event loop was unresponsive in Worker for 34.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:46:03,643 - distributed.core - INFO - Event loop was unresponsive in Worker for 38.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:46:03,644 - distributed.core - INFO - Event loop was unresponsive in Worker for 38.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:46:03,650 - distributed.core - INFO - Event loop was unresponsive in Worker for 38.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:46:03,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 44.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:48:10,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 81.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:48:10,922 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:48:10,922 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:48:10,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 81.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:48:10,927 - distributed.core - INFO - Event loop was unresponsive in Worker for 57.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:48:10,927 - distributed.core - INFO - Event loop was unresponsive in Worker for 81.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:48:56,519 - distributed.core - INFO - Event loop was unresponsive in Worker for 65.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:48:56,523 - distributed.core - INFO - Event loop was unresponsive in Worker for 127.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:48:56,528 - distributed.core - INFO - Event loop was unresponsive in Worker for 103.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:06,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 113.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:06,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 121.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:06,394 - distributed.core - INFO - Event loop was unresponsive in Worker for 121.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:06,395 - distributed.core - INFO - Event loop was unresponsive in Worker for 75.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:06,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 113.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:06,398 - distributed.core - INFO - Event loop was unresponsive in Worker for 75.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:08,340 - distributed.core - INFO - Event loop was unresponsive in Worker for 123.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:08,345 - distributed.core - INFO - Event loop was unresponsive in Worker for 123.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:08,355 - distributed.core - INFO - Event loop was unresponsive in Worker for 123.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:08,355 - distributed.core - INFO - Event loop was unresponsive in Worker for 123.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:08,356 - distributed.core - INFO - Event loop was unresponsive in Worker for 115.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:08,357 - distributed.core - INFO - Event loop was unresponsive in Worker for 123.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:08,358 - distributed.core - INFO - Event loop was unresponsive in Worker for 123.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:08,358 - distributed.core - INFO - Event loop was unresponsive in Worker for 115.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:08,358 - distributed.core - INFO - Event loop was unresponsive in Worker for 123.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:08,359 - distributed.core - INFO - Event loop was unresponsive in Worker for 115.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:08,359 - distributed.core - INFO - Event loop was unresponsive in Worker for 115.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:08,361 - distributed.core - INFO - Event loop was unresponsive in Worker for 123.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:08,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 115.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:08,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 115.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:08,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 115.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:20,359 - distributed.core - INFO - Event loop was unresponsive in Worker for 127.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:20,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 127.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:20,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 127.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:49:20,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 127.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,112 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,112 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,112 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,112 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,113 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,114 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,114 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,114 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,115 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,115 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,117 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,130 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,130 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,130 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,131 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,131 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,133 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,133 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,133 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,134 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,140 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,147 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,178 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,178 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,178 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,179 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,180 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,180 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,183 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,184 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,237 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,239 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,239 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,239 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,239 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,241 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,242 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:51:45,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:24,343 - distributed.core - INFO - Event loop was unresponsive in Worker for 39.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:24,343 - distributed.core - INFO - Event loop was unresponsive in Worker for 39.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:24,344 - distributed.core - INFO - Event loop was unresponsive in Worker for 30.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:24,345 - distributed.core - INFO - Event loop was unresponsive in Worker for 30.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:24,347 - distributed.core - INFO - Event loop was unresponsive in Worker for 30.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:24,348 - distributed.core - INFO - Event loop was unresponsive in Worker for 30.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:24,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 39.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:24,533 - distributed.core - INFO - Event loop was unresponsive in Worker for 39.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:24,534 - distributed.core - INFO - Event loop was unresponsive in Worker for 39.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:24,536 - distributed.core - INFO - Event loop was unresponsive in Worker for 39.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:24,536 - distributed.core - INFO - Event loop was unresponsive in Worker for 39.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:30,850 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:30,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:30,853 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:30,853 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:30,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:30,860 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:30,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:31,007 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:31,007 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:31,008 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:31,008 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:31,009 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:31,013 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:31,014 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:53:31,015 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:54:19,456 - distributed.core - INFO - Event loop was unresponsive in Worker for 40.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:54:19,457 - distributed.core - INFO - Event loop was unresponsive in Worker for 40.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:54:19,460 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:54:19,460 - distributed.core - INFO - Event loop was unresponsive in Worker for 38.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:54:19,459 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:54:19,460 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:54:19,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:54:19,463 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:54:36,946 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:54:46,360 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:54:46,376 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:54:46,778 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:54:47,343 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:54:47,423 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:54:47,444 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:15,273 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:15,274 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:15,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:15,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:15,278 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:15,278 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:15,278 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:15,278 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:15,278 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:15,283 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:17,498 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:17,501 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:17,502 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:17,502 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:17,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:17,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:17,506 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:17,506 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:17,506 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:17,508 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:18,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:18,232 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:18,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:18,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:18,238 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:18,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:18,241 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:18,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:18,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:18,247 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:18,248 - distributed.core - INFO - Event loop was unresponsive in Worker for 96.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:24,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 102.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:24,279 - distributed.core - INFO - Event loop was unresponsive in Worker for 68.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:24,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 99.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:24,282 - distributed.core - INFO - Event loop was unresponsive in Worker for 102.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:24,283 - distributed.core - INFO - Event loop was unresponsive in Worker for 102.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:24,286 - distributed.core - INFO - Event loop was unresponsive in Worker for 102.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:24,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 102.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:36,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 81.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:56:51,191 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 74.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 56.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,725 - distributed.core - INFO - Event loop was unresponsive in Worker for 74.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,724 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,726 - distributed.core - INFO - Event loop was unresponsive in Worker for 74.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,726 - distributed.core - INFO - Event loop was unresponsive in Worker for 74.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,727 - distributed.core - INFO - Event loop was unresponsive in Worker for 74.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,729 - distributed.core - INFO - Event loop was unresponsive in Worker for 74.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,730 - distributed.core - INFO - Event loop was unresponsive in Worker for 74.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,731 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,731 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,731 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,773 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,773 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,773 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,777 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,776 - distributed.core - INFO - Event loop was unresponsive in Worker for 74.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,778 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,780 - distributed.core - INFO - Event loop was unresponsive in Worker for 74.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,780 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:13,787 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:49,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 110.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:50,446 - distributed.core - INFO - Event loop was unresponsive in Worker for 111.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:50,447 - distributed.core - INFO - Event loop was unresponsive in Worker for 111.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:50,451 - distributed.core - INFO - Event loop was unresponsive in Worker for 111.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:50,451 - distributed.core - INFO - Event loop was unresponsive in Worker for 111.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:50,452 - distributed.core - INFO - Event loop was unresponsive in Worker for 111.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:50,456 - distributed.core - INFO - Event loop was unresponsive in Worker for 111.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 16:58:50,457 - distributed.core - INFO - Event loop was unresponsive in Worker for 111.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:01:45,691 - distributed.core - INFO - Event loop was unresponsive in Worker for 136.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:01:45,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 136.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:01:45,697 - distributed.core - INFO - Event loop was unresponsive in Worker for 136.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:01:45,805 - distributed.core - INFO - Event loop was unresponsive in Worker for 136.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:01:46,862 - distributed.core - INFO - Event loop was unresponsive in Worker for 137.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:01:46,864 - distributed.core - INFO - Event loop was unresponsive in Worker for 137.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:01:46,866 - distributed.core - INFO - Event loop was unresponsive in Worker for 137.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:02:03,024 - distributed.core - INFO - Event loop was unresponsive in Worker for 153.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:02:03,024 - distributed.core - INFO - Event loop was unresponsive in Worker for 153.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:02:03,025 - distributed.core - INFO - Event loop was unresponsive in Worker for 153.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:02:03,942 - distributed.core - INFO - Event loop was unresponsive in Worker for 154.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:02:03,944 - distributed.core - INFO - Event loop was unresponsive in Worker for 154.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:02:15,955 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:02:18,862 - distributed.core - INFO - Event loop was unresponsive in Worker for 169.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:02:48,295 - distributed.core - INFO - Event loop was unresponsive in Worker for 39.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 94.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,860 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,862 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,862 - distributed.core - INFO - Event loop was unresponsive in Worker for 94.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,864 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,866 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,866 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,867 - distributed.core - INFO - Event loop was unresponsive in Worker for 94.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 94.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 64.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,972 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:03:53,983 - distributed.core - INFO - Event loop was unresponsive in Worker for 94.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:04:27,916 - distributed.core - INFO - Event loop was unresponsive in Worker for 128.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:04:37,134 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:04:55,298 - distributed.core - INFO - Event loop was unresponsive in Worker for 61.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,039 - distributed.core - INFO - Event loop was unresponsive in Worker for 74.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,042 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,042 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,042 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,043 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,044 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,048 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,048 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,052 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,067 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,070 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:06:47,071 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:07:26,049 - distributed.core - INFO - Event loop was unresponsive in Worker for 125.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:07:26,127 - distributed.core - INFO - Event loop was unresponsive in Worker for 125.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:08:05,544 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:08:05,544 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:08:05,545 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:08:05,545 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:08:05,545 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:08:05,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:08:05,549 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:08:05,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:08:55,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 54.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:10,115 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:10,116 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:10,117 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:10,117 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:10,119 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:10,120 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:10,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:10,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 61.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:10,167 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:10,167 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:10,168 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:10,169 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:17,339 - distributed.core - INFO - Event loop was unresponsive in Worker for 66.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:17,341 - distributed.core - INFO - Event loop was unresponsive in Worker for 66.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:17,342 - distributed.core - INFO - Event loop was unresponsive in Worker for 68.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:17,341 - distributed.core - INFO - Event loop was unresponsive in Worker for 66.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:19,819 - distributed.core - INFO - Event loop was unresponsive in Worker for 70.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:19,829 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:19,832 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:19,832 - distributed.core - INFO - Event loop was unresponsive in Worker for 70.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:19,834 - distributed.core - INFO - Event loop was unresponsive in Worker for 70.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:19,839 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:19,841 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:19,844 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:19,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:19,846 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:19,848 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:19,849 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:09:19,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:11:44,390 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:11:44,392 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:11:44,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:11:44,397 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:11:44,397 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:11:44,397 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:11:44,399 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:11:44,400 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:11:44,401 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:11:44,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:11:44,414 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:12:05,715 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:12:05,717 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:12:05,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:12:05,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:12:48,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 49.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:12:48,300 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:12:48,300 - distributed.core - INFO - Event loop was unresponsive in Worker for 49.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:12:48,300 - distributed.core - INFO - Event loop was unresponsive in Worker for 49.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:12:48,303 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:12:48,302 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:12:48,315 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:12:48,318 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:12:48,328 - distributed.core - INFO - Event loop was unresponsive in Worker for 49.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:12:48,335 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,414 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,414 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,417 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,463 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,463 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,464 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,465 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,595 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,598 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,599 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,599 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,601 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,601 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,601 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,601 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,607 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,607 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,608 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,609 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,608 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,621 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,623 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:42,629 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:57,596 - distributed.core - INFO - Event loop was unresponsive in Worker for 68.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:13:58,932 - distributed.core - INFO - Event loop was unresponsive in Worker for 69.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:18:35,765 - distributed.core - INFO - Event loop was unresponsive in Worker for 84.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:18:35,767 - distributed.core - INFO - Event loop was unresponsive in Worker for 84.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:18:35,767 - distributed.core - INFO - Event loop was unresponsive in Worker for 84.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:18:35,768 - distributed.core - INFO - Event loop was unresponsive in Worker for 84.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:18:35,771 - distributed.core - INFO - Event loop was unresponsive in Worker for 84.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:18:35,772 - distributed.core - INFO - Event loop was unresponsive in Worker for 84.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:18:35,911 - distributed.core - INFO - Event loop was unresponsive in Worker for 84.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:05,697 - distributed.core - INFO - Event loop was unresponsive in Worker for 114.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:05,700 - distributed.core - INFO - Event loop was unresponsive in Worker for 114.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:05,702 - distributed.core - INFO - Event loop was unresponsive in Worker for 114.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:05,819 - distributed.core - INFO - Event loop was unresponsive in Worker for 114.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:05,820 - distributed.core - INFO - Event loop was unresponsive in Worker for 114.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:05,820 - distributed.core - INFO - Event loop was unresponsive in Worker for 114.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:05,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 114.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:05,823 - distributed.core - INFO - Event loop was unresponsive in Worker for 114.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:05,825 - distributed.core - INFO - Event loop was unresponsive in Worker for 114.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:07,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 115.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:07,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 115.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:07,178 - distributed.core - INFO - Event loop was unresponsive in Worker for 115.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:07,178 - distributed.core - INFO - Event loop was unresponsive in Worker for 115.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:07,180 - distributed.core - INFO - Event loop was unresponsive in Worker for 115.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:07,181 - distributed.core - INFO - Event loop was unresponsive in Worker for 115.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:07,183 - distributed.core - INFO - Event loop was unresponsive in Worker for 115.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:11,699 - distributed.core - INFO - Event loop was unresponsive in Worker for 120.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:11,699 - distributed.core - INFO - Event loop was unresponsive in Worker for 120.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:11,702 - distributed.core - INFO - Event loop was unresponsive in Worker for 120.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:11,703 - distributed.core - INFO - Event loop was unresponsive in Worker for 120.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:18,990 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:19:18,991 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,150 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,151 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,151 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,153 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,153 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,155 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,155 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,155 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,154 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,156 - distributed.core - INFO - Event loop was unresponsive in Worker for 112.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,156 - distributed.core - INFO - Event loop was unresponsive in Worker for 116.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,156 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,157 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,157 - distributed.core - INFO - Event loop was unresponsive in Worker for 112.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,157 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,157 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,159 - distributed.core - INFO - Event loop was unresponsive in Worker for 116.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,159 - distributed.core - INFO - Event loop was unresponsive in Worker for 116.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,160 - distributed.core - INFO - Event loop was unresponsive in Worker for 62.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,160 - distributed.core - INFO - Event loop was unresponsive in Worker for 80.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,159 - distributed.core - INFO - Event loop was unresponsive in Worker for 112.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,163 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,164 - distributed.core - INFO - Event loop was unresponsive in Worker for 112.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,164 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,166 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:17,167 - distributed.core - INFO - Event loop was unresponsive in Worker for 112.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:20,426 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:20,426 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:20,427 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:20,427 - distributed.core - INFO - Event loop was unresponsive in Worker for 125.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:20,428 - distributed.core - INFO - Event loop was unresponsive in Worker for 115.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:20,428 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:20,429 - distributed.core - INFO - Event loop was unresponsive in Worker for 115.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:20,432 - distributed.core - INFO - Event loop was unresponsive in Worker for 125.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:54,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 153.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:54,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 149.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:54,825 - distributed.core - INFO - Event loop was unresponsive in Worker for 149.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:57,794 - distributed.core - INFO - Event loop was unresponsive in Worker for 152.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:21:57,794 - distributed.core - INFO - Event loop was unresponsive in Worker for 152.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:22:24,909 - distributed.core - INFO - Event loop was unresponsive in Worker for 179.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:23:54,966 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:23:54,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:23:54,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:23:54,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:23:54,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:23:54,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:23:54,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:23:54,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 43.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:23:54,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:23:54,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:23:54,978 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:23:54,990 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:24:44,844 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:21,379 - distributed.core - INFO - Event loop was unresponsive in Worker for 132.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:21,382 - distributed.core - INFO - Event loop was unresponsive in Worker for 132.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:21,849 - distributed.core - INFO - Event loop was unresponsive in Worker for 132.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:21,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 130.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:21,854 - distributed.core - INFO - Event loop was unresponsive in Worker for 132.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:38,982 - distributed.core - INFO - Event loop was unresponsive in Worker for 147.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:38,983 - distributed.core - INFO - Event loop was unresponsive in Worker for 147.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:38,983 - distributed.core - INFO - Event loop was unresponsive in Worker for 149.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:38,984 - distributed.core - INFO - Event loop was unresponsive in Worker for 147.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:39,058 - distributed.core - INFO - Event loop was unresponsive in Worker for 148.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:39,058 - distributed.core - INFO - Event loop was unresponsive in Worker for 148.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:39,059 - distributed.core - INFO - Event loop was unresponsive in Worker for 148.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:39,060 - distributed.core - INFO - Event loop was unresponsive in Worker for 148.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:39,060 - distributed.core - INFO - Event loop was unresponsive in Worker for 148.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:39,062 - distributed.core - INFO - Event loop was unresponsive in Worker for 148.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:39,063 - distributed.core - INFO - Event loop was unresponsive in Worker for 148.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:39,076 - distributed.core - INFO - Event loop was unresponsive in Worker for 148.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:47,308 - distributed.core - INFO - Event loop was unresponsive in Worker for 156.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:49,085 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:50,252 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:25:50,253 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,623 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,625 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,625 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,626 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,626 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,627 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,628 - distributed.core - INFO - Event loop was unresponsive in Worker for 66.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,629 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,630 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,630 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,631 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,631 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,633 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,632 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,633 - distributed.core - INFO - Event loop was unresponsive in Worker for 68.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,634 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,639 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,639 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,639 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:26:57,639 - distributed.core - INFO - Event loop was unresponsive in Worker for 73.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:27:07,063 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:27:07,064 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:27:07,064 - distributed.core - INFO - Event loop was unresponsive in Worker for 76.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:27:07,064 - distributed.core - INFO - Event loop was unresponsive in Worker for 78.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:27:07,065 - distributed.core - INFO - Event loop was unresponsive in Worker for 76.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:27:07,067 - distributed.core - INFO - Event loop was unresponsive in Worker for 76.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:27:11,576 - distributed.core - INFO - Event loop was unresponsive in Worker for 82.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:27:11,578 - distributed.core - INFO - Event loop was unresponsive in Worker for 80.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:27:11,796 - distributed.core - INFO - Event loop was unresponsive in Worker for 80.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:27:11,818 - distributed.core - INFO - Event loop was unresponsive in Worker for 80.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:27:11,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 80.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:27:12,952 - distributed.core - INFO - Event loop was unresponsive in Worker for 81.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:28:49,213 - distributed.core - INFO - Event loop was unresponsive in Worker for 76.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:28:49,213 - distributed.core - INFO - Event loop was unresponsive in Worker for 76.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:28:49,214 - distributed.core - INFO - Event loop was unresponsive in Worker for 68.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:28:49,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 76.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:28:49,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 76.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:28:49,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 68.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:28:49,217 - distributed.core - INFO - Event loop was unresponsive in Worker for 76.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:28:49,217 - distributed.core - INFO - Event loop was unresponsive in Worker for 76.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:28:49,217 - distributed.core - INFO - Event loop was unresponsive in Worker for 68.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:28:49,218 - distributed.core - INFO - Event loop was unresponsive in Worker for 76.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:28:49,221 - distributed.core - INFO - Event loop was unresponsive in Worker for 68.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:10,544 - distributed.core - INFO - Event loop was unresponsive in Worker for 97.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:10,544 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:10,546 - distributed.core - INFO - Event loop was unresponsive in Worker for 97.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:10,547 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:10,547 - distributed.core - INFO - Event loop was unresponsive in Worker for 97.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:10,549 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:10,554 - distributed.core - INFO - Event loop was unresponsive in Worker for 97.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:10,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 97.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:13,382 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:13,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:13,386 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:13,386 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:13,389 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:13,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:13,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:13,452 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:13,453 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:13,453 - distributed.core - INFO - Event loop was unresponsive in Worker for 92.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:13,453 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:13,459 - distributed.core - INFO - Event loop was unresponsive in Worker for 100.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:14,338 - distributed.core - INFO - Event loop was unresponsive in Worker for 101.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:14,338 - distributed.core - INFO - Event loop was unresponsive in Worker for 101.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:14,338 - distributed.core - INFO - Event loop was unresponsive in Worker for 101.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:14,339 - distributed.core - INFO - Event loop was unresponsive in Worker for 101.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:19,166 - distributed.core - INFO - Event loop was unresponsive in Worker for 106.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:20,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 99.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:20,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 99.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:20,178 - distributed.core - INFO - Event loop was unresponsive in Worker for 99.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:20,178 - distributed.core - INFO - Event loop was unresponsive in Worker for 99.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:29:20,182 - distributed.core - INFO - Event loop was unresponsive in Worker for 99.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:30:45,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:30:45,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:30:45,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:30:45,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:30:45,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:30:45,875 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:30:45,875 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:30:45,877 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:30:46,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:30:46,039 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:30:46,041 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:30:46,043 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:31:09,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 46.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:31:09,865 - distributed.core - INFO - Event loop was unresponsive in Worker for 46.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:31:09,865 - distributed.core - INFO - Event loop was unresponsive in Worker for 76.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:31:09,866 - distributed.core - INFO - Event loop was unresponsive in Worker for 46.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:31:09,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 76.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:31:09,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 76.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:31:09,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 76.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:31:09,879 - distributed.core - INFO - Event loop was unresponsive in Worker for 76.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:31:09,879 - distributed.core - INFO - Event loop was unresponsive in Worker for 46.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:31:09,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 76.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:31:19,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 86.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:31:35,003 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:30,225 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:30,228 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:30,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:30,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:30,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:30,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:30,247 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:30,248 - distributed.core - INFO - Event loop was unresponsive in Worker for 53.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:30,252 - distributed.core - INFO - Event loop was unresponsive in Worker for 55.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:37,832 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:37,834 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:37,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:37,836 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:37,836 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:37,836 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:37,838 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:37,838 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:37,840 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:37,850 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:37,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:37,853 - distributed.core - INFO - Event loop was unresponsive in Worker for 60.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:37,854 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:32:37,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 59.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:33:42,529 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:33:42,529 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:33:42,531 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:33:42,531 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:33:42,531 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:33:42,532 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:33:42,533 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:33:42,534 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:33:42,534 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:33:42,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 45.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:33:43,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:33:46,956 - distributed.core - INFO - Event loop was unresponsive in Worker for 49.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:33:46,956 - distributed.core - INFO - Event loop was unresponsive in Worker for 49.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:33:46,963 - distributed.core - INFO - Event loop was unresponsive in Worker for 49.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:33:46,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 49.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:33:47,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,506 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,507 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,524 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,524 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,524 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,524 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,525 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,525 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,526 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,527 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,528 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,529 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,529 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,529 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,530 - distributed.core - INFO - Event loop was unresponsive in Worker for 50.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,534 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,535 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,955 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,957 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,957 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,962 - distributed.core - INFO - Event loop was unresponsive in Worker for 52.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,962 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,966 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:39,976 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:34:40,125 - distributed.core - INFO - Event loop was unresponsive in Worker for 51.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:35:12,028 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:35:12,058 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:35:12,961 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-yhqydw9m/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-wt1inv59/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-qk62ptgl/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
2025-11-26 17:39:07,466 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-dwcsv9e6/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-xobxdai_/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-vs6toys_/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-fp_bakvo/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-gi1iuro3/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-i9oaaeou/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-u473c9xj/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-c3jaxqtf/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-xbnhq8nc/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-zpgumcvl/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-uauxcgrv/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-cockp_l9/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
2025-11-26 17:43:31,046 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-f23cc_8j/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-bwhwx9ni/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-0sa9g9l7/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-gx_5gj3h/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-1s_aatem/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
2025-11-26 17:43:38,778 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-jmpie69e/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-9ckwes2j/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-1tl64yrg/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-4f7x6s9d/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-hs0tbpgg/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-2eh6rtyi/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-1thoq669/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-61yng8ii/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-0hs6001j/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-sw25tf1k/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-gs4q5bsl/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-b3f39_g4/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-vc6nwys0/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-a4ui1wp1/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-lavcj7jw/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-_48a_ml4/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-l5j7wuv9/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-4nyzay9z/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
2025-11-26 17:51:35,555 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-86r3xc_1/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-wnprtiir/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-cpogyyw3/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-5i0gkxzu/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-8bk3gd5r/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
2025-11-26 17:54:48,566 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:54:48,566 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:54:48,594 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-nyqjsk8x/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-7ms9ovf3/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
2025-11-26 17:56:10,595 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:56:25,761 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:56:26,391 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:56:31,238 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:56:46,054 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:56:46,066 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-11t4t_z4/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
2025-11-26 17:56:53,583 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:56:54,088 - distributed.core - INFO - Event loop was unresponsive in Worker for 27.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:56:54,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:57:07,629 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 17:57:07,647 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-sglt6enf/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
2025-11-26 22:49:25,904 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/jobfs/155409960.gadi-pbs/dask-scratch-space/worker-fl0bvym7/qme_utils.py:96: RuntimeWarning: invalid value encountered in cast
  return rounded.astype(int)
2025-11-26 23:57:06,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 23:57:06,862 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 23:57:06,875 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 23:57:06,881 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 23:57:06,887 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 23:57:06,890 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 23:57:06,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 23:57:06,913 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 23:57:06,917 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 23:57:06,917 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 23:57:06,920 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 23:57:06,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-26 23:57:06,933 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-27 01:05:43,726 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-27 01:07:01,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-11-27 15:23:40,659 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:55110 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,662 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,662 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,663 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,663 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,659 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:55168 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,660 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:55052 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,665 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,660 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:54968 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,683 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:43265. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,660 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:55028 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,683 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:33675. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,659 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:55184 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,683 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:44005. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,660 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:54836 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,663 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,683 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:38001. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,662 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45814 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,680 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45812 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,660 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:54996 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,663 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45974 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,660 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:54846 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,684 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:37887. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,659 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:55114 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,661 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:54760 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,663 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45778 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,683 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,671 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,660 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:55118 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,683 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,659 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:55156 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,660 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:55134 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,685 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:37061. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,660 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:54896 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,660 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:55014 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,665 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,660 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:55212 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,661 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:54966 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,660 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:54772 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,685 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:33965. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,684 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,684 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,684 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,661 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:54794 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,666 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45750 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,686 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:43987. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,686 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:37011. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,684 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,681 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45990 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,684 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,684 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,687 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:42869. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,687 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:38321. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,685 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,687 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:34165. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,686 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,685 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,688 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:43945. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,686 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,686 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,688 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:36507. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,688 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:45245. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,684 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45632 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,688 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:44349. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,688 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:37377. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,688 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:41123. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,681 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45950 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,686 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,686 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,685 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,682 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45918 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,685 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45616 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,670 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,685 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,689 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:39971. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,689 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:39115. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,689 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:44791. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,686 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45568 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,686 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,689 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:36535. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,687 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,689 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:37845. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,689 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:41461. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,690 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:34935. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,661 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:54834 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,685 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:46807. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,684 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,685 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:37883. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,689 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,684 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,684 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45584 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,686 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:36545. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,686 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,685 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45604 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,663 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45858 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,691 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:44733. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,691 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:41633. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,689 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,687 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,692 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:35917. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,692 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:43319. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,692 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:40455. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,692 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:36145. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,677 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,684 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,693 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:45453. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,688 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45736 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,689 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45600 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,691 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,694 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:36747. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,689 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,694 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:46141. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,695 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:37803. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,692 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,685 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,696 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:39365. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,692 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,694 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,697 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:39865. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,691 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45680 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,697 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:46475. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,698 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:35201. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,693 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45668 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,698 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45832 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,701 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:34901'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,696 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45696 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,704 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:44781'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,704 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:34075'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,704 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:39447'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,696 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,703 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,705 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:43217. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,705 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:40151. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,697 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,664 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45846 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,707 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:36361. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,708 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:42071'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,708 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:36403'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,708 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 13, 17))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,708 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:38371'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,709 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,709 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 16, 10))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,709 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,709 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,709 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,709 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,709 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,709 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 19, 20))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,709 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,709 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,709 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,709 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,709 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,710 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,710 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,710 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,710 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,711 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 13, 20))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,707 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,711 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,711 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:39231. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,711 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,711 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,711 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,711 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,713 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 13, 12))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,713 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,713 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,713 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,713 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,713 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,709 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:46010 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,715 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 4, 9))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,715 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,715 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,716 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,710 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45938 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,716 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,716 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,714 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,717 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:33333. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,711 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.5.30:45724 remote=tcp://10.6.5.29:8754>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-11-27 15:23:40,721 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:39081'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,716 - distributed.core - INFO - Connection to tcp://10.6.5.29:8754 has been closed.
2025-11-27 15:23:40,721 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:43419'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,721 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,721 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,721 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.30:46625. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,721 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:41193'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,721 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,721 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,721 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,722 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,722 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:43299'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,722 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,722 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,722 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,722 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,722 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:41893'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,722 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 19, 5))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,722 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:32901'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,722 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,722 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:44087'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,722 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 6, 12))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,723 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,723 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,723 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:38235'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,723 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,723 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,723 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,723 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,723 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:39599'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,723 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,723 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 3, 5))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,723 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,723 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,723 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:40487'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,723 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 3, 13))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,723 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,724 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:38775'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,724 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,724 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,724 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 13, 9))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,724 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:40401'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,724 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,724 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,724 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,724 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,724 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:42853'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,724 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,724 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,724 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,724 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,724 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,724 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,724 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:44361'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,725 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,725 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,725 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,725 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 20, 10))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,725 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,725 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:40099'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,725 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,725 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,725 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,725 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,725 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:35533'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,725 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,725 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,725 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:39859'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,725 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,725 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,725 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:42277'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,726 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:43369'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,726 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 19, 16))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,726 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:42901'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,726 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 11, 2))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,726 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,726 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,726 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 19, 9))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,726 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:40313'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,726 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,726 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,727 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,727 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,727 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,727 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,727 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,727 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,727 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:36113'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,727 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,727 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,727 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,727 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,727 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,727 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:35631'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,727 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:33045'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,727 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 3, 20))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,727 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:44235'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,728 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 12, 1, 3))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,728 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,728 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 13, 13))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,728 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,728 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,728 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 12, 1, 13))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,728 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,728 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,728 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,728 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 19, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,728 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,728 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,728 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,728 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,729 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,729 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 16, 8))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,729 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,729 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,729 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,729 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,729 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,729 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,729 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,729 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,729 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,729 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,729 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,729 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,729 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,729 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,729 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,729 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 12, 1, 19))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,729 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,730 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,730 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,730 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 20, 21))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,730 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,730 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,730 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,730 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,730 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,730 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,730 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,730 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,731 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,731 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,731 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,731 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 16, 19))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,732 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 3, 23))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,733 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,733 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,733 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,733 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,733 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,733 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,733 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 3, 12))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,733 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,733 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,733 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,733 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,734 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,734 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,734 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,734 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,734 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,738 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:43285'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,738 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:34989'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,714 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14d09b705650>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-11-27 15:23:40,738 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:41115'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,739 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:33961'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,739 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 6, 6))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,739 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,735 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14fcbcef0850>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-11-27 15:23:40,740 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 12, 1, 8))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,740 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,740 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:44007'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,740 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,740 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,740 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,740 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 13, 4))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,740 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,740 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,740 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,740 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,740 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,740 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 3, 3))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,740 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,740 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,740 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,740 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,740 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 4, 14))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,740 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,741 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,741 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,741 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,741 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,741 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,741 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,741 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,741 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:35905'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,741 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,741 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,741 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,741 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:42795'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,742 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:46665'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,742 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 3, 21))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,742 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:42699'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,742 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,743 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,743 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,743 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 6, 5))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,743 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,743 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,744 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:39089'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,744 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,744 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:44865'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,744 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,744 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,745 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,745 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,745 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 19, 15))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,745 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 16, 16))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,745 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:36405'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,745 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,745 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,745 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:37831'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,745 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 13, 1))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,745 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,746 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,746 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,746 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,746 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,746 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 12, 1, 5))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,746 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,746 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,746 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,746 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,746 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,746 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,746 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,746 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,746 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,746 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,747 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,747 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,747 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,748 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 19, 21))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,748 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:34113'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,748 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,748 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,748 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,748 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,748 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,748 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:40717'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,749 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 16, 11))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,750 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,750 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,750 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,750 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,750 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,751 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 12, 1, 2))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,752 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.30:38217'. Reason: worker-handle-scheduler-connection-broken
2025-11-27 15:23:40,753 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 3, 22))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,754 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,754 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,754 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,754 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,754 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,755 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,756 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,756 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,756 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,756 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,752 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14ce4b1d0b90>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-11-27 15:23:40,758 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 3, 8))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,759 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,759 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,759 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,759 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,759 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,761 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 18, 5))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,762 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 12, 1, 14))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,763 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,763 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,763 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,763 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,763 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,764 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,764 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,764 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,764 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,764 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,775 - distributed.nanny - INFO - Worker closed
2025-11-27 15:23:40,787 - distributed.nanny - INFO - Worker closed
2025-11-27 15:23:40,800 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-store-map-5be050071693583639bb4470ea59ef87', 14, 16, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-11-27 15:23:40,800 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-11-27 15:23:40,800 - distributed.worker - INFO - Removing Worker plugin qme_utils.py674d9d32-6672-484a-b91b-e4a275413418
2025-11-27 15:23:40,801 - distributed.worker - INFO - Removing Worker plugin qme_vars.pya3033653-4f64-4bca-b9b2-9306677b8e14
2025-11-27 15:23:40,801 - distributed.worker - INFO - Removing Worker plugin qme_train.pyf0bd0531-9b7b-406c-8753-ddc98ddfd0d4
2025-11-27 15:23:40,801 - distributed.worker - INFO - Removing Worker plugin qme_apply.py35aa1b80-c438-4fcc-813f-77f213cb4fd9
2025-11-27 15:23:40,810 - distributed.nanny - INFO - Worker closed
2025-11-27 15:23:42,808 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-11-27 15:23:42,838 - distributed.nanny - ERROR - Worker process died unexpectedly
