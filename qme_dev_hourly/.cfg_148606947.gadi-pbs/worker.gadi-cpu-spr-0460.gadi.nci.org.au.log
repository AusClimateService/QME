Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-03 10:31:59,991 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:36199'
2025-09-03 10:32:00,003 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:39941'
2025-09-03 10:32:00,008 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:46683'
2025-09-03 10:32:00,014 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:37037'
2025-09-03 10:32:00,018 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:37661'
2025-09-03 10:32:00,025 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:38203'
2025-09-03 10:32:00,029 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:45083'
2025-09-03 10:32:00,033 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:39579'
2025-09-03 10:32:00,041 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:40503'
2025-09-03 10:32:00,046 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:37001'
2025-09-03 10:32:00,052 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:34813'
2025-09-03 10:32:00,059 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:46833'
2025-09-03 10:32:00,062 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:35551'
2025-09-03 10:32:00,067 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:41825'
2025-09-03 10:32:00,072 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:46649'
2025-09-03 10:32:00,076 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:35785'
2025-09-03 10:32:00,080 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:43465'
2025-09-03 10:32:00,085 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:35299'
2025-09-03 10:32:00,090 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:37287'
2025-09-03 10:32:00,094 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:36919'
2025-09-03 10:32:00,099 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:42927'
2025-09-03 10:32:00,103 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:45093'
2025-09-03 10:32:00,107 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:34589'
2025-09-03 10:32:00,112 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:46799'
2025-09-03 10:32:00,116 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:43433'
2025-09-03 10:32:00,121 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:37841'
2025-09-03 10:32:00,126 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:45989'
2025-09-03 10:32:00,231 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:36313'
2025-09-03 10:32:00,236 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:45557'
2025-09-03 10:32:00,240 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:43461'
2025-09-03 10:32:00,244 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:34633'
2025-09-03 10:32:00,248 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:46055'
2025-09-03 10:32:00,253 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:38811'
2025-09-03 10:32:00,257 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:43271'
2025-09-03 10:32:00,953 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:44939'
2025-09-03 10:32:00,958 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:45335'
2025-09-03 10:32:00,962 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:44773'
2025-09-03 10:32:00,967 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:39113'
2025-09-03 10:32:00,972 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:40567'
2025-09-03 10:32:00,977 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:38855'
2025-09-03 10:32:00,982 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:35347'
2025-09-03 10:32:00,986 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:45753'
2025-09-03 10:32:00,992 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:43585'
2025-09-03 10:32:00,997 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:41439'
2025-09-03 10:32:01,013 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:37379'
2025-09-03 10:32:01,016 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:45777'
2025-09-03 10:32:01,019 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:39735'
2025-09-03 10:32:01,022 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:37585
2025-09-03 10:32:01,023 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:37585
2025-09-03 10:32:01,023 - distributed.worker - INFO -          dashboard at:          10.6.102.28:35275
2025-09-03 10:32:01,023 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,023 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,023 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,023 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,023 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-dl5vm3tx
2025-09-03 10:32:01,023 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,023 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:46579
2025-09-03 10:32:01,023 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:35569'
2025-09-03 10:32:01,023 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:46579
2025-09-03 10:32:01,023 - distributed.worker - INFO -          dashboard at:          10.6.102.28:37813
2025-09-03 10:32:01,023 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,023 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,023 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,023 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,023 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-2w2giyj5
2025-09-03 10:32:01,023 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,023 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:34421
2025-09-03 10:32:01,024 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:34421
2025-09-03 10:32:01,024 - distributed.worker - INFO -          dashboard at:          10.6.102.28:34895
2025-09-03 10:32:01,024 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,024 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,024 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,024 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,024 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-tn5sgc25
2025-09-03 10:32:01,024 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,025 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:40409
2025-09-03 10:32:01,025 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:40409
2025-09-03 10:32:01,025 - distributed.worker - INFO -          dashboard at:          10.6.102.28:39325
2025-09-03 10:32:01,025 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,025 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,025 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,025 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,025 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-5w4qeuxr
2025-09-03 10:32:01,025 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,026 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:37965
2025-09-03 10:32:01,026 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:37965
2025-09-03 10:32:01,026 - distributed.worker - INFO -          dashboard at:          10.6.102.28:42229
2025-09-03 10:32:01,026 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:33429'
2025-09-03 10:32:01,026 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,026 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,026 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,026 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,026 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-sao5xogp
2025-09-03 10:32:01,026 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,028 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:46009
2025-09-03 10:32:01,028 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:46009
2025-09-03 10:32:01,028 - distributed.worker - INFO -          dashboard at:          10.6.102.28:42293
2025-09-03 10:32:01,028 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,028 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,028 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,028 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,028 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-icn009bq
2025-09-03 10:32:01,028 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,031 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:35803
2025-09-03 10:32:01,032 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:35803
2025-09-03 10:32:01,032 - distributed.worker - INFO -          dashboard at:          10.6.102.28:46169
2025-09-03 10:32:01,032 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,032 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,032 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:45837
2025-09-03 10:32:01,032 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,032 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,032 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:45837
2025-09-03 10:32:01,032 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ks_qe5a9
2025-09-03 10:32:01,032 - distributed.worker - INFO -          dashboard at:          10.6.102.28:33435
2025-09-03 10:32:01,032 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,032 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,032 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,032 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,032 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,033 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-xg2pr8zq
2025-09-03 10:32:01,033 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,033 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:43613'
2025-09-03 10:32:01,037 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:45099'
2025-09-03 10:32:01,040 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:45169'
2025-09-03 10:32:01,043 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:36073'
2025-09-03 10:32:01,048 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:38211'
2025-09-03 10:32:01,053 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:45433'
2025-09-03 10:32:01,058 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:39767'
2025-09-03 10:32:01,063 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:44609'
2025-09-03 10:32:01,067 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:42705'
2025-09-03 10:32:01,071 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:46775'
2025-09-03 10:32:01,074 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:46233'
2025-09-03 10:32:01,078 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:46283'
2025-09-03 10:32:01,082 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:45705'
2025-09-03 10:32:01,087 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:42587'
2025-09-03 10:32:01,091 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:35735'
2025-09-03 10:32:01,093 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:42909'
2025-09-03 10:32:01,098 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:41731'
2025-09-03 10:32:01,103 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:41697'
2025-09-03 10:32:01,106 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:45171'
2025-09-03 10:32:01,110 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:36677'
2025-09-03 10:32:01,112 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:36201'
2025-09-03 10:32:01,116 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:43185'
2025-09-03 10:32:01,120 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:36653'
2025-09-03 10:32:01,124 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:45097'
2025-09-03 10:32:01,131 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:34929'
2025-09-03 10:32:01,136 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:45829'
2025-09-03 10:32:01,140 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:43447'
2025-09-03 10:32:01,144 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:37403'
2025-09-03 10:32:01,148 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:34893'
2025-09-03 10:32:01,155 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:37615'
2025-09-03 10:32:01,159 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:41675'
2025-09-03 10:32:01,164 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:33583'
2025-09-03 10:32:01,169 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:37375'
2025-09-03 10:32:01,175 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:44503'
2025-09-03 10:32:01,179 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:36533'
2025-09-03 10:32:01,183 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:45275'
2025-09-03 10:32:01,190 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:46441'
2025-09-03 10:32:01,194 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:40671'
2025-09-03 10:32:01,199 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:35597'
2025-09-03 10:32:01,203 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:34235'
2025-09-03 10:32:01,208 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:42367'
2025-09-03 10:32:01,213 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:41133'
2025-09-03 10:32:01,219 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:33317'
2025-09-03 10:32:01,223 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:35717'
2025-09-03 10:32:01,227 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:43137'
2025-09-03 10:32:01,231 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:46131'
2025-09-03 10:32:01,298 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:37999
2025-09-03 10:32:01,298 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:37999
2025-09-03 10:32:01,298 - distributed.worker - INFO -          dashboard at:          10.6.102.28:34999
2025-09-03 10:32:01,298 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,298 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,298 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,298 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,298 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-osngwtav
2025-09-03 10:32:01,299 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,302 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:35355
2025-09-03 10:32:01,302 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:35355
2025-09-03 10:32:01,302 - distributed.worker - INFO -          dashboard at:          10.6.102.28:39245
2025-09-03 10:32:01,302 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,302 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,302 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,302 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,302 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-iijg0vdr
2025-09-03 10:32:01,302 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,305 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:43879
2025-09-03 10:32:01,305 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:43879
2025-09-03 10:32:01,305 - distributed.worker - INFO -          dashboard at:          10.6.102.28:38745
2025-09-03 10:32:01,305 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,305 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,305 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,305 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,305 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ob4199t_
2025-09-03 10:32:01,305 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,307 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:33631
2025-09-03 10:32:01,307 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:33631
2025-09-03 10:32:01,307 - distributed.worker - INFO -          dashboard at:          10.6.102.28:38381
2025-09-03 10:32:01,307 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,307 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,307 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,307 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,307 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-a4dv3lcv
2025-09-03 10:32:01,307 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,311 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:39255
2025-09-03 10:32:01,311 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:39255
2025-09-03 10:32:01,311 - distributed.worker - INFO -          dashboard at:          10.6.102.28:41965
2025-09-03 10:32:01,311 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,311 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,311 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,311 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,311 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-l0bq7czf
2025-09-03 10:32:01,311 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,314 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:35759
2025-09-03 10:32:01,314 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:35759
2025-09-03 10:32:01,314 - distributed.worker - INFO -          dashboard at:          10.6.102.28:42209
2025-09-03 10:32:01,314 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,314 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,314 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,314 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,314 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-gwtc1zn5
2025-09-03 10:32:01,314 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,316 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:37255
2025-09-03 10:32:01,316 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:37255
2025-09-03 10:32:01,316 - distributed.worker - INFO -          dashboard at:          10.6.102.28:40287
2025-09-03 10:32:01,316 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,316 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,316 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,316 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,316 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-6fhm82um
2025-09-03 10:32:01,316 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,320 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:33855
2025-09-03 10:32:01,321 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:33855
2025-09-03 10:32:01,321 - distributed.worker - INFO -          dashboard at:          10.6.102.28:41649
2025-09-03 10:32:01,321 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,321 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,321 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,321 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,321 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fcony0v6
2025-09-03 10:32:01,321 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,321 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:44589
2025-09-03 10:32:01,321 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:44589
2025-09-03 10:32:01,321 - distributed.worker - INFO -          dashboard at:          10.6.102.28:33755
2025-09-03 10:32:01,321 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,321 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,321 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,321 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,321 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-24ejexe3
2025-09-03 10:32:01,321 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,324 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:36259
2025-09-03 10:32:01,324 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:36259
2025-09-03 10:32:01,324 - distributed.worker - INFO -          dashboard at:          10.6.102.28:40601
2025-09-03 10:32:01,324 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,324 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,324 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,324 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,324 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-f4fs35fk
2025-09-03 10:32:01,324 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,326 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:40247
2025-09-03 10:32:01,326 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:40247
2025-09-03 10:32:01,326 - distributed.worker - INFO -          dashboard at:          10.6.102.28:37697
2025-09-03 10:32:01,326 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,326 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,326 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,327 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,327 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-5lvys_kx
2025-09-03 10:32:01,327 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,329 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:39407
2025-09-03 10:32:01,329 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:39407
2025-09-03 10:32:01,329 - distributed.worker - INFO -          dashboard at:          10.6.102.28:38293
2025-09-03 10:32:01,329 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,329 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,330 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,330 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,330 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-i2hsd_9n
2025-09-03 10:32:01,330 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,331 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:42307
2025-09-03 10:32:01,331 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:42307
2025-09-03 10:32:01,331 - distributed.worker - INFO -          dashboard at:          10.6.102.28:41719
2025-09-03 10:32:01,331 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,331 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,331 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,331 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,331 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-39e6vh8e
2025-09-03 10:32:01,331 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,332 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:38365
2025-09-03 10:32:01,332 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:38365
2025-09-03 10:32:01,332 - distributed.worker - INFO -          dashboard at:          10.6.102.28:33853
2025-09-03 10:32:01,332 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,332 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,332 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,332 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,332 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-koi2i5tb
2025-09-03 10:32:01,333 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,333 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:41387
2025-09-03 10:32:01,333 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:41387
2025-09-03 10:32:01,333 - distributed.worker - INFO -          dashboard at:          10.6.102.28:40359
2025-09-03 10:32:01,333 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,333 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,333 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,333 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,333 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-76pzt4b1
2025-09-03 10:32:01,333 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,335 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:38237
2025-09-03 10:32:01,335 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:38237
2025-09-03 10:32:01,335 - distributed.worker - INFO -          dashboard at:          10.6.102.28:43799
2025-09-03 10:32:01,335 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,335 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,335 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,335 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,335 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-rby5n4ru
2025-09-03 10:32:01,335 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,336 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:39133
2025-09-03 10:32:01,336 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:39133
2025-09-03 10:32:01,336 - distributed.worker - INFO -          dashboard at:          10.6.102.28:36487
2025-09-03 10:32:01,336 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,336 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,336 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,336 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,336 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-8lil9rjk
2025-09-03 10:32:01,336 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,337 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:38531
2025-09-03 10:32:01,337 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:38531
2025-09-03 10:32:01,337 - distributed.worker - INFO -          dashboard at:          10.6.102.28:38989
2025-09-03 10:32:01,337 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,337 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,337 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,337 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,337 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-qsp9p7eb
2025-09-03 10:32:01,337 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,339 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:33195
2025-09-03 10:32:01,340 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:33195
2025-09-03 10:32:01,340 - distributed.worker - INFO -          dashboard at:          10.6.102.28:44533
2025-09-03 10:32:01,340 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,340 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,340 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,340 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,340 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-lf6273lc
2025-09-03 10:32:01,340 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,341 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:41383
2025-09-03 10:32:01,341 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:41383
2025-09-03 10:32:01,341 - distributed.worker - INFO -          dashboard at:          10.6.102.28:44727
2025-09-03 10:32:01,341 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,341 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,341 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,341 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,341 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-0apm6fmt
2025-09-03 10:32:01,341 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,342 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:33491
2025-09-03 10:32:01,342 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:42663
2025-09-03 10:32:01,342 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:33491
2025-09-03 10:32:01,342 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:42663
2025-09-03 10:32:01,342 - distributed.worker - INFO -          dashboard at:          10.6.102.28:39511
2025-09-03 10:32:01,342 - distributed.worker - INFO -          dashboard at:          10.6.102.28:39409
2025-09-03 10:32:01,342 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,342 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,342 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,342 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,342 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,342 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,342 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,342 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-k31wager
2025-09-03 10:32:01,342 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,342 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,342 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-p1abmplh
2025-09-03 10:32:01,342 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,344 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:36319
2025-09-03 10:32:01,344 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:36319
2025-09-03 10:32:01,344 - distributed.worker - INFO -          dashboard at:          10.6.102.28:46591
2025-09-03 10:32:01,344 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,344 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,344 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,344 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,344 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zwoosy0d
2025-09-03 10:32:01,344 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,348 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:46643
2025-09-03 10:32:01,348 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:46643
2025-09-03 10:32:01,349 - distributed.worker - INFO -          dashboard at:          10.6.102.28:37147
2025-09-03 10:32:01,349 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,349 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,349 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,349 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,349 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-cdgl1yen
2025-09-03 10:32:01,349 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,350 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:35797
2025-09-03 10:32:01,351 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:35797
2025-09-03 10:32:01,351 - distributed.worker - INFO -          dashboard at:          10.6.102.28:42269
2025-09-03 10:32:01,351 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,351 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,351 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,351 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,351 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-v7s0qbl_
2025-09-03 10:32:01,351 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,352 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:33313
2025-09-03 10:32:01,352 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:33313
2025-09-03 10:32:01,352 - distributed.worker - INFO -          dashboard at:          10.6.102.28:35799
2025-09-03 10:32:01,352 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,352 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,352 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:01,352 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:01,352 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-w5i3tko3
2025-09-03 10:32:01,352 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,932 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:01,933 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,933 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,935 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:01,946 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:01,947 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,947 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,949 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:01,961 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:01,963 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,963 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,964 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:01,977 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:01,978 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,978 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,980 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:01,992 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:01,993 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:01,993 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:01,994 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:02,007 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:02,008 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,008 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,010 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:02,022 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:02,023 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,023 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,025 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:02,037 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:02,038 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,038 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,039 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:02,156 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:39733
2025-09-03 10:32:02,156 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:39733
2025-09-03 10:32:02,156 - distributed.worker - INFO -          dashboard at:          10.6.102.28:40481
2025-09-03 10:32:02,156 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,157 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,157 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,157 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,157 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-x0s446_9
2025-09-03 10:32:02,157 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,163 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:36709
2025-09-03 10:32:02,163 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:36709
2025-09-03 10:32:02,164 - distributed.worker - INFO -          dashboard at:          10.6.102.28:36019
2025-09-03 10:32:02,164 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,164 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,164 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,164 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,164 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-pceiql9o
2025-09-03 10:32:02,164 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,168 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:35583
2025-09-03 10:32:02,168 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:35583
2025-09-03 10:32:02,168 - distributed.worker - INFO -          dashboard at:          10.6.102.28:38153
2025-09-03 10:32:02,168 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,168 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,168 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,168 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,168 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-uvg2so1h
2025-09-03 10:32:02,168 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,183 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:38489
2025-09-03 10:32:02,183 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:38489
2025-09-03 10:32:02,183 - distributed.worker - INFO -          dashboard at:          10.6.102.28:36203
2025-09-03 10:32:02,183 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,183 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,183 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,183 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,183 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7u9fky1h
2025-09-03 10:32:02,183 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,185 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:43713
2025-09-03 10:32:02,185 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:43713
2025-09-03 10:32:02,185 - distributed.worker - INFO -          dashboard at:          10.6.102.28:40821
2025-09-03 10:32:02,186 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,186 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,186 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,186 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,186 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-07hlqd0c
2025-09-03 10:32:02,186 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,186 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:37387
2025-09-03 10:32:02,186 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:37387
2025-09-03 10:32:02,186 - distributed.worker - INFO -          dashboard at:          10.6.102.28:42795
2025-09-03 10:32:02,186 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,186 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,186 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,186 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,186 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_dqxc6r3
2025-09-03 10:32:02,187 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,197 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:41915
2025-09-03 10:32:02,197 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:41915
2025-09-03 10:32:02,197 - distributed.worker - INFO -          dashboard at:          10.6.102.28:40553
2025-09-03 10:32:02,197 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,197 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,197 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,197 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,198 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7t38fj9k
2025-09-03 10:32:02,198 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,254 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:46687
2025-09-03 10:32:02,254 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:46687
2025-09-03 10:32:02,254 - distributed.worker - INFO -          dashboard at:          10.6.102.28:32959
2025-09-03 10:32:02,255 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,255 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,255 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,255 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,255 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-sgy8dq_s
2025-09-03 10:32:02,255 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,403 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:45007
2025-09-03 10:32:02,403 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:45007
2025-09-03 10:32:02,404 - distributed.worker - INFO -          dashboard at:          10.6.102.28:44623
2025-09-03 10:32:02,404 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,404 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,404 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,404 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,404 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-u7ql7vgw
2025-09-03 10:32:02,404 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,408 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:35971
2025-09-03 10:32:02,409 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:35971
2025-09-03 10:32:02,409 - distributed.worker - INFO -          dashboard at:          10.6.102.28:37381
2025-09-03 10:32:02,409 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,409 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,409 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,409 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,409 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-5yro5nve
2025-09-03 10:32:02,409 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,413 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:33447
2025-09-03 10:32:02,413 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:33447
2025-09-03 10:32:02,413 - distributed.worker - INFO -          dashboard at:          10.6.102.28:42659
2025-09-03 10:32:02,413 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,413 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,413 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,413 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,413 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-tv309apk
2025-09-03 10:32:02,413 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,421 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:40697
2025-09-03 10:32:02,422 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:40697
2025-09-03 10:32:02,422 - distributed.worker - INFO -          dashboard at:          10.6.102.28:44965
2025-09-03 10:32:02,422 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,422 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,422 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,422 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,422 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-wxjoajb6
2025-09-03 10:32:02,422 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,439 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:40279
2025-09-03 10:32:02,439 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:40279
2025-09-03 10:32:02,439 - distributed.worker - INFO -          dashboard at:          10.6.102.28:46193
2025-09-03 10:32:02,439 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,439 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,439 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,439 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,439 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7mfsqtvr
2025-09-03 10:32:02,439 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,451 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:33459
2025-09-03 10:32:02,451 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:33459
2025-09-03 10:32:02,451 - distributed.worker - INFO -          dashboard at:          10.6.102.28:44415
2025-09-03 10:32:02,451 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,451 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,451 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,451 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,451 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-vwtsxgaa
2025-09-03 10:32:02,451 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,466 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:43831
2025-09-03 10:32:02,466 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:43831
2025-09-03 10:32:02,466 - distributed.worker - INFO -          dashboard at:          10.6.102.28:41743
2025-09-03 10:32:02,466 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,466 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,466 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,466 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,466 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ynth0gvf
2025-09-03 10:32:02,466 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,533 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:38339
2025-09-03 10:32:02,533 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:38339
2025-09-03 10:32:02,533 - distributed.worker - INFO -          dashboard at:          10.6.102.28:33135
2025-09-03 10:32:02,533 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,533 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,533 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,533 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,533 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-30pnczea
2025-09-03 10:32:02,533 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,590 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:45539
2025-09-03 10:32:02,590 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:45539
2025-09-03 10:32:02,590 - distributed.worker - INFO -          dashboard at:          10.6.102.28:44813
2025-09-03 10:32:02,590 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,590 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,590 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,590 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,590 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_y_wbn83
2025-09-03 10:32:02,590 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,622 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:44063
2025-09-03 10:32:02,623 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:44063
2025-09-03 10:32:02,623 - distributed.worker - INFO -          dashboard at:          10.6.102.28:43705
2025-09-03 10:32:02,623 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,623 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,623 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,623 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,623 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7lapsjb4
2025-09-03 10:32:02,623 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,633 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:33515
2025-09-03 10:32:02,633 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:33515
2025-09-03 10:32:02,633 - distributed.worker - INFO -          dashboard at:          10.6.102.28:43909
2025-09-03 10:32:02,633 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,633 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,633 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,633 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,633 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-g9v20w3t
2025-09-03 10:32:02,634 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,687 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:42777'
2025-09-03 10:32:02,692 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:37239'
2025-09-03 10:32:02,724 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:02,726 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,726 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,728 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:02,736 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:45095
2025-09-03 10:32:02,736 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:45095
2025-09-03 10:32:02,736 - distributed.worker - INFO -          dashboard at:          10.6.102.28:39857
2025-09-03 10:32:02,736 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,736 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,736 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,736 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,736 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-1c7n_vd7
2025-09-03 10:32:02,736 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,741 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:44995
2025-09-03 10:32:02,741 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:44995
2025-09-03 10:32:02,741 - distributed.worker - INFO -          dashboard at:          10.6.102.28:42441
2025-09-03 10:32:02,741 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,741 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,741 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,741 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,741 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-h60eq90w
2025-09-03 10:32:02,741 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:02,741 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,742 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,742 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,744 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:02,751 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:42309
2025-09-03 10:32:02,751 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:42309
2025-09-03 10:32:02,752 - distributed.worker - INFO -          dashboard at:          10.6.102.28:39331
2025-09-03 10:32:02,751 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:35969
2025-09-03 10:32:02,752 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,752 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,752 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:35969
2025-09-03 10:32:02,752 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,752 - distributed.worker - INFO -          dashboard at:          10.6.102.28:36387
2025-09-03 10:32:02,752 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,752 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,752 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-g6l4a1le
2025-09-03 10:32:02,752 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,752 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,752 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,752 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,752 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-mjkg7v7z
2025-09-03 10:32:02,752 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,753 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:46195
2025-09-03 10:32:02,753 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:46195
2025-09-03 10:32:02,753 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:40847
2025-09-03 10:32:02,753 - distributed.worker - INFO -          dashboard at:          10.6.102.28:38743
2025-09-03 10:32:02,753 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:40847
2025-09-03 10:32:02,753 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,753 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,753 - distributed.worker - INFO -          dashboard at:          10.6.102.28:38951
2025-09-03 10:32:02,753 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,753 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,753 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,753 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:41997
2025-09-03 10:32:02,753 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,753 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ysjtxlvg
2025-09-03 10:32:02,753 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,753 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:41997
2025-09-03 10:32:02,753 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,753 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,753 - distributed.worker - INFO -          dashboard at:          10.6.102.28:36889
2025-09-03 10:32:02,753 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-qymos2p6
2025-09-03 10:32:02,754 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,754 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,754 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,754 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,754 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,754 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-b9uhscjm
2025-09-03 10:32:02,754 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,755 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:42135
2025-09-03 10:32:02,755 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:42135
2025-09-03 10:32:02,755 - distributed.worker - INFO -          dashboard at:          10.6.102.28:35559
2025-09-03 10:32:02,755 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,755 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,755 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,755 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,755 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-eujnr3fc
2025-09-03 10:32:02,755 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,757 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:02,757 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:36543
2025-09-03 10:32:02,758 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:36543
2025-09-03 10:32:02,758 - distributed.worker - INFO -          dashboard at:          10.6.102.28:35859
2025-09-03 10:32:02,758 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,758 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,758 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,758 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,758 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-h8uj8cug
2025-09-03 10:32:02,758 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,758 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,758 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,760 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:02,775 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:44005
2025-09-03 10:32:02,775 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:44005
2025-09-03 10:32:02,775 - distributed.worker - INFO -          dashboard at:          10.6.102.28:44377
2025-09-03 10:32:02,775 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,775 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,775 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,775 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,775 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-nn1xjanf
2025-09-03 10:32:02,775 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,775 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:36337
2025-09-03 10:32:02,776 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:36337
2025-09-03 10:32:02,776 - distributed.worker - INFO -          dashboard at:          10.6.102.28:43381
2025-09-03 10:32:02,776 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,776 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,776 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,776 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,776 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_bkumxqw
2025-09-03 10:32:02,776 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,784 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:39479
2025-09-03 10:32:02,784 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:39479
2025-09-03 10:32:02,784 - distributed.worker - INFO -          dashboard at:          10.6.102.28:38539
2025-09-03 10:32:02,784 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,784 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,784 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,784 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,784 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-t42bs6pi
2025-09-03 10:32:02,785 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,790 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:41679
2025-09-03 10:32:02,790 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:41679
2025-09-03 10:32:02,790 - distributed.worker - INFO -          dashboard at:          10.6.102.28:40541
2025-09-03 10:32:02,790 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,790 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,790 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,790 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,790 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-wd_et05m
2025-09-03 10:32:02,790 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,790 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:38297
2025-09-03 10:32:02,790 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:38297
2025-09-03 10:32:02,790 - distributed.worker - INFO -          dashboard at:          10.6.102.28:38993
2025-09-03 10:32:02,791 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,791 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,791 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,791 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,791 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-xbsbr2g7
2025-09-03 10:32:02,791 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,792 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:45453
2025-09-03 10:32:02,792 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:45453
2025-09-03 10:32:02,792 - distributed.worker - INFO -          dashboard at:          10.6.102.28:45029
2025-09-03 10:32:02,792 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,792 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,792 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,792 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,792 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-toljjffj
2025-09-03 10:32:02,792 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,793 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:37507
2025-09-03 10:32:02,793 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:37507
2025-09-03 10:32:02,793 - distributed.worker - INFO -          dashboard at:          10.6.102.28:37883
2025-09-03 10:32:02,793 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,793 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,793 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,793 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,793 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-x9k86_s3
2025-09-03 10:32:02,793 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,794 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:39419
2025-09-03 10:32:02,794 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:39419
2025-09-03 10:32:02,794 - distributed.worker - INFO -          dashboard at:          10.6.102.28:39811
2025-09-03 10:32:02,794 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,794 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,794 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,794 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,794 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-pf0u44da
2025-09-03 10:32:02,794 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,794 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:34709
2025-09-03 10:32:02,794 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:34709
2025-09-03 10:32:02,794 - distributed.worker - INFO -          dashboard at:          10.6.102.28:39297
2025-09-03 10:32:02,794 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,794 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,794 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,794 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,794 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-025rb6xj
2025-09-03 10:32:02,794 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,796 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:38301
2025-09-03 10:32:02,796 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:38301
2025-09-03 10:32:02,796 - distributed.worker - INFO -          dashboard at:          10.6.102.28:32825
2025-09-03 10:32:02,796 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,796 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,796 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,796 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,796 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-rsavg4k7
2025-09-03 10:32:02,796 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,797 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:46031
2025-09-03 10:32:02,797 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:46031
2025-09-03 10:32:02,797 - distributed.worker - INFO -          dashboard at:          10.6.102.28:44279
2025-09-03 10:32:02,797 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,797 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,797 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,797 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,798 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-rz4j3u2x
2025-09-03 10:32:02,798 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,798 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:34821
2025-09-03 10:32:02,798 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:34821
2025-09-03 10:32:02,798 - distributed.worker - INFO -          dashboard at:          10.6.102.28:36861
2025-09-03 10:32:02,798 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,798 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,798 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,798 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,798 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-aod2t3y5
2025-09-03 10:32:02,798 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,799 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:41795
2025-09-03 10:32:02,799 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:41795
2025-09-03 10:32:02,799 - distributed.worker - INFO -          dashboard at:          10.6.102.28:38555
2025-09-03 10:32:02,799 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,799 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,800 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,800 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,800 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-gi0uqo6t
2025-09-03 10:32:02,800 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,803 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:35321
2025-09-03 10:32:02,803 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:35321
2025-09-03 10:32:02,803 - distributed.worker - INFO -          dashboard at:          10.6.102.28:42821
2025-09-03 10:32:02,803 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,803 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,803 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,803 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,803 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-0c9ymvrc
2025-09-03 10:32:02,803 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:46651
2025-09-03 10:32:02,803 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,803 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:46651
2025-09-03 10:32:02,803 - distributed.worker - INFO -          dashboard at:          10.6.102.28:38845
2025-09-03 10:32:02,803 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,803 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:36619
2025-09-03 10:32:02,803 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,803 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,803 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:36619
2025-09-03 10:32:02,803 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,803 - distributed.worker - INFO -          dashboard at:          10.6.102.28:34491
2025-09-03 10:32:02,803 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-tp7kxb4u
2025-09-03 10:32:02,803 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,803 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,803 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,803 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,804 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,804 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3qdn28p9
2025-09-03 10:32:02,804 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,804 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:46575
2025-09-03 10:32:02,804 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:46575
2025-09-03 10:32:02,804 - distributed.worker - INFO -          dashboard at:          10.6.102.28:37363
2025-09-03 10:32:02,804 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,804 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,804 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,804 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,804 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-kikinuar
2025-09-03 10:32:02,804 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,804 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:36057
2025-09-03 10:32:02,804 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:36057
2025-09-03 10:32:02,804 - distributed.worker - INFO -          dashboard at:          10.6.102.28:44099
2025-09-03 10:32:02,805 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,805 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,805 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,805 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,805 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-29pcf2e2
2025-09-03 10:32:02,805 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,805 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:37639
2025-09-03 10:32:02,805 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:37639
2025-09-03 10:32:02,805 - distributed.worker - INFO -          dashboard at:          10.6.102.28:46811
2025-09-03 10:32:02,805 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,805 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:37987
2025-09-03 10:32:02,805 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,805 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,805 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:37987
2025-09-03 10:32:02,805 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,805 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:36509
2025-09-03 10:32:02,805 - distributed.worker - INFO -          dashboard at:          10.6.102.28:37685
2025-09-03 10:32:02,805 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-gnortm_v
2025-09-03 10:32:02,805 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:36509
2025-09-03 10:32:02,805 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,805 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,805 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,805 - distributed.worker - INFO -          dashboard at:          10.6.102.28:41707
2025-09-03 10:32:02,805 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,805 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,805 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,805 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,805 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-5lww4mqt
2025-09-03 10:32:02,805 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,805 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,805 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,805 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-0pke3cz8
2025-09-03 10:32:02,805 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,806 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:46663
2025-09-03 10:32:02,806 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:38503
2025-09-03 10:32:02,806 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:46663
2025-09-03 10:32:02,806 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:38503
2025-09-03 10:32:02,806 - distributed.worker - INFO -          dashboard at:          10.6.102.28:37755
2025-09-03 10:32:02,806 - distributed.worker - INFO -          dashboard at:          10.6.102.28:36399
2025-09-03 10:32:02,806 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,806 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,806 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,806 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,806 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,806 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,806 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,806 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,806 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-95dl8b98
2025-09-03 10:32:02,807 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-2khxspps
2025-09-03 10:32:02,807 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,807 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,808 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:40861
2025-09-03 10:32:02,808 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:33915
2025-09-03 10:32:02,808 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:40861
2025-09-03 10:32:02,808 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:33915
2025-09-03 10:32:02,808 - distributed.worker - INFO -          dashboard at:          10.6.102.28:34365
2025-09-03 10:32:02,808 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,808 - distributed.worker - INFO -          dashboard at:          10.6.102.28:34695
2025-09-03 10:32:02,808 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,808 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,808 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,808 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,808 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,808 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,808 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,808 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-8f6p8uf7
2025-09-03 10:32:02,808 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-u21q393g
2025-09-03 10:32:02,808 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,808 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,810 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:40131
2025-09-03 10:32:02,810 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:40131
2025-09-03 10:32:02,810 - distributed.worker - INFO -          dashboard at:          10.6.102.28:39771
2025-09-03 10:32:02,810 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,810 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,810 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,810 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,810 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-e0v38r9a
2025-09-03 10:32:02,810 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,811 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:45953
2025-09-03 10:32:02,811 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:45953
2025-09-03 10:32:02,811 - distributed.worker - INFO -          dashboard at:          10.6.102.28:45783
2025-09-03 10:32:02,811 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,811 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,811 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,811 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,811 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-oa6kwxkc
2025-09-03 10:32:02,811 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,812 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:35383
2025-09-03 10:32:02,812 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:35383
2025-09-03 10:32:02,812 - distributed.worker - INFO -          dashboard at:          10.6.102.28:45559
2025-09-03 10:32:02,812 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,812 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,812 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,812 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,812 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7hiipxmc
2025-09-03 10:32:02,812 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,812 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:38393
2025-09-03 10:32:02,812 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:38393
2025-09-03 10:32:02,812 - distributed.worker - INFO -          dashboard at:          10.6.102.28:46761
2025-09-03 10:32:02,812 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,812 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,812 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,812 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,812 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-5q_8ftrd
2025-09-03 10:32:02,812 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,814 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:34435
2025-09-03 10:32:02,814 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:34435
2025-09-03 10:32:02,814 - distributed.worker - INFO -          dashboard at:          10.6.102.28:40121
2025-09-03 10:32:02,814 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,814 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,814 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,814 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,814 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-kfdn55hw
2025-09-03 10:32:02,814 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,815 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:44137
2025-09-03 10:32:02,815 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:44137
2025-09-03 10:32:02,815 - distributed.worker - INFO -          dashboard at:          10.6.102.28:44277
2025-09-03 10:32:02,815 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,816 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,816 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,816 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,816 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-maxzz5i_
2025-09-03 10:32:02,816 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,825 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:42633
2025-09-03 10:32:02,825 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:42633
2025-09-03 10:32:02,825 - distributed.worker - INFO -          dashboard at:          10.6.102.28:36441
2025-09-03 10:32:02,826 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,826 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,826 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,826 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,826 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-flx3prot
2025-09-03 10:32:02,826 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,834 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:43247
2025-09-03 10:32:02,834 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:43247
2025-09-03 10:32:02,834 - distributed.worker - INFO -          dashboard at:          10.6.102.28:43041
2025-09-03 10:32:02,834 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,834 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,834 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:02,834 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:02,834 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-jziiofh8
2025-09-03 10:32:02,834 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,147 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,148 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,148 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,150 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,162 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,163 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,163 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,164 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,239 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,240 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,240 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,242 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,253 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,255 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,255 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,256 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,269 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,270 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,270 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,272 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,315 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,316 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,316 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,318 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,330 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,331 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,332 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,333 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,345 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,347 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,347 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,348 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,361 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,362 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,362 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,363 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,377 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,378 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,378 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,380 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,392 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,393 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,394 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,395 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,459 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:35687
2025-09-03 10:32:03,459 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:35687
2025-09-03 10:32:03,459 - distributed.worker - INFO -          dashboard at:          10.6.102.28:39785
2025-09-03 10:32:03,459 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,459 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,459 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,459 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,459 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zhsfdlbb
2025-09-03 10:32:03,459 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,460 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:40981
2025-09-03 10:32:03,460 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:40981
2025-09-03 10:32:03,460 - distributed.worker - INFO -          dashboard at:          10.6.102.28:44067
2025-09-03 10:32:03,460 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,460 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,460 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,460 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,460 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-adt1x30p
2025-09-03 10:32:03,460 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,634 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,635 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,636 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,637 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,649 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,650 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,650 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,652 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,664 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,665 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,666 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,667 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,680 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,681 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,681 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,683 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,695 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,696 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,696 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,698 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,710 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,711 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,711 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,713 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,725 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,726 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,726 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,728 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,740 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,741 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,741 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,743 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,756 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,757 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,757 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,759 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,771 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,772 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,772 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,775 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,786 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,787 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,788 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,790 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,801 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,802 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,804 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,815 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,817 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,817 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,819 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,831 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,832 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,833 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,835 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,861 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,862 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,862 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,864 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,876 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,878 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,878 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,879 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,892 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,893 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,893 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,895 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,907 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,908 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,908 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,910 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,923 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,924 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,924 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,926 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,938 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,939 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,939 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,941 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,954 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,955 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,955 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,957 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,969 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,971 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,971 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,973 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:03,984 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:03,986 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,986 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,988 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,000 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,001 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,002 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,004 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,015 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,017 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,017 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,019 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,031 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,032 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,032 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,034 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,046 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,047 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,048 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,049 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,061 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,062 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,062 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,064 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,076 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,077 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,078 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,080 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,091 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,093 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,093 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,095 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,106 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,108 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,108 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,110 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,122 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,123 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,123 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,125 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,137 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,139 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,139 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,141 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,153 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,154 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,156 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,183 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,184 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,184 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,186 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,760 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,761 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,762 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,763 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,791 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,792 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,792 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,794 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:05,244 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:05,246 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:05,246 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:05,249 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:05,260 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:05,261 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:05,261 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:05,264 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:05,275 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:05,277 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:05,277 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:05,280 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:05,368 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:05,369 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:05,369 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:05,371 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:11,049 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:11,051 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:11,051 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,052 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:11,066 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:11,067 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:11,067 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,069 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:11,082 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:11,083 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:11,084 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,085 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:11,099 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:11,100 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:11,101 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,102 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:11,451 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:11,452 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:11,452 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,454 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:17,140 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:17,142 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:17,142 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:17,143 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:17,157 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:17,158 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:17,158 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:17,159 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:17,172 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:17,174 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:17,174 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:17,175 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:17,304 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:17,306 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:17,306 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:17,307 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:17,321 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:17,323 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:17,323 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:17,324 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:18,988 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:18,989 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,989 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:18,991 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:19,005 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:19,006 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,007 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:19,008 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:19,022 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:19,023 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,024 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:19,025 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:19,038 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:19,040 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,040 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:19,041 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:19,055 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:19,057 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,057 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:19,058 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:19,071 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:19,073 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,073 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:19,074 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:19,088 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:19,089 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,089 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:19,090 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:19,104 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:19,105 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,105 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:19,106 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:19,120 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:19,121 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,121 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:19,123 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:19,136 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:19,137 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,137 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:19,139 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:19,154 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:19,157 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,158 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:19,162 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:19,168 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:19,170 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,170 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:19,171 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:19,186 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:19,187 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,187 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:19,188 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:19,202 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:19,203 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,203 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:19,205 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:19,218 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:19,219 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,219 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:19,221 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:19,234 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:19,235 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,235 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:19,237 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:19,250 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:19,251 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,251 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:19,253 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:25,599 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:25,600 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:25,600 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:25,602 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:25,615 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:25,617 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:25,617 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:25,618 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:25,632 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:25,633 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:25,633 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:25,635 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:25,649 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:25,650 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:25,650 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:25,652 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:25,665 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:25,666 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:25,667 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:25,668 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:25,681 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:25,682 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:25,683 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:25,684 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:27,553 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:46713'
2025-09-03 10:32:27,557 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:35949'
2025-09-03 10:32:27,561 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:34173'
2025-09-03 10:32:27,562 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:46511'
2025-09-03 10:32:27,564 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:39973'
2025-09-03 10:32:27,567 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:37105'
2025-09-03 10:32:27,597 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.28:41995'
2025-09-03 10:32:28,422 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:37473
2025-09-03 10:32:28,422 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:37473
2025-09-03 10:32:28,422 - distributed.worker - INFO -          dashboard at:          10.6.102.28:35127
2025-09-03 10:32:28,422 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:28,422 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:28,422 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:28,422 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:28,422 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-m5qeu_d2
2025-09-03 10:32:28,422 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:28,427 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:45487
2025-09-03 10:32:28,427 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:45487
2025-09-03 10:32:28,427 - distributed.worker - INFO -          dashboard at:          10.6.102.28:37407
2025-09-03 10:32:28,427 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:28,427 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:28,427 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:28,427 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:28,427 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fjhncw7d
2025-09-03 10:32:28,427 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:28,428 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:44439
2025-09-03 10:32:28,428 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:44439
2025-09-03 10:32:28,428 - distributed.worker - INFO -          dashboard at:          10.6.102.28:44337
2025-09-03 10:32:28,428 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:28,428 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:28,428 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:28,428 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:28,428 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ywwlud80
2025-09-03 10:32:28,428 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:28,433 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:39109
2025-09-03 10:32:28,433 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:39109
2025-09-03 10:32:28,433 - distributed.worker - INFO -          dashboard at:          10.6.102.28:34241
2025-09-03 10:32:28,433 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:28,433 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:28,433 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:28,433 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:28,433 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-07_fz30u
2025-09-03 10:32:28,433 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:28,433 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:39343
2025-09-03 10:32:28,434 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:39343
2025-09-03 10:32:28,434 - distributed.worker - INFO -          dashboard at:          10.6.102.28:36053
2025-09-03 10:32:28,434 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:28,434 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:28,434 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:28,434 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:28,434 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-pw355t8d
2025-09-03 10:32:28,434 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:28,435 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:39923
2025-09-03 10:32:28,435 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:39923
2025-09-03 10:32:28,435 - distributed.worker - INFO -          dashboard at:          10.6.102.28:36025
2025-09-03 10:32:28,435 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:28,435 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:28,435 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:28,435 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:28,435 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-n9otpvo8
2025-09-03 10:32:28,435 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:28,451 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.28:40669
2025-09-03 10:32:28,451 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.28:40669
2025-09-03 10:32:28,451 - distributed.worker - INFO -          dashboard at:          10.6.102.28:46047
2025-09-03 10:32:28,451 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:28,451 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:28,451 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:28,451 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:28,451 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_umgdr7z
2025-09-03 10:32:28,451 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:31,309 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:34,725 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:34,740 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:34,757 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:35,777 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:36,276 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:36,291 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:40,158 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:40,159 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:40,160 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:40,161 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:50,004 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:50,022 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:50,039 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:50,055 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:50,073 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:50,087 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:58,423 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:58,427 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:58,429 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:58,434 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:58,435 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:58,436 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:58,453 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:58,583 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:58,585 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:58,585 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:58,586 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:58,605 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:58,607 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:58,607 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:58,608 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:58,624 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:58,625 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:58,626 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:58,627 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:58,642 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:58,643 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:58,643 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:58,644 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:58,659 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:58,661 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:58,661 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:58,662 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:58,677 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:58,678 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:58,678 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:58,679 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:58,766 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:58,767 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:58,767 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:58,768 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:35:51,109 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,112 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,677 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,682 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,880 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,885 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,058 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,061 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,068 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,073 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,032 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,037 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,089 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,095 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,134 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,139 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,146 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,147 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,151 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,152 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,157 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,161 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,162 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,163 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,169 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,175 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,315 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,316 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,359 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,362 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,402 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,407 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,532 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,534 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,576 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,581 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,641 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,645 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,894 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,900 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,011 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,017 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,047 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,050 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,244 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,250 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,266 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,267 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,328 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,334 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,352 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,357 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,385 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,391 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,401 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,408 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,444 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,454 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,857 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,863 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,957 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,963 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,990 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,991 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,146 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,155 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,223 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,229 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,428 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,434 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,463 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,468 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,756 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,758 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,783 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,784 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,817 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,823 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,885 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,890 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,013 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,018 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,065 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,070 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,123 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,127 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,129 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,130 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,175 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,181 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,265 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,268 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,337 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,343 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,353 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,357 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,620 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,622 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,672 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,675 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,708 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,712 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,713 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,713 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,716 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,717 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,737 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,744 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,840 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,845 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,989 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,994 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,028 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,034 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,035 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,038 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,161 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,169 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,234 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,242 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,577 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,579 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,609 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,615 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,656 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,659 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,709 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,715 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,742 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,745 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,763 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,766 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,110 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,113 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,174 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,179 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,342 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,344 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,346 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,348 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,456 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,461 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,721 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,727 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,883 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,890 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,102 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,103 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,460 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,463 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,670 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,674 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,912 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,918 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,958 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,963 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,144 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,153 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,236 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,241 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,247 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,254 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,264 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,269 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,538 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,541 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,542 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,546 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,731 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,733 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,901 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,906 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,017 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,019 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,075 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,080 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,251 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,254 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,077 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,082 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,119 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,120 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,254 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,259 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,943 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,948 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:03,274 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,277 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:03,297 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,302 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:03,675 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,678 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:03,754 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,758 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:04,617 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:04,619 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:04,661 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:04,667 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:04,736 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:04,742 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:07,408 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:07,410 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:12,080 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:12,085 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:13,732 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:13,738 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:14,552 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:14,559 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:22,885 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,886 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,898 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,899 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,907 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,908 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,915 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,916 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,933 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,935 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,939 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,940 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,947 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,947 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,949 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,950 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,956 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,960 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,407 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,408 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,409 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,409 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,495 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,497 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,499 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,500 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,502 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,506 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,506 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,505 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,507 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,506 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,507 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,509 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,511 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,512 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,526 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,531 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,537 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,538 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,539 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,540 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,552 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,554 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,556 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,560 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,560 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,562 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,562 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,563 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,572 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,573 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,787 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,789 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,797 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,799 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,833 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,835 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,835 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,837 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,837 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,839 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,847 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,849 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,850 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,854 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,853 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,858 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,866 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,868 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,890 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,890 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,892 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,894 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,896 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,898 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,898 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,900 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,910 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,911 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,020 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,022 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,024 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,026 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,031 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,033 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,063 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,065 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,066 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,066 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,067 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,068 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,071 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,071 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,072 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,073 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,086 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,088 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,098 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,099 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,113 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,115 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,121 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,122 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,125 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,124 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,126 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,128 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,128 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,130 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,233 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,235 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,240 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,241 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,240 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,244 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,395 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,397 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,399 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,399 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,400 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,400 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,434 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,436 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,448 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,453 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,460 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,462 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,498 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,500 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,511 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,512 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,579 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,584 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,585 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,586 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,586 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,587 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,594 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,596 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,662 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,664 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,668 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,670 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,670 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,675 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,682 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,684 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,749 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,750 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,759 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,760 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,789 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,791 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,864 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,865 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,895 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,895 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,896 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,897 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,919 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,921 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,930 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,930 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,931 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,932 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,969 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,970 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,971 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,972 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,014 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,015 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,015 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,021 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,071 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,073 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,435 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,437 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,454 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,455 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,487 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,490 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,512 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,514 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,545 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,547 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,647 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,649 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,707 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,712 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,717 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,718 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,866 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,868 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,979 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,981 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,030 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,032 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,084 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,086 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,228 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,231 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,307 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,309 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,345 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,348 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,470 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,471 - distributed.utils - INFO - Reload module qme_vars from .py file
