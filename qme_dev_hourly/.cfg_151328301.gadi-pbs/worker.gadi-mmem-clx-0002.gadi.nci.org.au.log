Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-10-01 11:07:44,558 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:34761'
2025-10-01 11:07:44,566 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:36341'
2025-10-01 11:07:44,569 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:36305'
2025-10-01 11:07:44,573 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:46523'
2025-10-01 11:07:44,577 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:40569'
2025-10-01 11:07:44,581 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:40875'
2025-10-01 11:07:44,585 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:33487'
2025-10-01 11:07:44,592 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:36881'
2025-10-01 11:07:44,597 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:38493'
2025-10-01 11:07:44,601 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:44399'
2025-10-01 11:07:44,606 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:41557'
2025-10-01 11:07:44,609 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:37627'
2025-10-01 11:07:44,614 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:33499'
2025-10-01 11:07:44,618 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:34087'
2025-10-01 11:07:44,622 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:36787'
2025-10-01 11:07:44,626 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:45903'
2025-10-01 11:07:44,630 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:45369'
2025-10-01 11:07:44,634 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:34521'
2025-10-01 11:07:44,638 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:44835'
2025-10-01 11:07:44,642 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:44249'
2025-10-01 11:07:44,646 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:33183'
2025-10-01 11:07:44,776 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:35193'
2025-10-01 11:07:44,781 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:35883'
2025-10-01 11:07:44,785 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:43569'
2025-10-01 11:07:44,789 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:45947'
2025-10-01 11:07:44,794 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:45249'
2025-10-01 11:07:44,799 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:41173'
2025-10-01 11:07:44,803 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:35409'
2025-10-01 11:07:44,807 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:44945'
2025-10-01 11:07:44,811 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:42807'
2025-10-01 11:07:44,815 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:33141'
2025-10-01 11:07:44,819 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:38585'
2025-10-01 11:07:44,823 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:35085'
2025-10-01 11:07:44,827 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:35961'
2025-10-01 11:07:44,832 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:41793'
2025-10-01 11:07:44,837 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:43499'
2025-10-01 11:07:44,840 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:32911'
2025-10-01 11:07:44,843 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:34999'
2025-10-01 11:07:44,847 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:37741'
2025-10-01 11:07:44,851 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:46641'
2025-10-01 11:07:44,855 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:40109'
2025-10-01 11:07:44,860 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:36619'
2025-10-01 11:07:44,864 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:39195'
2025-10-01 11:07:44,866 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:45985'
2025-10-01 11:07:44,868 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:41923'
2025-10-01 11:07:44,871 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:46009'
2025-10-01 11:07:44,876 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:34873'
2025-10-01 11:07:44,879 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.29:44855'
2025-10-01 11:07:45,929 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:43545
2025-10-01 11:07:45,929 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:36557
2025-10-01 11:07:45,929 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:43545
2025-10-01 11:07:45,929 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:36557
2025-10-01 11:07:45,929 - distributed.worker - INFO -          dashboard at:            10.6.5.29:32847
2025-10-01 11:07:45,929 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:44303
2025-10-01 11:07:45,929 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:41629
2025-10-01 11:07:45,929 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:33693
2025-10-01 11:07:45,929 - distributed.worker - INFO -          dashboard at:            10.6.5.29:44229
2025-10-01 11:07:45,929 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:45,929 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:35603
2025-10-01 11:07:45,929 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:44303
2025-10-01 11:07:45,929 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:41629
2025-10-01 11:07:45,929 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:45,929 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,929 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:33693
2025-10-01 11:07:45,929 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:35603
2025-10-01 11:07:45,929 - distributed.worker - INFO -          dashboard at:            10.6.5.29:37807
2025-10-01 11:07:45,929 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,929 - distributed.worker - INFO -          dashboard at:            10.6.5.29:40703
2025-10-01 11:07:45,929 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:45,929 - distributed.worker - INFO -          dashboard at:            10.6.5.29:41057
2025-10-01 11:07:45,929 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:45,929 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:45,929 - distributed.worker - INFO -          dashboard at:            10.6.5.29:33343
2025-10-01 11:07:45,929 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:45,929 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:45,929 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:45,929 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:45,929 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,929 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,929 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:45,929 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,929 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-3xu996aa
2025-10-01 11:07:45,929 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:45,929 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-lay_1yjo
2025-10-01 11:07:45,929 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:45,930 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,930 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:45,930 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:45,930 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,930 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:45,930 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:45,930 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,930 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:45,930 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-me9no3yc
2025-10-01 11:07:45,930 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:45,930 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-uvv3tti2
2025-10-01 11:07:45,930 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-pbm9e0ki
2025-10-01 11:07:45,930 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,930 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-9zpy0y45
2025-10-01 11:07:45,930 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,930 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,930 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,943 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:45,944 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:45,944 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,945 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:45,945 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:45,946 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:45,946 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,946 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:45,948 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:45,949 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:45,949 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,949 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:45,950 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:45,951 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:45,951 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:45,951 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,951 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:45,951 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,952 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:45,952 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:45,954 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:45,954 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:45,954 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,955 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:45,968 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:36669
2025-10-01 11:07:45,968 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:36669
2025-10-01 11:07:45,968 - distributed.worker - INFO -          dashboard at:            10.6.5.29:34349
2025-10-01 11:07:45,968 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:45,968 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,968 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:45,969 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:45,969 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-ybxpzbhs
2025-10-01 11:07:45,969 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,982 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:45,983 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:45,983 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:45,984 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,108 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:41653
2025-10-01 11:07:46,108 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:41653
2025-10-01 11:07:46,108 - distributed.worker - INFO -          dashboard at:            10.6.5.29:36867
2025-10-01 11:07:46,108 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,108 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,108 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,108 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,108 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-s89vikp6
2025-10-01 11:07:46,109 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,121 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,122 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,122 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,122 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,127 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:36343
2025-10-01 11:07:46,127 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:36343
2025-10-01 11:07:46,127 - distributed.worker - INFO -          dashboard at:            10.6.5.29:39997
2025-10-01 11:07:46,127 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,127 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,127 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,127 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,127 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-ahjmgpe0
2025-10-01 11:07:46,127 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,134 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:44123
2025-10-01 11:07:46,134 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:44123
2025-10-01 11:07:46,134 - distributed.worker - INFO -          dashboard at:            10.6.5.29:41679
2025-10-01 11:07:46,134 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,134 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,134 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,134 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,134 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-qsnevnaa
2025-10-01 11:07:46,135 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,138 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:44775
2025-10-01 11:07:46,138 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:44775
2025-10-01 11:07:46,138 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:45433
2025-10-01 11:07:46,138 - distributed.worker - INFO -          dashboard at:            10.6.5.29:33703
2025-10-01 11:07:46,138 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,138 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:45433
2025-10-01 11:07:46,138 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,138 - distributed.worker - INFO -          dashboard at:            10.6.5.29:42979
2025-10-01 11:07:46,138 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,139 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,139 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,139 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,139 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-fbqvu6vb
2025-10-01 11:07:46,139 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,139 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,139 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,139 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,139 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-hxh_taz3
2025-10-01 11:07:46,139 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,139 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,139 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,140 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,149 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,150 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,150 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,150 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,151 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,152 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,152 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:42219
2025-10-01 11:07:46,152 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,152 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:42219
2025-10-01 11:07:46,152 - distributed.worker - INFO -          dashboard at:            10.6.5.29:39277
2025-10-01 11:07:46,152 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,152 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,152 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,152 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,152 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-05r1zk62
2025-10-01 11:07:46,152 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,153 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,155 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,155 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,155 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,156 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,169 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,170 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,170 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,171 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,177 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:36243
2025-10-01 11:07:46,177 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:36243
2025-10-01 11:07:46,177 - distributed.worker - INFO -          dashboard at:            10.6.5.29:43761
2025-10-01 11:07:46,177 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,177 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,177 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,177 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,177 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-q7drmjav
2025-10-01 11:07:46,177 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,185 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:43751
2025-10-01 11:07:46,186 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:43751
2025-10-01 11:07:46,186 - distributed.worker - INFO -          dashboard at:            10.6.5.29:45143
2025-10-01 11:07:46,186 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,186 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,186 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,186 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,186 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-98k2synp
2025-10-01 11:07:46,186 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,195 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:39219
2025-10-01 11:07:46,196 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:39219
2025-10-01 11:07:46,196 - distributed.worker - INFO -          dashboard at:            10.6.5.29:41905
2025-10-01 11:07:46,196 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,196 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,196 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,196 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,196 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-2b20an5r
2025-10-01 11:07:46,196 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,197 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,198 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,198 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,199 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:46457
2025-10-01 11:07:46,199 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:46457
2025-10-01 11:07:46,199 - distributed.worker - INFO -          dashboard at:            10.6.5.29:43387
2025-10-01 11:07:46,199 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,199 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,199 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,199 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,199 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-ijivqs69
2025-10-01 11:07:46,199 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,199 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,207 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,208 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,208 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,209 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,209 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:38507
2025-10-01 11:07:46,209 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:38507
2025-10-01 11:07:46,209 - distributed.worker - INFO -          dashboard at:            10.6.5.29:33057
2025-10-01 11:07:46,209 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,209 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,210 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,210 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,210 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-g2pr79de
2025-10-01 11:07:46,210 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,210 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:43407
2025-10-01 11:07:46,210 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:43407
2025-10-01 11:07:46,211 - distributed.worker - INFO -          dashboard at:            10.6.5.29:40149
2025-10-01 11:07:46,211 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,211 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,211 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,211 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,211 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-j0vbiv4s
2025-10-01 11:07:46,211 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,217 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,218 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,218 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,219 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,220 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,221 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,221 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,222 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,222 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,222 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,222 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,223 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:35641
2025-10-01 11:07:46,223 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:35641
2025-10-01 11:07:46,223 - distributed.worker - INFO -          dashboard at:            10.6.5.29:37987
2025-10-01 11:07:46,223 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,223 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,223 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,223 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,223 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-3n96gide
2025-10-01 11:07:46,223 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,223 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,230 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,231 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,231 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,232 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,235 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,235 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,235 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,236 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,252 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:41213
2025-10-01 11:07:46,252 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:41213
2025-10-01 11:07:46,252 - distributed.worker - INFO -          dashboard at:            10.6.5.29:33551
2025-10-01 11:07:46,252 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,252 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,252 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,252 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,252 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-vlt5xckx
2025-10-01 11:07:46,252 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,264 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:41333
2025-10-01 11:07:46,264 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:41333
2025-10-01 11:07:46,264 - distributed.worker - INFO -          dashboard at:            10.6.5.29:35385
2025-10-01 11:07:46,264 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,264 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,264 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,264 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,264 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-9awjax94
2025-10-01 11:07:46,265 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,268 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,269 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,269 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,270 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,285 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:39623
2025-10-01 11:07:46,285 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:39623
2025-10-01 11:07:46,285 - distributed.worker - INFO -          dashboard at:            10.6.5.29:37407
2025-10-01 11:07:46,285 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,286 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,286 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,286 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,286 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-knel9zdz
2025-10-01 11:07:46,286 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,286 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,287 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,287 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,288 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,298 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,298 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,298 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,299 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,352 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:41851
2025-10-01 11:07:46,352 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:41851
2025-10-01 11:07:46,352 - distributed.worker - INFO -          dashboard at:            10.6.5.29:34071
2025-10-01 11:07:46,352 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,352 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,352 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,352 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,352 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-4srhiiem
2025-10-01 11:07:46,352 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,372 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,373 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,373 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,374 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,392 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:40505
2025-10-01 11:07:46,392 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:40505
2025-10-01 11:07:46,392 - distributed.worker - INFO -          dashboard at:            10.6.5.29:40791
2025-10-01 11:07:46,392 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,392 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,392 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,392 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,392 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-4x915hhr
2025-10-01 11:07:46,392 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,412 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,413 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,413 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,414 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,428 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:40833
2025-10-01 11:07:46,428 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:40833
2025-10-01 11:07:46,428 - distributed.worker - INFO -          dashboard at:            10.6.5.29:39409
2025-10-01 11:07:46,428 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,429 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,429 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,429 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,429 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-qsk6bnl0
2025-10-01 11:07:46,429 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,431 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:44085
2025-10-01 11:07:46,431 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:44085
2025-10-01 11:07:46,432 - distributed.worker - INFO -          dashboard at:            10.6.5.29:42417
2025-10-01 11:07:46,432 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,432 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,432 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,432 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,432 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-jj3tr7b9
2025-10-01 11:07:46,432 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,432 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:41997
2025-10-01 11:07:46,432 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:41997
2025-10-01 11:07:46,432 - distributed.worker - INFO -          dashboard at:            10.6.5.29:46045
2025-10-01 11:07:46,432 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,433 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,433 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,433 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,433 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-lnxhzede
2025-10-01 11:07:46,433 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,440 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:41243
2025-10-01 11:07:46,440 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:41243
2025-10-01 11:07:46,440 - distributed.worker - INFO -          dashboard at:            10.6.5.29:45103
2025-10-01 11:07:46,440 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,440 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,440 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,440 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,440 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-l2fo1456
2025-10-01 11:07:46,440 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,444 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,445 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,445 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,445 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,450 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,451 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,451 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:40585
2025-10-01 11:07:46,451 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:40585
2025-10-01 11:07:46,451 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,451 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:36995
2025-10-01 11:07:46,451 - distributed.worker - INFO -          dashboard at:            10.6.5.29:37087
2025-10-01 11:07:46,451 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:36995
2025-10-01 11:07:46,451 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,451 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,451 - distributed.worker - INFO -          dashboard at:            10.6.5.29:43627
2025-10-01 11:07:46,451 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,451 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,451 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,451 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,451 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,451 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-w_7tk3bw
2025-10-01 11:07:46,451 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,451 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,451 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-vwdnowz8
2025-10-01 11:07:46,451 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,452 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,452 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,452 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,452 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,453 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,453 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:43351
2025-10-01 11:07:46,454 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:43351
2025-10-01 11:07:46,454 - distributed.worker - INFO -          dashboard at:            10.6.5.29:38953
2025-10-01 11:07:46,454 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,454 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,454 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,454 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,454 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-3fum880v
2025-10-01 11:07:46,454 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,454 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:38001
2025-10-01 11:07:46,454 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:38001
2025-10-01 11:07:46,454 - distributed.worker - INFO -          dashboard at:            10.6.5.29:44939
2025-10-01 11:07:46,454 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,454 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,454 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,454 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,454 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-40e_1so3
2025-10-01 11:07:46,454 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,455 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,455 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,455 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,456 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,459 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:42215
2025-10-01 11:07:46,459 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:42215
2025-10-01 11:07:46,459 - distributed.worker - INFO -          dashboard at:            10.6.5.29:40269
2025-10-01 11:07:46,459 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,459 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,459 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,459 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,459 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-rcc36mrx
2025-10-01 11:07:46,459 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,460 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:46679
2025-10-01 11:07:46,460 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:46679
2025-10-01 11:07:46,460 - distributed.worker - INFO -          dashboard at:            10.6.5.29:45077
2025-10-01 11:07:46,460 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,460 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,460 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,460 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,460 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-4y463w3i
2025-10-01 11:07:46,460 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,463 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:40571
2025-10-01 11:07:46,463 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:40571
2025-10-01 11:07:46,463 - distributed.worker - INFO -          dashboard at:            10.6.5.29:33747
2025-10-01 11:07:46,463 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,463 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,463 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,463 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,463 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-em19sm67
2025-10-01 11:07:46,463 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,464 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:45297
2025-10-01 11:07:46,464 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:45297
2025-10-01 11:07:46,464 - distributed.worker - INFO -          dashboard at:            10.6.5.29:44561
2025-10-01 11:07:46,464 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,464 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,464 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,464 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,464 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-kr4h7x07
2025-10-01 11:07:46,464 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,465 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,465 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,465 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,466 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:41893
2025-10-01 11:07:46,466 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:41893
2025-10-01 11:07:46,466 - distributed.worker - INFO -          dashboard at:            10.6.5.29:39319
2025-10-01 11:07:46,466 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,466 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,466 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,466 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,466 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,466 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-1qrkubmg
2025-10-01 11:07:46,466 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,467 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,468 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,468 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,469 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,469 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,469 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,469 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,470 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,470 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:41515
2025-10-01 11:07:46,470 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:41515
2025-10-01 11:07:46,470 - distributed.worker - INFO -          dashboard at:            10.6.5.29:38095
2025-10-01 11:07:46,471 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,471 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,471 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,471 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,471 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-ptrs3zf4
2025-10-01 11:07:46,471 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,473 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,474 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,474 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,474 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,474 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:39211
2025-10-01 11:07:46,474 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:39211
2025-10-01 11:07:46,474 - distributed.worker - INFO -          dashboard at:            10.6.5.29:40337
2025-10-01 11:07:46,474 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,474 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,475 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,475 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,475 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-f50g9h93
2025-10-01 11:07:46,475 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,475 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:44657
2025-10-01 11:07:46,475 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:44657
2025-10-01 11:07:46,475 - distributed.worker - INFO -          dashboard at:            10.6.5.29:43053
2025-10-01 11:07:46,475 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,475 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,475 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,475 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,475 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-s8up87_7
2025-10-01 11:07:46,476 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,475 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,476 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,476 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,477 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:46291
2025-10-01 11:07:46,477 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:46291
2025-10-01 11:07:46,477 - distributed.worker - INFO -          dashboard at:            10.6.5.29:34415
2025-10-01 11:07:46,477 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,477 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,477 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,477 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,477 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-mzke6hvp
2025-10-01 11:07:46,477 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,477 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,478 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,478 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,479 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,479 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:42329
2025-10-01 11:07:46,479 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:42329
2025-10-01 11:07:46,479 - distributed.worker - INFO -          dashboard at:            10.6.5.29:45529
2025-10-01 11:07:46,479 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,479 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,479 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,479 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,479 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-f6sifvz3
2025-10-01 11:07:46,479 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,480 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,481 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,482 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,482 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,482 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:45391
2025-10-01 11:07:46,482 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:45391
2025-10-01 11:07:46,482 - distributed.worker - INFO -          dashboard at:            10.6.5.29:41433
2025-10-01 11:07:46,482 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,482 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,482 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,482 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,482 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-08j7npnq
2025-10-01 11:07:46,482 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,483 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,483 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,484 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,484 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,485 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,486 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,487 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,487 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,487 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,487 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,487 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,488 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,488 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:34263
2025-10-01 11:07:46,488 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:34263
2025-10-01 11:07:46,488 - distributed.worker - INFO -          dashboard at:            10.6.5.29:45571
2025-10-01 11:07:46,488 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,488 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,488 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,488 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,488 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-r_wk564s
2025-10-01 11:07:46,488 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,488 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,490 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,490 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,490 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,491 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,493 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,493 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,494 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,495 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,495 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,496 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,496 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,496 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,496 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:40159
2025-10-01 11:07:46,497 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:40159
2025-10-01 11:07:46,497 - distributed.worker - INFO -          dashboard at:            10.6.5.29:37457
2025-10-01 11:07:46,497 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,497 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,497 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,497 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,497 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-hdl9ao_s
2025-10-01 11:07:46,497 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,497 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,497 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,497 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,498 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,501 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,502 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,502 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,503 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,507 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,508 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,508 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,509 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,510 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,510 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,510 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,510 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,526 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:42195
2025-10-01 11:07:46,526 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:42195
2025-10-01 11:07:46,526 - distributed.worker - INFO -          dashboard at:            10.6.5.29:36065
2025-10-01 11:07:46,526 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,526 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,526 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,526 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,526 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-17x5dxm5
2025-10-01 11:07:46,526 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,545 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,546 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,546 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,547 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:46,565 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.29:46079
2025-10-01 11:07:46,566 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.29:46079
2025-10-01 11:07:46,566 - distributed.worker - INFO -          dashboard at:            10.6.5.29:44323
2025-10-01 11:07:46,566 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,566 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,566 - distributed.worker - INFO -               Threads:                          1
2025-10-01 11:07:46,566 - distributed.worker - INFO -                Memory:                  62.29 GiB
2025-10-01 11:07:46,566 - distributed.worker - INFO -       Local Directory: /jobfs/151328301.gadi-pbs/dask-scratch-space/worker-r1nho7uu
2025-10-01 11:07:46,566 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,577 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:07:46,577 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.28:8715
2025-10-01 11:07:46,577 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:07:46,578 - distributed.core - INFO - Starting established connection to tcp://10.6.5.28:8715
2025-10-01 11:07:51,373 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,373 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,374 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,374 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,374 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,375 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,375 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,375 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,375 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,375 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,375 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,375 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,375 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,376 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,376 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,376 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,376 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,376 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,377 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,377 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,377 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,377 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,377 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,377 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,378 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,378 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,378 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,378 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,379 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,379 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,379 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,379 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,379 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,379 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,380 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,380 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,380 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,380 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,380 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,381 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,381 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,381 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,381 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,381 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,380 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,381 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,381 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,382 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,382 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,382 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,382 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,382 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,383 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,383 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,383 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,383 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,383 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,384 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,384 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,384 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,384 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,384 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,385 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,385 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,385 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,385 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,385 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,385 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,386 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,386 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,386 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,386 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,386 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,386 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,387 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,387 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,387 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,387 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,387 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,387 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,387 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,387 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,387 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,387 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,387 - distributed.worker - INFO - Starting Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:07:51,388 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,388 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,388 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,388 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,388 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,388 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,388 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,388 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,389 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,390 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:51,390 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:07:53,639 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,639 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,639 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,640 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,640 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,640 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,640 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,641 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,641 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,641 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,641 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,641 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,642 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,641 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,642 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,641 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,642 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,642 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,641 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,642 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,642 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,642 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,642 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,643 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,642 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,643 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,643 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,642 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,643 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,643 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,643 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,643 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,643 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,643 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,644 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,644 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,644 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,642 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,643 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,644 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,644 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,644 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,644 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,644 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,644 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,644 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,645 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,645 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,645 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,645 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,645 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,645 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,646 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,646 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,646 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,645 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,645 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,646 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,646 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,646 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,646 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,647 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,646 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,647 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,647 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,647 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,647 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,647 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,645 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,647 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,648 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,647 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,647 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,648 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,648 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,648 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,648 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,647 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,648 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,649 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,649 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,649 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,648 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,648 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,649 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,649 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,649 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,649 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,646 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,649 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,649 - distributed.worker - INFO - Starting Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:07:53,650 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,650 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,650 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,650 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,651 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:07:53,693 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,693 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,693 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,693 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,693 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,694 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,694 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,694 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,694 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,695 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,695 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,695 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,695 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,695 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,695 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,695 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,695 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,695 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,696 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,696 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,696 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,696 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,696 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,696 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,696 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,696 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,696 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,697 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,697 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,697 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,697 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,697 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,697 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,697 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,697 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,697 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,698 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,698 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,698 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,698 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,698 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,698 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,698 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,698 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,698 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,698 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,699 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,699 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,699 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,699 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,700 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,699 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,700 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,700 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,700 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,700 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,700 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,700 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,700 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,700 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,701 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,701 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,701 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,701 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,701 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,701 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,701 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,701 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,701 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,701 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,702 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,702 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,701 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,702 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,702 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,702 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,702 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,703 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,702 - distributed.worker - INFO - Starting Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:07:53,703 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,702 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,703 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,703 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,703 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,704 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,704 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,704 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,704 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,705 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,705 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,706 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:07:53,760 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,760 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,760 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,760 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,761 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,761 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,761 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,761 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,761 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,761 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,761 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,762 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,761 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,761 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,762 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,762 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,762 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,762 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,762 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,762 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,762 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,762 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,763 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,763 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,763 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,763 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,763 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,763 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,763 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,763 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,763 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,763 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,763 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,763 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,764 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,764 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,764 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,764 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,764 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,764 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,764 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,764 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,764 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,764 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,764 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,765 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,765 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,765 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,765 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,765 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,765 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,765 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,765 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,766 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,766 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,766 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,766 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,766 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,766 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,766 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,766 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,766 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,766 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,766 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,767 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,767 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,767 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,767 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,767 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,767 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,767 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,767 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,767 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,768 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,767 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,768 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,768 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,768 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,768 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,768 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,768 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,768 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,769 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,769 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,769 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,769 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,769 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,769 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,769 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,769 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,769 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:07:53,770 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,770 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,770 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,770 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:07:53,770 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:59:29,642 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:36557. Reason: scheduler-close
2025-10-01 11:59:29,642 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:35603. Reason: scheduler-close
2025-10-01 11:59:29,642 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:36343. Reason: scheduler-close
2025-10-01 11:59:29,642 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:42219. Reason: scheduler-close
2025-10-01 11:59:29,642 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:36669. Reason: scheduler-close
2025-10-01 11:59:29,642 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:44123. Reason: scheduler-close
2025-10-01 11:59:29,642 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:43407. Reason: scheduler-close
2025-10-01 11:59:29,642 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:41653. Reason: scheduler-close
2025-10-01 11:59:29,642 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:45433. Reason: scheduler-close
2025-10-01 11:59:29,642 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:44775. Reason: scheduler-close
2025-10-01 11:59:29,642 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:44303. Reason: scheduler-close
2025-10-01 11:59:29,643 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:35641. Reason: scheduler-close
2025-10-01 11:59:29,643 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:41213. Reason: scheduler-close
2025-10-01 11:59:29,643 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:43751. Reason: scheduler-close
2025-10-01 11:59:29,643 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:41333. Reason: scheduler-close
2025-10-01 11:59:29,643 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:41893. Reason: scheduler-close
2025-10-01 11:59:29,643 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:36243. Reason: scheduler-close
2025-10-01 11:59:29,643 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:36995. Reason: scheduler-close
2025-10-01 11:59:29,643 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:41997. Reason: scheduler-close
2025-10-01 11:59:29,643 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:41629. Reason: scheduler-close
2025-10-01 11:59:29,643 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:41243. Reason: scheduler-close
2025-10-01 11:59:29,643 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:45297. Reason: scheduler-close
2025-10-01 11:59:29,643 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:42215. Reason: scheduler-close
2025-10-01 11:59:29,643 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:41851. Reason: scheduler-close
2025-10-01 11:59:29,643 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:40833. Reason: scheduler-close
2025-10-01 11:59:29,644 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:45391. Reason: scheduler-close
2025-10-01 11:59:29,644 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:40571. Reason: scheduler-close
2025-10-01 11:59:29,644 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:42329. Reason: scheduler-close
2025-10-01 11:59:29,644 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:39211. Reason: scheduler-close
2025-10-01 11:59:29,644 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:46679. Reason: scheduler-close
2025-10-01 11:59:29,644 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:41515. Reason: scheduler-close
2025-10-01 11:59:29,645 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:42195. Reason: scheduler-close
2025-10-01 11:59:29,646 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:34263. Reason: scheduler-close
2025-10-01 11:59:29,646 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:43351. Reason: scheduler-close
2025-10-01 11:59:29,646 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:46291. Reason: scheduler-close
2025-10-01 11:59:29,646 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:44657. Reason: scheduler-close
2025-10-01 11:59:29,646 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:40585. Reason: scheduler-close
2025-10-01 11:59:29,647 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:38001. Reason: scheduler-close
2025-10-01 11:59:29,648 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:39623. Reason: scheduler-close
2025-10-01 11:59:29,648 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:44085. Reason: scheduler-close
2025-10-01 11:59:29,654 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:34761'. Reason: scheduler-close
2025-10-01 11:59:29,657 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 124, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,657 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,657 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,658 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,658 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,658 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,663 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:39219. Reason: scheduler-close
2025-10-01 11:59:29,665 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:44249'. Reason: scheduler-close
2025-10-01 11:59:29,665 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:36881'. Reason: scheduler-close
2025-10-01 11:59:29,666 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:36341'. Reason: scheduler-close
2025-10-01 11:59:29,666 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 217, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,666 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:34521'. Reason: scheduler-close
2025-10-01 11:59:29,666 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 12, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,666 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:34087'. Reason: scheduler-close
2025-10-01 11:59:29,667 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,667 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,667 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:36305'. Reason: scheduler-close
2025-10-01 11:59:29,667 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 91, 119, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,667 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,667 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,667 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:35085'. Reason: scheduler-close
2025-10-01 11:59:29,667 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 17, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,667 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 39, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,667 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:46457. Reason: scheduler-close
2025-10-01 11:59:29,690 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,668 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 201, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,690 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,668 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:38507. Reason: scheduler-close
2025-10-01 11:59:29,690 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,675 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:40505. Reason: scheduler-close
2025-10-01 11:59:29,690 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,690 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,690 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:41557'. Reason: scheduler-close
2025-10-01 11:59:29,690 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,690 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,691 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,691 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,691 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,691 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,691 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,691 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,691 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,691 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,691 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:33183'. Reason: scheduler-close
2025-10-01 11:59:29,691 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,691 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,691 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,691 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,691 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,691 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,691 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 135, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,691 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,691 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,692 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,691 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:45369'. Reason: scheduler-close
2025-10-01 11:59:29,692 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,692 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,692 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,692 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,692 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:36787'. Reason: scheduler-close
2025-10-01 11:59:29,692 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,692 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 165, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,692 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 220, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,692 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,692 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,693 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,693 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:35193'. Reason: scheduler-close
2025-10-01 11:59:29,693 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,693 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,693 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,693 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:45903'. Reason: scheduler-close
2025-10-01 11:59:29,693 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,693 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,693 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,693 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 47, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,694 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,694 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,694 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:33487'. Reason: scheduler-close
2025-10-01 11:59:29,694 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,694 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 198, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,694 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 184, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,694 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,694 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:44855'. Reason: scheduler-close
2025-10-01 11:59:29,695 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,695 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,695 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 49, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,695 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,695 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,695 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:46009'. Reason: scheduler-close
2025-10-01 11:59:29,695 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,695 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,695 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,695 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,695 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,695 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,695 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,695 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,695 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,696 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,695 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:45947'. Reason: scheduler-close
2025-10-01 11:59:29,696 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 119, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,696 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,696 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,696 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,696 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 175, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,696 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,696 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,696 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,696 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:41923'. Reason: scheduler-close
2025-10-01 11:59:29,697 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,697 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,697 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,697 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,697 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,697 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 199, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,697 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 172, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,698 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,698 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,698 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,698 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,698 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,698 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,698 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 26, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,699 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,699 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,699 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,699 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,699 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,699 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,699 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,700 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,700 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,700 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,700 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,700 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,700 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,712 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:35409'. Reason: scheduler-close
2025-10-01 11:59:29,713 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:37627'. Reason: scheduler-close
2025-10-01 11:59:29,713 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:37741'. Reason: scheduler-close
2025-10-01 11:59:29,714 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 116, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,714 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:34873'. Reason: scheduler-close
2025-10-01 11:59:29,714 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 152, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,714 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:41173'. Reason: scheduler-close
2025-10-01 11:59:29,714 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,714 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,714 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:36619'. Reason: scheduler-close
2025-10-01 11:59:29,715 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,715 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,715 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 41, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,715 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:40875'. Reason: scheduler-close
2025-10-01 11:59:29,715 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,715 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,715 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,715 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 161, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,715 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 162, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,715 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,715 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,715 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:43499'. Reason: scheduler-close
2025-10-01 11:59:29,715 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,716 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 151, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,716 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,716 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,716 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:42807'. Reason: scheduler-close
2025-10-01 11:59:29,716 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,716 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,716 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,716 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:45985'. Reason: scheduler-close
2025-10-01 11:59:29,716 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,716 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,716 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,716 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,716 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,716 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,716 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:41793'. Reason: scheduler-close
2025-10-01 11:59:29,716 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,716 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 197, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,716 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,716 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,716 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,717 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:43569'. Reason: scheduler-close
2025-10-01 11:59:29,717 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,717 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,717 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,717 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,717 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,717 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:46641'. Reason: scheduler-close
2025-10-01 11:59:29,717 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,717 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 183, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,717 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,717 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:32911'. Reason: scheduler-close
2025-10-01 11:59:29,717 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,717 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,717 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,717 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,717 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 118, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,717 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:44945'. Reason: scheduler-close
2025-10-01 11:59:29,717 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 51, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,718 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:35961'. Reason: scheduler-close
2025-10-01 11:59:29,718 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 3, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,718 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,718 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,718 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:40109'. Reason: scheduler-close
2025-10-01 11:59:29,718 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,718 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 20, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,718 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,718 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,718 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 212, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,718 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,718 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,719 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:33693. Reason: scheduler-close
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,719 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 34, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,719 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 191, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,719 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,720 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,720 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,720 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,720 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,720 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,720 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,720 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,720 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 187, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,720 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,721 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,721 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,721 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,721 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,721 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,721 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,722 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,722 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,722 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 56, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,722 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,723 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,723 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,723 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,723 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,723 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,723 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:38585'. Reason: scheduler-close
2025-10-01 11:59:29,724 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:44399'. Reason: scheduler-close
2025-10-01 11:59:29,724 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:35883'. Reason: scheduler-close
2025-10-01 11:59:29,724 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:46079. Reason: scheduler-close
2025-10-01 11:59:29,724 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:45249'. Reason: scheduler-close
2025-10-01 11:59:29,725 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,725 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 134, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,725 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,725 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,725 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,725 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,726 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,726 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('vectorize_apply-vectorize_apply_0-store-map-ddb80650b632d8e0d7f83cf1ce62a76c', 90, 193, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,726 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,726 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,726 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,726 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,726 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,727 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,727 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,727 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,727 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,727 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,728 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,728 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,728 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,728 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,721 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.5.29:49146 remote=tcp://10.6.5.28:8715>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.5.29:49146 remote=tcp://10.6.5.28:8715>: Stream is closed
2025-10-01 11:59:29,735 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:46523'. Reason: scheduler-close
2025-10-01 11:59:29,729 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.5.29:49576 remote=tcp://10.6.5.28:8715>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.5.29:49576 remote=tcp://10.6.5.28:8715>: Stream is closed
2025-10-01 11:59:29,736 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:34999'. Reason: scheduler-close
2025-10-01 11:59:29,738 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-rechunk-merge-vectorize_count_dist-vectorize_count_dist_0-transpose-8854610993b5b7d39b0538fb4dd50b88', 90, 104, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,738 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,739 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,739 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,739 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,739 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,735 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.5.29:49266 remote=tcp://10.6.5.28:8715>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.5.29:49266 remote=tcp://10.6.5.28:8715>: Stream is closed
2025-10-01 11:59:29,741 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:44835'. Reason: scheduler-close
2025-10-01 11:59:29,738 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.5.29:49290 remote=tcp://10.6.5.28:8715>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.5.29:49290 remote=tcp://10.6.5.28:8715>: Stream is closed
2025-10-01 11:59:29,743 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:33499'. Reason: scheduler-close
2025-10-01 11:59:29,748 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-rechunk-merge-vectorize_count_dist-vectorize_count_dist_0-transpose-8854610993b5b7d39b0538fb4dd50b88', 90, 110, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,748 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,748 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,748 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,748 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,748 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,752 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:43545. Reason: scheduler-close
2025-10-01 11:59:29,758 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-rechunk-merge-vectorize_count_dist-vectorize_count_dist_0-transpose-8854610993b5b7d39b0538fb4dd50b88', 90, 112, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,758 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,759 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,759 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,759 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,759 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,755 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.5.29:49116 remote=tcp://10.6.5.28:8715>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.5.29:49116 remote=tcp://10.6.5.28:8715>: Stream is closed
2025-10-01 11:59:29,755 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.5.29:49282 remote=tcp://10.6.5.28:8715>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.5.29:49282 remote=tcp://10.6.5.28:8715>: Stream is closed
2025-10-01 11:59:29,759 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:40569'. Reason: scheduler-close
2025-10-01 11:59:29,760 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:38493'. Reason: scheduler-close
2025-10-01 11:59:29,769 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:29,770 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:29,772 - distributed.worker - INFO - Stopping worker at tcp://10.6.5.29:40159. Reason: scheduler-close
2025-10-01 11:59:29,782 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:29,783 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:29,785 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-rechunk-merge-vectorize_count_dist-vectorize_count_dist_0-transpose-c5516e166d356e92094c155f79e441ec', 90, 182, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,786 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,786 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,786 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,786 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,786 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,786 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-rechunk-merge-vectorize_count_dist-vectorize_count_dist_0-transpose-c5516e166d356e92094c155f79e441ec', 90, 101, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,787 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,787 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,787 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,787 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,787 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,792 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-rechunk-merge-vectorize_count_dist-vectorize_count_dist_0-transpose-c5516e166d356e92094c155f79e441ec', 90, 18, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,793 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,793 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,793 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,793 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,793 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,778 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.5.29:49554 remote=tcp://10.6.5.28:8715>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.5.29:49554 remote=tcp://10.6.5.28:8715>: Stream is closed
2025-10-01 11:59:29,800 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:39195'. Reason: scheduler-close
2025-10-01 11:59:29,766 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.5.29:49370 remote=tcp://10.6.5.28:8715>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.5.29:49370 remote=tcp://10.6.5.28:8715>: Stream is closed
2025-10-01 11:59:29,835 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.5.29:33141'. Reason: scheduler-close
2025-10-01 11:59:29,849 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-rechunk-merge-vectorize_count_dist-vectorize_count_dist_0-transpose-8854610993b5b7d39b0538fb4dd50b88', 90, 106, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,854 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,860 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,865 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,870 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,871 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:29,873 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-rechunk-merge-vectorize_count_dist-vectorize_count_dist_0-transpose-8854610993b5b7d39b0538fb4dd50b88', 90, 108, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-01 11:59:29,875 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 11:59:29,875 - distributed.worker - INFO - Removing Worker plugin qme_utils.py9a67029b-27f2-484d-a7cd-ef3e2d7cad1b
2025-10-01 11:59:29,875 - distributed.worker - INFO - Removing Worker plugin qme_vars.py372f3706-9023-44e1-8789-f143fd7bb370
2025-10-01 11:59:29,875 - distributed.worker - INFO - Removing Worker plugin qme_train.pya0f0b3f8-620d-4835-bd83-6034f749f4ca
2025-10-01 11:59:29,875 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfec99a5d-7a9f-452e-b70d-0fbbdb9af790
2025-10-01 11:59:30,301 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:30,303 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:30,480 - distributed.semaphore - ERROR - Release failed for id=5502d7fd574149718d674a7b9407d3df, lease_id=30c6b4d47bc3462b98de52b96ff061d8, name=/g/data/xv83/users/at2708/bias_adjustment_acs_qme/qme_dev_copy_hourly/outputs_netcdf20/BOM/ACCESS-CM2/historical/r4i1p1f1/BARPA-R/v1-r1-ACS-QME-BARRAR2-1980-2022/1hr/tasAdjust/v20250311/tasAdjust_AUST-20i_ACCESS-CM2_historical_r4i1p1f1_BOM_BARPA-R_v1-r1-ACS-QME-BARRAR2-1980-2022_day_19600101-19601231.nc. Cluster network might be unstable?
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/semaphore.py", line 486, in _release
    await retry_operation(
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1456, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2025-10-01 11:59:30,529 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:30,534 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:31,168 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:31,170 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:31,951 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:31,954 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,313 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,314 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,369 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,371 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,373 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,376 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,437 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,440 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,456 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,459 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,462 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,466 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,464 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,468 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,471 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,473 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,476 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,480 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,484 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,486 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,484 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,489 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,496 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,497 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,499 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,502 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,505 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,508 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,512 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,515 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,515 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,518 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,520 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,522 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,524 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,527 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,539 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:32,542 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,545 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,575 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,579 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,614 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,617 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,641 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,645 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,697 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,700 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,704 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,706 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,719 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,718 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,721 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,721 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,724 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,726 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,726 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,728 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,726 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,728 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,737 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,739 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,737 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,740 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,742 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,746 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,743 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,747 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,752 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,755 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,757 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,765 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,765 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,770 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,777 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,780 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:32,773 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:32,781 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:33,022 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:33,024 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:33,605 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:44399'. Reason: nanny-close-gracefully
2025-10-01 11:59:33,609 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:44399' closed.
2025-10-01 11:59:33,612 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:45249'. Reason: nanny-close-gracefully
2025-10-01 11:59:33,614 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:45249' closed.
2025-10-01 11:59:34,004 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:33499'. Reason: nanny-close-gracefully
2025-10-01 11:59:34,011 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:33499' closed.
2025-10-01 11:59:34,292 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:34,293 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:34,327 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:34,381 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:34,464 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:34,473 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:34,490 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:34,495 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:34,500 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:34,506 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:34,512 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:34,523 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:34,526 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:34,553 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:41793'. Reason: nanny-close-gracefully
2025-10-01 11:59:34,554 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:41793' closed.
2025-10-01 11:59:34,587 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:34,621 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:34,652 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:34,732 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:34,733 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:34,743 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:34,753 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:34,771 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:34,912 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:34,914 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:34,938 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:33141'. Reason: nanny-close-gracefully
2025-10-01 11:59:34,939 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:33141' closed.
2025-10-01 11:59:35,502 - distributed.core - INFO - Received 'close-stream' from tcp://10.6.5.28:8715; closing.
2025-10-01 11:59:35,508 - distributed.nanny - INFO - Worker closed
2025-10-01 11:59:36,298 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:36,324 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:39195'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,325 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:39195' closed.
2025-10-01 11:59:36,468 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:34521'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,470 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:34521' closed.
2025-10-01 11:59:36,509 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:35085'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,510 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:35085' closed.
2025-10-01 11:59:36,524 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:35883'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,533 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:35883' closed.
2025-10-01 11:59:36,533 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:43499'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,534 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:43499' closed.
2025-10-01 11:59:36,547 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:37741'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,547 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:37741' closed.
2025-10-01 11:59:36,661 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:36305'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,662 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:36305' closed.
2025-10-01 11:59:36,682 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:34761'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,684 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:34761' closed.
2025-10-01 11:59:36,700 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:41923'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,700 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:41923' closed.
2025-10-01 11:59:36,705 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:33183'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,706 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:33183' closed.
2025-10-01 11:59:36,741 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:35193'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,742 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:35193' closed.
2025-10-01 11:59:36,747 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:45369'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,748 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:45369' closed.
2025-10-01 11:59:36,781 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:35409'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,782 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:35409' closed.
2025-10-01 11:59:36,785 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:33487'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,785 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:33487' closed.
2025-10-01 11:59:36,790 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:44855'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,791 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:44855' closed.
2025-10-01 11:59:36,797 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:34087'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,798 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:34087' closed.
2025-10-01 11:59:36,801 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:44835'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,802 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:34873'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,803 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:44835' closed.
2025-10-01 11:59:36,804 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:34873' closed.
2025-10-01 11:59:36,816 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:41173'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,817 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:41173' closed.
2025-10-01 11:59:36,842 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:36787'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,843 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:36787' closed.
2025-10-01 11:59:36,859 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:36341'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,860 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:36341' closed.
2025-10-01 11:59:36,874 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:45947'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,875 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:45947' closed.
2025-10-01 11:59:36,884 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:46009'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,884 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:45985'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,885 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:46009' closed.
2025-10-01 11:59:36,885 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:45985' closed.
2025-10-01 11:59:36,919 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 11:59:36,920 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:37627'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,921 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:37627' closed.
2025-10-01 11:59:36,935 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:45903'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,936 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:45903' closed.
2025-10-01 11:59:36,938 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:32911'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,938 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:32911' closed.
2025-10-01 11:59:36,941 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:40109'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,941 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:40109' closed.
2025-10-01 11:59:36,950 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:41557'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,951 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:41557' closed.
2025-10-01 11:59:36,962 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:42807'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,963 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:42807' closed.
2025-10-01 11:59:36,970 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:46641'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,970 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:46641' closed.
2025-10-01 11:59:36,982 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:44945'. Reason: nanny-close-gracefully
2025-10-01 11:59:36,983 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:44945' closed.
2025-10-01 11:59:37,045 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:44249'. Reason: nanny-close-gracefully
2025-10-01 11:59:37,046 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:44249' closed.
2025-10-01 11:59:37,068 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:36881'. Reason: nanny-close-gracefully
2025-10-01 11:59:37,069 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:36881' closed.
2025-10-01 11:59:37,230 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:34999'. Reason: nanny-close-gracefully
2025-10-01 11:59:37,232 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:36619'. Reason: nanny-close-gracefully
2025-10-01 11:59:37,233 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:34999' closed.
2025-10-01 11:59:37,233 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:36619' closed.
2025-10-01 11:59:37,336 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:40875'. Reason: nanny-close-gracefully
2025-10-01 11:59:37,337 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:40875' closed.
2025-10-01 11:59:37,438 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:43569'. Reason: nanny-close-gracefully
2025-10-01 11:59:37,439 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:43569' closed.
2025-10-01 11:59:37,611 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:38585'. Reason: nanny-close-gracefully
2025-10-01 11:59:37,612 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:38585' closed.
2025-10-01 11:59:37,835 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:35961'. Reason: nanny-close-gracefully
2025-10-01 11:59:37,835 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:35961' closed.
2025-10-01 11:59:38,143 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:40569'. Reason: nanny-close-gracefully
2025-10-01 11:59:38,144 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:40569' closed.
2025-10-01 11:59:38,727 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:46523'. Reason: nanny-close-gracefully
2025-10-01 11:59:38,728 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:46523' closed.
2025-10-01 11:59:39,201 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.5.29:38493'. Reason: nanny-close-gracefully
2025-10-01 11:59:39,202 - distributed.nanny - INFO - Nanny at 'tcp://10.6.5.29:38493' closed.
2025-10-01 11:59:39,204 - distributed.dask_worker - INFO - End worker
