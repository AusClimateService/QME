Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-03 10:31:33,214 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:35887'
2025-09-03 10:31:33,224 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:36291'
2025-09-03 10:31:33,230 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:46307'
2025-09-03 10:31:33,235 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:39793'
2025-09-03 10:31:33,240 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:44747'
2025-09-03 10:31:33,378 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:41339'
2025-09-03 10:31:33,383 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:35969'
2025-09-03 10:31:33,387 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:38471'
2025-09-03 10:31:33,392 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:39201'
2025-09-03 10:31:33,397 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:42651'
2025-09-03 10:31:33,402 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:45615'
2025-09-03 10:31:33,406 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:46387'
2025-09-03 10:31:33,411 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:34925'
2025-09-03 10:31:33,416 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:33539'
2025-09-03 10:31:33,420 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:45135'
2025-09-03 10:31:33,424 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:42613'
2025-09-03 10:31:33,428 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:44139'
2025-09-03 10:31:33,433 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:39187'
2025-09-03 10:31:33,438 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:41643'
2025-09-03 10:31:33,444 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:42633'
2025-09-03 10:31:33,448 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:41785'
2025-09-03 10:31:33,451 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:41147'
2025-09-03 10:31:33,457 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:45081'
2025-09-03 10:31:33,462 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:39163'
2025-09-03 10:31:33,466 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:34321'
2025-09-03 10:31:33,471 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:45297'
2025-09-03 10:31:33,475 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:42417'
2025-09-03 10:31:33,480 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:34573'
2025-09-03 10:31:33,485 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:37867'
2025-09-03 10:31:33,491 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:46847'
2025-09-03 10:31:33,494 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:42537'
2025-09-03 10:31:33,498 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:36233'
2025-09-03 10:31:33,503 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:43389'
2025-09-03 10:31:33,507 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:33017'
2025-09-03 10:31:33,512 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:38665'
2025-09-03 10:31:33,516 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:44787'
2025-09-03 10:31:33,520 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:44811'
2025-09-03 10:31:33,523 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:38225'
2025-09-03 10:31:33,527 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:45907'
2025-09-03 10:31:33,532 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:34881'
2025-09-03 10:31:33,537 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:35257'
2025-09-03 10:31:33,707 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:36467'
2025-09-03 10:31:33,712 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:42113'
2025-09-03 10:31:33,716 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:34347'
2025-09-03 10:31:33,721 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:37611'
2025-09-03 10:31:33,725 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:46033'
2025-09-03 10:31:33,730 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:40687'
2025-09-03 10:31:33,735 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:36979'
2025-09-03 10:31:33,740 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:35961'
2025-09-03 10:31:33,744 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:37037'
2025-09-03 10:31:33,749 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:37823'
2025-09-03 10:31:33,755 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:43337'
2025-09-03 10:31:33,759 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:40645'
2025-09-03 10:31:33,764 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:38045'
2025-09-03 10:31:33,767 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:45967'
2025-09-03 10:31:33,771 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:40713'
2025-09-03 10:31:33,774 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:41811'
2025-09-03 10:31:33,777 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:33119'
2025-09-03 10:31:33,784 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:44679'
2025-09-03 10:31:33,788 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:43733'
2025-09-03 10:31:33,793 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:38625'
2025-09-03 10:31:33,795 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:41815'
2025-09-03 10:31:33,799 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:33051'
2025-09-03 10:31:33,802 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:45183'
2025-09-03 10:31:33,804 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:38557'
2025-09-03 10:31:33,807 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:42443'
2025-09-03 10:31:33,813 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:38991'
2025-09-03 10:31:33,820 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:40041'
2025-09-03 10:31:33,824 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:37189'
2025-09-03 10:31:33,828 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:33621'
2025-09-03 10:31:33,833 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:39551'
2025-09-03 10:31:33,837 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:46273'
2025-09-03 10:31:33,842 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:40385'
2025-09-03 10:31:33,847 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:44409'
2025-09-03 10:31:33,851 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:42269'
2025-09-03 10:31:33,856 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:45445'
2025-09-03 10:31:33,861 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:37263'
2025-09-03 10:31:33,866 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:35799'
2025-09-03 10:31:33,871 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:46231'
2025-09-03 10:31:33,875 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:37107'
2025-09-03 10:31:33,879 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:32771'
2025-09-03 10:31:33,882 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:40875'
2025-09-03 10:31:33,886 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:44937'
2025-09-03 10:31:33,890 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:41555'
2025-09-03 10:31:33,910 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:34213'
2025-09-03 10:31:33,913 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:36411'
2025-09-03 10:31:33,915 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:36093'
2025-09-03 10:31:33,919 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:38909'
2025-09-03 10:31:33,923 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:38083'
2025-09-03 10:31:33,928 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:44959'
2025-09-03 10:31:33,932 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:43501'
2025-09-03 10:31:33,936 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:36911'
2025-09-03 10:31:33,939 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:41483'
2025-09-03 10:31:33,942 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:36535'
2025-09-03 10:31:33,946 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:40107'
2025-09-03 10:31:33,951 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:40009'
2025-09-03 10:31:33,953 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:36835'
2025-09-03 10:31:33,960 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:42519'
2025-09-03 10:31:33,964 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:36957'
2025-09-03 10:31:33,971 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:39533'
2025-09-03 10:31:33,978 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:46779'
2025-09-03 10:31:33,983 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:33517'
2025-09-03 10:31:33,988 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:34277'
2025-09-03 10:31:33,992 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.5:35069'
2025-09-03 10:31:34,905 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:35713
2025-09-03 10:31:34,905 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:38481
2025-09-03 10:31:34,905 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:41189
2025-09-03 10:31:34,905 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:37081
2025-09-03 10:31:34,906 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:35713
2025-09-03 10:31:34,905 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:41803
2025-09-03 10:31:34,905 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:36649
2025-09-03 10:31:34,906 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:38481
2025-09-03 10:31:34,906 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:41189
2025-09-03 10:31:34,906 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:36501
2025-09-03 10:31:34,906 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:37081
2025-09-03 10:31:34,906 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:43329
2025-09-03 10:31:34,906 - distributed.worker - INFO -          dashboard at:           10.6.102.5:35421
2025-09-03 10:31:34,906 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:41383
2025-09-03 10:31:34,906 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:41803
2025-09-03 10:31:34,906 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:36649
2025-09-03 10:31:34,906 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:40933
2025-09-03 10:31:34,906 - distributed.worker - INFO -          dashboard at:           10.6.102.5:42313
2025-09-03 10:31:34,906 - distributed.worker - INFO -          dashboard at:           10.6.102.5:39091
2025-09-03 10:31:34,906 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:36501
2025-09-03 10:31:34,906 - distributed.worker - INFO -          dashboard at:           10.6.102.5:45173
2025-09-03 10:31:34,906 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:37629
2025-09-03 10:31:34,906 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:43329
2025-09-03 10:31:34,906 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,906 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:41383
2025-09-03 10:31:34,906 - distributed.worker - INFO -          dashboard at:           10.6.102.5:34737
2025-09-03 10:31:34,906 - distributed.worker - INFO -          dashboard at:           10.6.102.5:36517
2025-09-03 10:31:34,906 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:40933
2025-09-03 10:31:34,906 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,906 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,906 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,906 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,906 - distributed.worker - INFO -          dashboard at:           10.6.102.5:42779
2025-09-03 10:31:34,906 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:37629
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO -          dashboard at:           10.6.102.5:37671
2025-09-03 10:31:34,906 - distributed.worker - INFO -          dashboard at:           10.6.102.5:34871
2025-09-03 10:31:34,906 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO -          dashboard at:           10.6.102.5:39259
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,906 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,906 - distributed.worker - INFO -          dashboard at:           10.6.102.5:40527
2025-09-03 10:31:34,906 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,906 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,906 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,906 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,906 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,906 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,906 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,906 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,906 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,906 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,906 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,906 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-6grbjmed
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,906 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,906 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-thux88jk
2025-09-03 10:31:34,906 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-rcrzhm7u
2025-09-03 10:31:34,906 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,906 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-m5edgpd6
2025-09-03 10:31:34,906 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,906 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-0kuw1zdm
2025-09-03 10:31:34,906 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,906 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,906 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-v4fradmw
2025-09-03 10:31:34,906 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-cgk_t4y2
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-bia8plt4
2025-09-03 10:31:34,906 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-exnp547x
2025-09-03 10:31:34,906 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-07jaafna
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-wxix3r2h
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,907 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,028 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:37405
2025-09-03 10:31:35,029 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:37405
2025-09-03 10:31:35,029 - distributed.worker - INFO -          dashboard at:           10.6.102.5:35911
2025-09-03 10:31:35,029 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,029 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,029 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,029 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,029 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-a8e0koo4
2025-09-03 10:31:35,029 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,050 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:36797
2025-09-03 10:31:35,050 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:36797
2025-09-03 10:31:35,050 - distributed.worker - INFO -          dashboard at:           10.6.102.5:33647
2025-09-03 10:31:35,050 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,050 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,050 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,050 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fo8ykis4
2025-09-03 10:31:35,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,053 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:46865
2025-09-03 10:31:35,053 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:46865
2025-09-03 10:31:35,053 - distributed.worker - INFO -          dashboard at:           10.6.102.5:41535
2025-09-03 10:31:35,053 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,053 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,053 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,053 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,054 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-g5c1s30w
2025-09-03 10:31:35,054 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,056 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:42361
2025-09-03 10:31:35,057 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:42361
2025-09-03 10:31:35,057 - distributed.worker - INFO -          dashboard at:           10.6.102.5:42905
2025-09-03 10:31:35,057 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,057 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,057 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,057 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,057 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-o0ayob8x
2025-09-03 10:31:35,057 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,086 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:41645
2025-09-03 10:31:35,087 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:41645
2025-09-03 10:31:35,087 - distributed.worker - INFO -          dashboard at:           10.6.102.5:37719
2025-09-03 10:31:35,087 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,087 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,087 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,087 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,087 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-mp7ku493
2025-09-03 10:31:35,087 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,094 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:38117
2025-09-03 10:31:35,094 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:38117
2025-09-03 10:31:35,094 - distributed.worker - INFO -          dashboard at:           10.6.102.5:40389
2025-09-03 10:31:35,094 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,094 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,094 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,094 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,094 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9qyspta6
2025-09-03 10:31:35,094 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,317 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:38881
2025-09-03 10:31:35,317 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:38881
2025-09-03 10:31:35,317 - distributed.worker - INFO -          dashboard at:           10.6.102.5:40475
2025-09-03 10:31:35,317 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,317 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,317 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,317 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,317 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-hodgfuu6
2025-09-03 10:31:35,317 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,321 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:38779
2025-09-03 10:31:35,321 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:38779
2025-09-03 10:31:35,321 - distributed.worker - INFO -          dashboard at:           10.6.102.5:36155
2025-09-03 10:31:35,321 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,321 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,321 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,321 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,321 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-u4m3w3cj
2025-09-03 10:31:35,321 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,340 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:44639
2025-09-03 10:31:35,340 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:44639
2025-09-03 10:31:35,340 - distributed.worker - INFO -          dashboard at:           10.6.102.5:41989
2025-09-03 10:31:35,340 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,340 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,340 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,340 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,340 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-tyawf9hp
2025-09-03 10:31:35,341 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,355 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:38623
2025-09-03 10:31:35,355 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:38623
2025-09-03 10:31:35,355 - distributed.worker - INFO -          dashboard at:           10.6.102.5:36329
2025-09-03 10:31:35,355 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,355 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,355 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,355 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,355 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4s_fzar7
2025-09-03 10:31:35,355 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,356 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:40899
2025-09-03 10:31:35,356 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:40899
2025-09-03 10:31:35,356 - distributed.worker - INFO -          dashboard at:           10.6.102.5:35619
2025-09-03 10:31:35,356 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,356 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,356 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,356 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,356 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-1s6uqktg
2025-09-03 10:31:35,356 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,360 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:37869
2025-09-03 10:31:35,360 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:37869
2025-09-03 10:31:35,360 - distributed.worker - INFO -          dashboard at:           10.6.102.5:36455
2025-09-03 10:31:35,360 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,360 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,360 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,360 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,360 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-sk5ximx9
2025-09-03 10:31:35,360 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,363 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:33911
2025-09-03 10:31:35,363 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:33911
2025-09-03 10:31:35,363 - distributed.worker - INFO -          dashboard at:           10.6.102.5:34413
2025-09-03 10:31:35,363 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,363 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,363 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,363 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,363 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-xv25f59p
2025-09-03 10:31:35,363 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,364 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:38853
2025-09-03 10:31:35,364 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:38853
2025-09-03 10:31:35,364 - distributed.worker - INFO -          dashboard at:           10.6.102.5:38367
2025-09-03 10:31:35,364 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,364 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,364 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,364 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,364 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-l03thtbg
2025-09-03 10:31:35,364 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,366 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:38123
2025-09-03 10:31:35,366 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:38123
2025-09-03 10:31:35,366 - distributed.worker - INFO -          dashboard at:           10.6.102.5:40915
2025-09-03 10:31:35,366 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,366 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,366 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,366 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,366 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-txi4dy0k
2025-09-03 10:31:35,366 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,371 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:42993
2025-09-03 10:31:35,371 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:42993
2025-09-03 10:31:35,371 - distributed.worker - INFO -          dashboard at:           10.6.102.5:45703
2025-09-03 10:31:35,371 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,371 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,371 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,371 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,371 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-0e9mrrbf
2025-09-03 10:31:35,371 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,373 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:43085
2025-09-03 10:31:35,373 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:43085
2025-09-03 10:31:35,373 - distributed.worker - INFO -          dashboard at:           10.6.102.5:34665
2025-09-03 10:31:35,373 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,373 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,373 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,373 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,373 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ygmiyk24
2025-09-03 10:31:35,373 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,376 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:40505
2025-09-03 10:31:35,377 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:40505
2025-09-03 10:31:35,377 - distributed.worker - INFO -          dashboard at:           10.6.102.5:33689
2025-09-03 10:31:35,377 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,377 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,377 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,377 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,377 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-rjha7w_e
2025-09-03 10:31:35,377 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,379 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:38213
2025-09-03 10:31:35,379 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:38213
2025-09-03 10:31:35,379 - distributed.worker - INFO -          dashboard at:           10.6.102.5:40959
2025-09-03 10:31:35,379 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,379 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,379 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,379 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,379 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-dj50tss8
2025-09-03 10:31:35,379 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,382 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:35241
2025-09-03 10:31:35,382 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:35241
2025-09-03 10:31:35,382 - distributed.worker - INFO -          dashboard at:           10.6.102.5:41467
2025-09-03 10:31:35,382 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,382 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,382 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,382 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,382 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-0vyze_u8
2025-09-03 10:31:35,382 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,387 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:43431
2025-09-03 10:31:35,387 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:43431
2025-09-03 10:31:35,387 - distributed.worker - INFO -          dashboard at:           10.6.102.5:36493
2025-09-03 10:31:35,387 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,387 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,387 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,387 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,387 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ebkaqeob
2025-09-03 10:31:35,387 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,390 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:41315
2025-09-03 10:31:35,390 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:41315
2025-09-03 10:31:35,390 - distributed.worker - INFO -          dashboard at:           10.6.102.5:41733
2025-09-03 10:31:35,390 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,390 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,390 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,390 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,390 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-1kqe0xqb
2025-09-03 10:31:35,391 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,390 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:33707
2025-09-03 10:31:35,391 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:33707
2025-09-03 10:31:35,391 - distributed.worker - INFO -          dashboard at:           10.6.102.5:45671
2025-09-03 10:31:35,391 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,391 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,391 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,391 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,391 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7pxmdpud
2025-09-03 10:31:35,391 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,396 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:46695
2025-09-03 10:31:35,397 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:46695
2025-09-03 10:31:35,397 - distributed.worker - INFO -          dashboard at:           10.6.102.5:41941
2025-09-03 10:31:35,397 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,397 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,397 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,397 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,397 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-xld3aqfv
2025-09-03 10:31:35,397 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,398 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:42401
2025-09-03 10:31:35,398 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:42401
2025-09-03 10:31:35,398 - distributed.worker - INFO -          dashboard at:           10.6.102.5:45999
2025-09-03 10:31:35,398 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,398 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,398 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,398 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,398 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-tf2x0xxe
2025-09-03 10:31:35,398 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,399 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:38133
2025-09-03 10:31:35,399 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:38133
2025-09-03 10:31:35,399 - distributed.worker - INFO -          dashboard at:           10.6.102.5:44257
2025-09-03 10:31:35,399 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,400 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,400 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,400 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,400 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-laje7ijr
2025-09-03 10:31:35,400 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:37865
2025-09-03 10:31:35,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:37865
2025-09-03 10:31:35,410 - distributed.worker - INFO -          dashboard at:           10.6.102.5:34309
2025-09-03 10:31:35,410 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,410 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,410 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,410 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,410 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-kda44_j1
2025-09-03 10:31:35,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,422 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:43171
2025-09-03 10:31:35,422 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:43171
2025-09-03 10:31:35,422 - distributed.worker - INFO -          dashboard at:           10.6.102.5:38111
2025-09-03 10:31:35,422 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,422 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,422 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,422 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,422 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-n5m3habl
2025-09-03 10:31:35,422 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,597 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:36475
2025-09-03 10:31:35,597 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:36475
2025-09-03 10:31:35,597 - distributed.worker - INFO -          dashboard at:           10.6.102.5:42355
2025-09-03 10:31:35,597 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,597 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,597 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,597 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-vl34nuco
2025-09-03 10:31:35,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,604 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:38391
2025-09-03 10:31:35,604 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:38391
2025-09-03 10:31:35,604 - distributed.worker - INFO -          dashboard at:           10.6.102.5:40907
2025-09-03 10:31:35,604 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,604 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,604 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,604 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,604 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-z06yvf44
2025-09-03 10:31:35,604 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,814 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:34883
2025-09-03 10:31:35,814 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:34883
2025-09-03 10:31:35,814 - distributed.worker - INFO -          dashboard at:           10.6.102.5:36185
2025-09-03 10:31:35,814 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,814 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,814 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,814 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,814 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zbk29b_v
2025-09-03 10:31:35,814 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,818 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:39963
2025-09-03 10:31:35,818 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:39963
2025-09-03 10:31:35,818 - distributed.worker - INFO -          dashboard at:           10.6.102.5:46725
2025-09-03 10:31:35,818 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,818 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,818 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,818 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3e1nnq6b
2025-09-03 10:31:35,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,881 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:36245
2025-09-03 10:31:35,881 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:36245
2025-09-03 10:31:35,881 - distributed.worker - INFO -          dashboard at:           10.6.102.5:42199
2025-09-03 10:31:35,881 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,881 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,881 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,882 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,882 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ecszgpub
2025-09-03 10:31:35,882 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,905 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:33851
2025-09-03 10:31:35,905 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:33851
2025-09-03 10:31:35,905 - distributed.worker - INFO -          dashboard at:           10.6.102.5:38285
2025-09-03 10:31:35,905 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,905 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,905 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,905 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,905 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-n1e3qqj_
2025-09-03 10:31:35,905 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,003 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,004 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,004 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,006 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,030 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:42523
2025-09-03 10:31:36,030 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:42523
2025-09-03 10:31:36,030 - distributed.worker - INFO -          dashboard at:           10.6.102.5:35941
2025-09-03 10:31:36,030 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,030 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,030 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,030 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-t7f847no
2025-09-03 10:31:36,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,053 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,054 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,055 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,056 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,082 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:37177
2025-09-03 10:31:36,082 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:37177
2025-09-03 10:31:36,082 - distributed.worker - INFO -          dashboard at:           10.6.102.5:34345
2025-09-03 10:31:36,082 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,082 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,082 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,082 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,082 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-n1w8z7km
2025-09-03 10:31:36,082 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,085 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,087 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,087 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,089 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,162 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:41485
2025-09-03 10:31:36,162 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:41485
2025-09-03 10:31:36,162 - distributed.worker - INFO -          dashboard at:           10.6.102.5:44689
2025-09-03 10:31:36,162 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,162 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,162 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,162 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,162 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-tfe7gj2q
2025-09-03 10:31:36,162 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,169 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:40661
2025-09-03 10:31:36,169 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:40661
2025-09-03 10:31:36,169 - distributed.worker - INFO -          dashboard at:           10.6.102.5:43675
2025-09-03 10:31:36,169 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,169 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,169 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,169 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,169 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-s9wunn8h
2025-09-03 10:31:36,169 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,175 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:39087
2025-09-03 10:31:36,175 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:39087
2025-09-03 10:31:36,175 - distributed.worker - INFO -          dashboard at:           10.6.102.5:34035
2025-09-03 10:31:36,175 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,175 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,175 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,175 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,175 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-nkpb7nap
2025-09-03 10:31:36,175 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,180 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:39725
2025-09-03 10:31:36,180 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:39725
2025-09-03 10:31:36,180 - distributed.worker - INFO -          dashboard at:           10.6.102.5:36803
2025-09-03 10:31:36,180 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,180 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,180 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,180 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,180 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-j396vl0z
2025-09-03 10:31:36,180 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,213 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:46799
2025-09-03 10:31:36,213 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:46799
2025-09-03 10:31:36,213 - distributed.worker - INFO -          dashboard at:           10.6.102.5:43417
2025-09-03 10:31:36,214 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,214 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,214 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,214 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,214 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-285_wlvd
2025-09-03 10:31:36,214 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,221 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:46389
2025-09-03 10:31:36,221 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:46389
2025-09-03 10:31:36,221 - distributed.worker - INFO -          dashboard at:           10.6.102.5:33319
2025-09-03 10:31:36,221 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,221 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,221 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,221 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,221 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-em6y65wd
2025-09-03 10:31:36,221 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,222 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:43233
2025-09-03 10:31:36,222 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:43233
2025-09-03 10:31:36,222 - distributed.worker - INFO -          dashboard at:           10.6.102.5:39783
2025-09-03 10:31:36,222 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,222 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,222 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,222 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,222 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-h67ebkw8
2025-09-03 10:31:36,222 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,243 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:40479
2025-09-03 10:31:36,243 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:40479
2025-09-03 10:31:36,243 - distributed.worker - INFO -          dashboard at:           10.6.102.5:39077
2025-09-03 10:31:36,243 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,243 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,243 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,243 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,243 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4m5dlcz4
2025-09-03 10:31:36,243 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,270 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:46807
2025-09-03 10:31:36,270 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:46807
2025-09-03 10:31:36,270 - distributed.worker - INFO -          dashboard at:           10.6.102.5:41839
2025-09-03 10:31:36,270 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,270 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,270 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,270 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,270 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-80dgj40d
2025-09-03 10:31:36,270 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,291 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,292 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,293 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,294 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,313 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,314 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,314 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,314 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:36173
2025-09-03 10:31:36,315 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:36173
2025-09-03 10:31:36,315 - distributed.worker - INFO -          dashboard at:           10.6.102.5:36587
2025-09-03 10:31:36,315 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,315 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,315 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,315 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,315 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-___ez4zh
2025-09-03 10:31:36,315 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,316 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,330 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:44991
2025-09-03 10:31:36,330 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:44991
2025-09-03 10:31:36,330 - distributed.worker - INFO -          dashboard at:           10.6.102.5:39499
2025-09-03 10:31:36,330 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,330 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,330 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,330 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,330 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-tmsyj6vv
2025-09-03 10:31:36,330 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,340 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:39895
2025-09-03 10:31:36,340 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:39895
2025-09-03 10:31:36,340 - distributed.worker - INFO -          dashboard at:           10.6.102.5:41577
2025-09-03 10:31:36,340 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,340 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,340 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,340 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,340 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-hdk7e3as
2025-09-03 10:31:36,340 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,343 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:46875
2025-09-03 10:31:36,343 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:46875
2025-09-03 10:31:36,343 - distributed.worker - INFO -          dashboard at:           10.6.102.5:35797
2025-09-03 10:31:36,343 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,343 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,343 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,343 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,343 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-bh4cgl6m
2025-09-03 10:31:36,343 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,358 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:39375
2025-09-03 10:31:36,358 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:39375
2025-09-03 10:31:36,358 - distributed.worker - INFO -          dashboard at:           10.6.102.5:34335
2025-09-03 10:31:36,358 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,358 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,358 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,358 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,358 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-nbjne0oo
2025-09-03 10:31:36,358 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,412 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:38385
2025-09-03 10:31:36,412 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:38385
2025-09-03 10:31:36,412 - distributed.worker - INFO -          dashboard at:           10.6.102.5:37507
2025-09-03 10:31:36,413 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,413 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,413 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,413 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,413 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-wa6z0zh0
2025-09-03 10:31:36,413 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,472 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:32777
2025-09-03 10:31:36,472 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:32777
2025-09-03 10:31:36,472 - distributed.worker - INFO -          dashboard at:           10.6.102.5:45873
2025-09-03 10:31:36,472 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,472 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,472 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,472 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,472 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-aseag3gl
2025-09-03 10:31:36,472 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,500 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:45817
2025-09-03 10:31:36,500 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:45817
2025-09-03 10:31:36,500 - distributed.worker - INFO -          dashboard at:           10.6.102.5:38491
2025-09-03 10:31:36,500 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,500 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,500 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,500 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,500 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-jw3g2dpn
2025-09-03 10:31:36,500 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,535 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:44269
2025-09-03 10:31:36,535 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:44269
2025-09-03 10:31:36,535 - distributed.worker - INFO -          dashboard at:           10.6.102.5:36583
2025-09-03 10:31:36,535 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,535 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,535 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,535 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,535 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-j_z_4nai
2025-09-03 10:31:36,536 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,602 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:43151
2025-09-03 10:31:36,602 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:43151
2025-09-03 10:31:36,602 - distributed.worker - INFO -          dashboard at:           10.6.102.5:41399
2025-09-03 10:31:36,602 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,602 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,602 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,602 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,602 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-8oa4gu4v
2025-09-03 10:31:36,602 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,610 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:38463
2025-09-03 10:31:36,610 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:38463
2025-09-03 10:31:36,610 - distributed.worker - INFO -          dashboard at:           10.6.102.5:32923
2025-09-03 10:31:36,610 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,610 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,610 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,610 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,610 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-bdclagu2
2025-09-03 10:31:36,610 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,628 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:40673
2025-09-03 10:31:36,628 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:40673
2025-09-03 10:31:36,628 - distributed.worker - INFO -          dashboard at:           10.6.102.5:33147
2025-09-03 10:31:36,628 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,628 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,628 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,628 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,628 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-z2u1c0et
2025-09-03 10:31:36,628 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,655 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:34033
2025-09-03 10:31:36,655 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:34033
2025-09-03 10:31:36,655 - distributed.worker - INFO -          dashboard at:           10.6.102.5:43407
2025-09-03 10:31:36,655 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,655 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,655 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,655 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,655 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-qjjd7z2f
2025-09-03 10:31:36,655 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,658 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:46645
2025-09-03 10:31:36,658 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:34547
2025-09-03 10:31:36,658 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:46645
2025-09-03 10:31:36,658 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:34547
2025-09-03 10:31:36,658 - distributed.worker - INFO -          dashboard at:           10.6.102.5:41699
2025-09-03 10:31:36,659 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,659 - distributed.worker - INFO -          dashboard at:           10.6.102.5:39037
2025-09-03 10:31:36,659 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,659 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,659 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,659 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,659 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,659 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,659 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,659 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-o2g500m5
2025-09-03 10:31:36,659 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-rere17gi
2025-09-03 10:31:36,659 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,659 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,659 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:42133
2025-09-03 10:31:36,659 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:42133
2025-09-03 10:31:36,659 - distributed.worker - INFO -          dashboard at:           10.6.102.5:37283
2025-09-03 10:31:36,660 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,660 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,660 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,660 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,660 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-jibpab55
2025-09-03 10:31:36,660 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,662 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:39983
2025-09-03 10:31:36,662 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:39983
2025-09-03 10:31:36,662 - distributed.worker - INFO -          dashboard at:           10.6.102.5:33871
2025-09-03 10:31:36,662 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,662 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,662 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,662 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,662 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-0n1lnwsl
2025-09-03 10:31:36,662 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,670 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:37041
2025-09-03 10:31:36,670 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:37041
2025-09-03 10:31:36,670 - distributed.worker - INFO -          dashboard at:           10.6.102.5:34575
2025-09-03 10:31:36,670 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,670 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,670 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,670 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,670 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-oc08jo_j
2025-09-03 10:31:36,670 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,671 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:36745
2025-09-03 10:31:36,672 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:36745
2025-09-03 10:31:36,672 - distributed.worker - INFO -          dashboard at:           10.6.102.5:44265
2025-09-03 10:31:36,672 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,672 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,672 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,672 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,672 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-8p5hk8yc
2025-09-03 10:31:36,672 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,684 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:46107
2025-09-03 10:31:36,684 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:46107
2025-09-03 10:31:36,684 - distributed.worker - INFO -          dashboard at:           10.6.102.5:44587
2025-09-03 10:31:36,684 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,684 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,684 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,684 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,684 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-hxyqtpqe
2025-09-03 10:31:36,684 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,701 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:44431
2025-09-03 10:31:36,701 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:44431
2025-09-03 10:31:36,701 - distributed.worker - INFO -          dashboard at:           10.6.102.5:46003
2025-09-03 10:31:36,701 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,701 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,701 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,702 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,702 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-5zudkc9f
2025-09-03 10:31:36,702 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,702 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:40379
2025-09-03 10:31:36,702 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:40379
2025-09-03 10:31:36,702 - distributed.worker - INFO -          dashboard at:           10.6.102.5:43275
2025-09-03 10:31:36,702 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,702 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,702 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,702 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,702 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-lum0aeqz
2025-09-03 10:31:36,703 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,708 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:36791
2025-09-03 10:31:36,708 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:36791
2025-09-03 10:31:36,708 - distributed.worker - INFO -          dashboard at:           10.6.102.5:41277
2025-09-03 10:31:36,708 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,708 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,708 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,708 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,708 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fdnvjl51
2025-09-03 10:31:36,708 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,708 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:45971
2025-09-03 10:31:36,708 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:45971
2025-09-03 10:31:36,708 - distributed.worker - INFO -          dashboard at:           10.6.102.5:34375
2025-09-03 10:31:36,708 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,708 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,708 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,708 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,708 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-y0000k62
2025-09-03 10:31:36,708 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,822 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,823 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,823 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,824 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,833 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,834 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,834 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,836 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,844 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,845 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,845 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,846 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,854 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,855 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,855 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,857 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,865 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,866 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,866 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,868 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,876 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,877 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,878 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,879 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,887 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,888 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,888 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,890 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,898 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,899 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,899 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,901 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,920 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,921 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,921 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,923 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,942 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,943 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,943 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,945 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,953 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,954 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,954 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,956 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:37,404 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:45213
2025-09-03 10:31:37,404 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:45213
2025-09-03 10:31:37,404 - distributed.worker - INFO -          dashboard at:           10.6.102.5:40399
2025-09-03 10:31:37,404 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,404 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,404 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,404 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,404 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-czfprfts
2025-09-03 10:31:37,404 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,408 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:39537
2025-09-03 10:31:37,408 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:39537
2025-09-03 10:31:37,408 - distributed.worker - INFO -          dashboard at:           10.6.102.5:42235
2025-09-03 10:31:37,408 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,408 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,408 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,408 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,408 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-h2sfo7gk
2025-09-03 10:31:37,408 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,409 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:40697
2025-09-03 10:31:37,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:40697
2025-09-03 10:31:37,410 - distributed.worker - INFO -          dashboard at:           10.6.102.5:33245
2025-09-03 10:31:37,410 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,410 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,410 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,410 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,410 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4bmo6w0h
2025-09-03 10:31:37,410 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:41325
2025-09-03 10:31:37,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:41325
2025-09-03 10:31:37,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:33211
2025-09-03 10:31:37,410 - distributed.worker - INFO -          dashboard at:           10.6.102.5:41661
2025-09-03 10:31:37,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:33211
2025-09-03 10:31:37,410 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,410 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,410 - distributed.worker - INFO -          dashboard at:           10.6.102.5:36237
2025-09-03 10:31:37,410 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,410 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,410 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,410 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,410 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,410 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-tqygvvtu
2025-09-03 10:31:37,410 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,410 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,411 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-17ertlrm
2025-09-03 10:31:37,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,419 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:39763
2025-09-03 10:31:37,419 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:39763
2025-09-03 10:31:37,419 - distributed.worker - INFO -          dashboard at:           10.6.102.5:34107
2025-09-03 10:31:37,420 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,420 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,420 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,420 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,420 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-tvd2gza2
2025-09-03 10:31:37,420 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,519 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:33687
2025-09-03 10:31:37,519 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:33687
2025-09-03 10:31:37,519 - distributed.worker - INFO -          dashboard at:           10.6.102.5:36399
2025-09-03 10:31:37,520 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,520 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,520 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,520 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,520 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-xdi190j1
2025-09-03 10:31:37,520 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,524 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:39501
2025-09-03 10:31:37,524 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:43841
2025-09-03 10:31:37,524 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:39501
2025-09-03 10:31:37,524 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:43841
2025-09-03 10:31:37,524 - distributed.worker - INFO -          dashboard at:           10.6.102.5:42625
2025-09-03 10:31:37,524 - distributed.worker - INFO -          dashboard at:           10.6.102.5:45079
2025-09-03 10:31:37,524 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,525 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,525 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,525 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,525 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,525 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,525 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,525 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-94dunqc_
2025-09-03 10:31:37,525 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,525 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,525 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-48zza_s1
2025-09-03 10:31:37,525 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,525 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:41087
2025-09-03 10:31:37,525 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:41087
2025-09-03 10:31:37,526 - distributed.worker - INFO -          dashboard at:           10.6.102.5:38043
2025-09-03 10:31:37,526 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,526 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,526 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,526 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,526 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ikllrc69
2025-09-03 10:31:37,526 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,528 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:42669
2025-09-03 10:31:37,528 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:42669
2025-09-03 10:31:37,528 - distributed.worker - INFO -          dashboard at:           10.6.102.5:36551
2025-09-03 10:31:37,528 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,528 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,528 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,528 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,528 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-u8bpl5c8
2025-09-03 10:31:37,528 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,530 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:35869
2025-09-03 10:31:37,530 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:35869
2025-09-03 10:31:37,530 - distributed.worker - INFO -          dashboard at:           10.6.102.5:43381
2025-09-03 10:31:37,530 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,530 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,530 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,530 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,530 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-d6ilcifd
2025-09-03 10:31:37,530 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,547 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:35591
2025-09-03 10:31:37,547 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:35591
2025-09-03 10:31:37,547 - distributed.worker - INFO -          dashboard at:           10.6.102.5:46423
2025-09-03 10:31:37,547 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,547 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,547 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,547 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-jfmnpk3_
2025-09-03 10:31:37,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,549 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:37221
2025-09-03 10:31:37,549 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:37221
2025-09-03 10:31:37,549 - distributed.worker - INFO -          dashboard at:           10.6.102.5:33623
2025-09-03 10:31:37,549 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,549 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,549 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,549 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,549 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-kmn2n356
2025-09-03 10:31:37,549 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,551 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:38193
2025-09-03 10:31:37,551 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:38193
2025-09-03 10:31:37,551 - distributed.worker - INFO -          dashboard at:           10.6.102.5:34297
2025-09-03 10:31:37,551 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,551 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,551 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,551 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,551 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-jim9pq8v
2025-09-03 10:31:37,551 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,552 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:37163
2025-09-03 10:31:37,553 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:37163
2025-09-03 10:31:37,553 - distributed.worker - INFO -          dashboard at:           10.6.102.5:46571
2025-09-03 10:31:37,553 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,553 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,553 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,553 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-nt3a5wu1
2025-09-03 10:31:37,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,555 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:40775
2025-09-03 10:31:37,555 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:40775
2025-09-03 10:31:37,555 - distributed.worker - INFO -          dashboard at:           10.6.102.5:36575
2025-09-03 10:31:37,555 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,555 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,555 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,555 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,555 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-smd649ds
2025-09-03 10:31:37,555 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,555 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:33763
2025-09-03 10:31:37,555 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:33763
2025-09-03 10:31:37,556 - distributed.worker - INFO -          dashboard at:           10.6.102.5:40141
2025-09-03 10:31:37,556 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,556 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,556 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,556 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,556 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-so2vmsqe
2025-09-03 10:31:37,556 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,559 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:39165
2025-09-03 10:31:37,559 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:39165
2025-09-03 10:31:37,559 - distributed.worker - INFO -          dashboard at:           10.6.102.5:44589
2025-09-03 10:31:37,559 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,559 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,559 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,559 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,559 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-2mmaiiep
2025-09-03 10:31:37,559 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,559 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:36413
2025-09-03 10:31:37,559 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:36413
2025-09-03 10:31:37,559 - distributed.worker - INFO -          dashboard at:           10.6.102.5:32797
2025-09-03 10:31:37,559 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,559 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,559 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,559 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,559 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-q30d_97r
2025-09-03 10:31:37,560 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,560 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:44205
2025-09-03 10:31:37,560 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:44205
2025-09-03 10:31:37,560 - distributed.worker - INFO -          dashboard at:           10.6.102.5:42703
2025-09-03 10:31:37,560 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,560 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,560 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,560 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,560 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-5hiiyil6
2025-09-03 10:31:37,560 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,560 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:40781
2025-09-03 10:31:37,560 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:40781
2025-09-03 10:31:37,560 - distributed.worker - INFO -          dashboard at:           10.6.102.5:41263
2025-09-03 10:31:37,560 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,560 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,560 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,560 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,560 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zu562dmf
2025-09-03 10:31:37,561 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,561 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:43989
2025-09-03 10:31:37,561 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:43989
2025-09-03 10:31:37,561 - distributed.worker - INFO -          dashboard at:           10.6.102.5:44247
2025-09-03 10:31:37,561 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,561 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,561 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,561 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,561 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-qpxp0qv8
2025-09-03 10:31:37,561 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,563 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.5:42369
2025-09-03 10:31:37,563 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.5:42369
2025-09-03 10:31:37,563 - distributed.worker - INFO -          dashboard at:           10.6.102.5:39081
2025-09-03 10:31:37,563 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,563 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,563 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,563 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,563 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fhjytya7
2025-09-03 10:31:37,563 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,977 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:37,978 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,979 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,981 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,279 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,280 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,280 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,282 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,290 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,291 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,292 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,294 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,301 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,302 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,302 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,304 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,313 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,314 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,314 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,316 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,591 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,592 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,592 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,594 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,703 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,704 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,704 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,706 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,726 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,727 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,728 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,729 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,737 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,738 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,738 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,741 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,749 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,750 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,750 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,752 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,760 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,762 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,762 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,764 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,771 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,773 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,773 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,775 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,783 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,784 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,784 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,786 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,794 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,795 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,795 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,797 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,827 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,829 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,829 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,831 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,850 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,851 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,851 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,853 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,861 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,863 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,863 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,865 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,872 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,874 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,874 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,876 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,884 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,886 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,886 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,888 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,895 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,897 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,897 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,899 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,906 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,907 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,907 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,909 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,918 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,919 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,920 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,922 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,940 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,942 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,942 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,944 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,632 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,633 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,633 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,635 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,643 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,645 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,645 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,647 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,655 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,657 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,657 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,659 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,667 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,668 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,668 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,670 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,834 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,835 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,835 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,837 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,845 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,847 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,847 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,849 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,857 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,858 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,858 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,860 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,869 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,870 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,870 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,872 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,880 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,882 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,882 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,884 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,892 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,894 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,894 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,896 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,904 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,905 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,905 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,907 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,916 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,917 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,917 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,919 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,245 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,246 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,246 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,248 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,257 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,258 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,259 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,260 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,269 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,270 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,270 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,272 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,281 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,282 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,282 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,284 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,293 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,294 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,294 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,296 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,304 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,305 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,305 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,307 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,317 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,318 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,318 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,320 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,721 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,722 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,723 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,724 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,745 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,747 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,747 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,749 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,135 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,137 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,137 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,138 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,159 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,161 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,161 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,163 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,289 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,291 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,291 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,292 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,338 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,340 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,340 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,341 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,362 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,364 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,364 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,366 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,546 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,550 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,550 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,555 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,634 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,635 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,635 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,637 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,646 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,647 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,648 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,649 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,657 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,659 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,659 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,661 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,670 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,672 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,672 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,673 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,683 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,685 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,685 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,686 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,695 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,696 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,696 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,698 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,025 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,026 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,026 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,028 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,086 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,088 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,088 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,090 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,613 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,614 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,614 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,616 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,625 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,626 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,627 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,628 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,637 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,638 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,639 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,640 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,650 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,652 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,652 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,653 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,662 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,663 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,663 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,665 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,674 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,675 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,675 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,677 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,686 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,688 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,688 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,690 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,698 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,700 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,700 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,702 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,710 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,712 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,714 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,723 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,725 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,725 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,727 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,735 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,737 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,737 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,739 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,748 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,749 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,749 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,751 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,919 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,921 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,921 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,923 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,931 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,932 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,933 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,934 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,956 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,957 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,958 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,959 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:58,711 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:58,713 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:58,713 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:58,715 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:58,725 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:58,726 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:58,726 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:58,728 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:58,739 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:58,741 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:58,741 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:58,743 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:58,754 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:58,755 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:58,755 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:58,757 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:58,768 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:58,770 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:58,770 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:58,772 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:59,918 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:59,919 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:59,919 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:59,921 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:59,932 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:59,934 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:59,934 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:59,935 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:59,947 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:59,949 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:59,949 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:59,951 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:59,962 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:59,964 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:59,964 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:59,965 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:59,977 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:59,978 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:59,978 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:59,980 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:59,991 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:59,992 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:59,992 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:59,994 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:05,319 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:05,322 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,501 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,537 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:07,090 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:09,679 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:09,680 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:09,680 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:09,682 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:09,694 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:09,696 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:09,696 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:09,698 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:12,637 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:12,649 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:14,727 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:15,141 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:16,755 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:17,108 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:17,109 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:17,109 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:17,111 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:17,124 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:17,125 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:17,125 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:17,127 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:30,923 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:30,939 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:30,952 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:30,969 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:30,983 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:30,996 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:38,091 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:47,753 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:35:51,380 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,382 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,438 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,440 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,464 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,471 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,488 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,489 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,490 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,490 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,620 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,626 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,673 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,682 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,882 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,887 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,954 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,959 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,034 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,037 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,048 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,049 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,119 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,124 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,138 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,145 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,240 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,243 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,158 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,159 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,202 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,206 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,350 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,351 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,378 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,379 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,392 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,398 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,484 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,490 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,503 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,509 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,544 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,550 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,875 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,879 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,928 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,929 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,984 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,985 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,992 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,994 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,276 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,281 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,301 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,302 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,740 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,747 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,769 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,770 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,822 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,823 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,855 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,860 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,902 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,908 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,965 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,967 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,151 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,152 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,224 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,225 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,250 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,258 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,324 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,326 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,393 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,398 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,398 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,400 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,416 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,417 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,428 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,429 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,669 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,672 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,766 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,768 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,801 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,807 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,811 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,817 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,862 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,863 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,012 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,015 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,071 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,073 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,086 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,091 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,150 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,151 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,208 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,209 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,214 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,216 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,230 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,233 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,307 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,313 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,576 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,578 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,640 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,647 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,972 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,974 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,068 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,072 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,105 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,111 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,112 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,114 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,180 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,188 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,223 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,225 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,226 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,229 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,542 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,547 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,705 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,707 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,756 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,762 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,835 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,834 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,838 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,840 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,883 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,885 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,888 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,890 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,948 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,950 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,047 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,051 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,053 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,054 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,235 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,241 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,282 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,283 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,286 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,289 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,348 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,354 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,468 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,473 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,706 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,712 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,778 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,784 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,833 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,835 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,940 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,948 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,973 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,979 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,066 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,067 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,716 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,721 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,152 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,153 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,250 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,257 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,335 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,341 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,398 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,401 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,522 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,524 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,629 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,631 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,102 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,103 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,280 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,282 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,542 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,547 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,138 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,140 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,872 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,873 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,999 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,000 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,002 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:03,004 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:03,315 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,319 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:04,115 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:04,116 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:04,315 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:04,316 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:04,586 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:04,591 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:05,109 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:05,110 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:22,896 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,898 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,899 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,905 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,906 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,907 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,907 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,912 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,913 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,915 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,915 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,916 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,920 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,921 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,922 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,923 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,932 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,935 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,934 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,936 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,942 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,944 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,950 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,952 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,959 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,960 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,386 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,388 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,392 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,393 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,396 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,397 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,398 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,400 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,405 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,407 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,407 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,409 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,512 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,517 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,519 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,521 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,523 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,523 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,525 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,525 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,528 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,530 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,530 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,532 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,539 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,542 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,552 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,555 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,564 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,567 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,569 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,569 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,789 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,794 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,795 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,796 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,799 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,801 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,806 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,808 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,806 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,811 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,835 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,837 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,844 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,846 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,848 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,850 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,848 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,853 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,860 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,862 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,884 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,886 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,887 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,887 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,889 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,889 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,898 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,897 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,900 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,903 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,912 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,914 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,018 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,021 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,027 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,029 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,033 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,036 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,037 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,039 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,064 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,066 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,070 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,072 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,088 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,091 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,094 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,096 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,101 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,103 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,113 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,115 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,121 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,125 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,228 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,231 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,237 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,239 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,240 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,242 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,335 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,337 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,400 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,399 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,402 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,404 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,431 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,432 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,433 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,434 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,448 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,450 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,500 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,503 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,507 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,509 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,579 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,581 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,589 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,592 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,598 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,600 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,637 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,639 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,641 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,643 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,663 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,670 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,675 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,677 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,684 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,687 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,690 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,692 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,745 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,745 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,746 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,747 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,748 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,748 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,861 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,863 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,867 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,869 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,900 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,901 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,902 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,903 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,920 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,922 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,925 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,927 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,963 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,965 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,966 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,968 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,991 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,993 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,017 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,019 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,027 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,029 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,052 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,054 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,282 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,284 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,300 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,303 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,389 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,391 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,417 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,419 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,495 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,498 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,652 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,654 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,702 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,704 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,708 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,710 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,865 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,867 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,039 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,044 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,246 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,248 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,417 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,419 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,460 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,463 - distributed.utils - INFO - Reload module qme_vars from .py file
