Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-03 10:31:34,090 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:34613'
2025-09-03 10:31:34,099 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:40829'
2025-09-03 10:31:34,104 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:40705'
2025-09-03 10:31:34,110 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:45493'
2025-09-03 10:31:34,114 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:37775'
2025-09-03 10:31:34,201 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:41781'
2025-09-03 10:31:34,206 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:33997'
2025-09-03 10:31:34,210 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:38211'
2025-09-03 10:31:34,215 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:43331'
2025-09-03 10:31:34,220 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:36079'
2025-09-03 10:31:34,225 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:42315'
2025-09-03 10:31:34,230 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:45173'
2025-09-03 10:31:34,235 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:45191'
2025-09-03 10:31:34,238 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:39885'
2025-09-03 10:31:34,243 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:40259'
2025-09-03 10:31:34,247 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:36923'
2025-09-03 10:31:34,252 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:40997'
2025-09-03 10:31:34,256 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:44001'
2025-09-03 10:31:34,262 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:35423'
2025-09-03 10:31:34,266 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:45415'
2025-09-03 10:31:34,271 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:35827'
2025-09-03 10:31:34,276 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:36005'
2025-09-03 10:31:34,281 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:43379'
2025-09-03 10:31:34,285 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:37907'
2025-09-03 10:31:34,290 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:36265'
2025-09-03 10:31:34,294 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:41449'
2025-09-03 10:31:34,299 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:41295'
2025-09-03 10:31:34,304 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:41615'
2025-09-03 10:31:34,307 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:46269'
2025-09-03 10:31:34,312 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:33975'
2025-09-03 10:31:34,316 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:35169'
2025-09-03 10:31:34,321 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:45637'
2025-09-03 10:31:34,325 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:33971'
2025-09-03 10:31:34,330 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:34527'
2025-09-03 10:31:34,335 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:45985'
2025-09-03 10:31:34,340 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:34155'
2025-09-03 10:31:34,345 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:40845'
2025-09-03 10:31:34,349 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:39385'
2025-09-03 10:31:34,356 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:40671'
2025-09-03 10:31:34,359 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:39133'
2025-09-03 10:31:34,362 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:45647'
2025-09-03 10:31:34,366 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:36903'
2025-09-03 10:31:34,503 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:41247'
2025-09-03 10:31:34,508 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:34463'
2025-09-03 10:31:34,514 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:39723'
2025-09-03 10:31:34,518 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:46301'
2025-09-03 10:31:34,523 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:42769'
2025-09-03 10:31:34,528 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:40009'
2025-09-03 10:31:34,533 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:35161'
2025-09-03 10:31:34,536 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:33117'
2025-09-03 10:31:34,540 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:38519'
2025-09-03 10:31:34,545 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:41483'
2025-09-03 10:31:34,550 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:45221'
2025-09-03 10:31:34,555 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:46075'
2025-09-03 10:31:34,560 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:36207'
2025-09-03 10:31:34,563 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:43201'
2025-09-03 10:31:34,564 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:37205'
2025-09-03 10:31:34,567 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:40313'
2025-09-03 10:31:34,571 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:44559'
2025-09-03 10:31:34,574 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:42443'
2025-09-03 10:31:34,578 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:46059'
2025-09-03 10:31:34,582 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:41375'
2025-09-03 10:31:34,585 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:45243'
2025-09-03 10:31:34,588 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:42135'
2025-09-03 10:31:34,596 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:34603'
2025-09-03 10:31:34,600 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:38847'
2025-09-03 10:31:34,604 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:40673'
2025-09-03 10:31:34,606 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:42183'
2025-09-03 10:31:34,611 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:43555'
2025-09-03 10:31:34,617 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:39887'
2025-09-03 10:31:34,622 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:33685'
2025-09-03 10:31:34,625 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:33315'
2025-09-03 10:31:34,630 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:35909'
2025-09-03 10:31:34,634 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:43131'
2025-09-03 10:31:34,638 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:38691'
2025-09-03 10:31:34,642 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:39849'
2025-09-03 10:31:34,660 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:33517'
2025-09-03 10:31:34,666 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:37347'
2025-09-03 10:31:34,671 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:34255'
2025-09-03 10:31:34,676 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:38103'
2025-09-03 10:31:34,679 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:36385'
2025-09-03 10:31:34,683 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:43369'
2025-09-03 10:31:34,688 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:45123'
2025-09-03 10:31:34,692 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:38383'
2025-09-03 10:31:34,700 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:37909'
2025-09-03 10:31:34,704 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:46071'
2025-09-03 10:31:34,708 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:44341'
2025-09-03 10:31:34,713 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:44545'
2025-09-03 10:31:34,718 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:44075'
2025-09-03 10:31:34,721 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:44885'
2025-09-03 10:31:34,725 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:41495'
2025-09-03 10:31:34,729 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:35977'
2025-09-03 10:31:34,734 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:39935'
2025-09-03 10:31:34,738 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:36699'
2025-09-03 10:31:34,742 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:44757'
2025-09-03 10:31:34,747 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:38115'
2025-09-03 10:31:34,752 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:33645'
2025-09-03 10:31:34,756 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:45701'
2025-09-03 10:31:34,762 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:43409'
2025-09-03 10:31:34,766 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:45533'
2025-09-03 10:31:34,770 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:33779'
2025-09-03 10:31:34,775 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:43703'
2025-09-03 10:31:34,780 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:39267'
2025-09-03 10:31:34,784 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.15:44703'
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:40273
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:34739
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:45557
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:37191
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:34845
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:38261
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:40865
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:36333
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:39023
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:41229
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:39251
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:44079
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:35721
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:46697
2025-09-03 10:31:36,068 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:40273
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:42595
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:38745
2025-09-03 10:31:36,068 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:34739
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:33027
2025-09-03 10:31:36,068 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:45557
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:36353
2025-09-03 10:31:36,068 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:37191
2025-09-03 10:31:36,068 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:34845
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:36445
2025-09-03 10:31:36,068 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:39945
2025-09-03 10:31:36,068 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:38261
2025-09-03 10:31:36,068 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:40865
2025-09-03 10:31:36,068 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:36333
2025-09-03 10:31:36,068 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:39023
2025-09-03 10:31:36,068 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:41229
2025-09-03 10:31:36,068 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:39251
2025-09-03 10:31:36,068 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:44079
2025-09-03 10:31:36,068 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:35721
2025-09-03 10:31:36,068 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:46697
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:37979
2025-09-03 10:31:36,069 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:42595
2025-09-03 10:31:36,069 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:38745
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:33413
2025-09-03 10:31:36,069 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:33027
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:39533
2025-09-03 10:31:36,069 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:36353
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:45175
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:45553
2025-09-03 10:31:36,069 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:36445
2025-09-03 10:31:36,069 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:39945
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:34691
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:35643
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:33505
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:44601
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:35411
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:41003
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:46427
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:44773
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:42633
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:46609
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:45805
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:35829
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:40235
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:40819
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO -          dashboard at:          10.6.102.15:37317
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-rpn9rs7l
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-p06mjnk4
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_1uhe4d8
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-m_43g42w
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-2o0sl4z5
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-66ds87xt
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,069 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-2g5lr7m8
2025-09-03 10:31:36,069 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zws8l62u
2025-09-03 10:31:36,069 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,069 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-5pfow7v8
2025-09-03 10:31:36,069 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-jvz8gpk4
2025-09-03 10:31:36,070 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-bvkhm48z
2025-09-03 10:31:36,069 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_gt9wmvs
2025-09-03 10:31:36,069 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fu5c7tc2
2025-09-03 10:31:36,070 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-tmtwpp7p
2025-09-03 10:31:36,070 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-lme_6rgw
2025-09-03 10:31:36,070 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-pnpju5_v
2025-09-03 10:31:36,070 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ua0o056b
2025-09-03 10:31:36,070 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9hue0a99
2025-09-03 10:31:36,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,070 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-oxjf1z2s
2025-09-03 10:31:36,070 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-y8qkn99m
2025-09-03 10:31:36,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,172 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:44407
2025-09-03 10:31:36,172 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:44407
2025-09-03 10:31:36,172 - distributed.worker - INFO -          dashboard at:          10.6.102.15:46605
2025-09-03 10:31:36,172 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,172 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,172 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,172 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,172 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-2wf_dt6n
2025-09-03 10:31:36,172 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,183 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:46787
2025-09-03 10:31:36,184 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:46787
2025-09-03 10:31:36,184 - distributed.worker - INFO -          dashboard at:          10.6.102.15:42685
2025-09-03 10:31:36,184 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,184 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,184 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,184 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,184 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-c6q6nlvy
2025-09-03 10:31:36,184 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,203 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:46343
2025-09-03 10:31:36,203 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:46343
2025-09-03 10:31:36,203 - distributed.worker - INFO -          dashboard at:          10.6.102.15:43123
2025-09-03 10:31:36,203 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,203 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,203 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,203 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,203 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fh2n8rfv
2025-09-03 10:31:36,203 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,204 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:34061
2025-09-03 10:31:36,204 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:34061
2025-09-03 10:31:36,205 - distributed.worker - INFO -          dashboard at:          10.6.102.15:42495
2025-09-03 10:31:36,205 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,205 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,205 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,205 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,205 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3etl06dv
2025-09-03 10:31:36,205 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,207 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:37269
2025-09-03 10:31:36,207 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:37269
2025-09-03 10:31:36,207 - distributed.worker - INFO -          dashboard at:          10.6.102.15:35951
2025-09-03 10:31:36,207 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,207 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,207 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,207 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,207 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-w97zpkb8
2025-09-03 10:31:36,207 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,212 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:33285
2025-09-03 10:31:36,212 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:33285
2025-09-03 10:31:36,212 - distributed.worker - INFO -          dashboard at:          10.6.102.15:38689
2025-09-03 10:31:36,212 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,212 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,212 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,212 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,212 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-u9i4n4q6
2025-09-03 10:31:36,212 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,354 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:45961
2025-09-03 10:31:36,354 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:45961
2025-09-03 10:31:36,355 - distributed.worker - INFO -          dashboard at:          10.6.102.15:38363
2025-09-03 10:31:36,355 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,355 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,355 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,355 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,355 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-q6i7h8b_
2025-09-03 10:31:36,355 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,357 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:42957
2025-09-03 10:31:36,358 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:42957
2025-09-03 10:31:36,358 - distributed.worker - INFO -          dashboard at:          10.6.102.15:41417
2025-09-03 10:31:36,358 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,358 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,358 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,358 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,358 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-x2qpmyh9
2025-09-03 10:31:36,358 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,381 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:33665
2025-09-03 10:31:36,381 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:33665
2025-09-03 10:31:36,381 - distributed.worker - INFO -          dashboard at:          10.6.102.15:33675
2025-09-03 10:31:36,381 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,381 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,381 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,381 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,381 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-b7yb5i02
2025-09-03 10:31:36,381 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,387 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:43945
2025-09-03 10:31:36,387 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:43945
2025-09-03 10:31:36,387 - distributed.worker - INFO -          dashboard at:          10.6.102.15:33573
2025-09-03 10:31:36,387 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,387 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,387 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,387 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,387 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-qpifywnu
2025-09-03 10:31:36,387 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,391 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:45975
2025-09-03 10:31:36,391 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:45975
2025-09-03 10:31:36,391 - distributed.worker - INFO -          dashboard at:          10.6.102.15:33055
2025-09-03 10:31:36,391 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,391 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,391 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,391 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,391 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-1f6nz_04
2025-09-03 10:31:36,392 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,394 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:40709
2025-09-03 10:31:36,394 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:40709
2025-09-03 10:31:36,394 - distributed.worker - INFO -          dashboard at:          10.6.102.15:44887
2025-09-03 10:31:36,394 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,394 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,394 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,394 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,394 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ntwvwmdj
2025-09-03 10:31:36,394 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,405 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:40657
2025-09-03 10:31:36,405 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:40657
2025-09-03 10:31:36,405 - distributed.worker - INFO -          dashboard at:          10.6.102.15:41093
2025-09-03 10:31:36,405 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,405 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,405 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,405 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,405 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_yi_wt22
2025-09-03 10:31:36,405 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,417 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:32991
2025-09-03 10:31:36,417 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:32991
2025-09-03 10:31:36,417 - distributed.worker - INFO -          dashboard at:          10.6.102.15:45577
2025-09-03 10:31:36,417 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,417 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,417 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,417 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,417 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9z0_m57x
2025-09-03 10:31:36,417 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,436 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:43287
2025-09-03 10:31:36,436 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:43287
2025-09-03 10:31:36,436 - distributed.worker - INFO -          dashboard at:          10.6.102.15:33127
2025-09-03 10:31:36,436 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,436 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,436 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,436 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,436 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-gsdggnl8
2025-09-03 10:31:36,436 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,438 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:33061
2025-09-03 10:31:36,438 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:33061
2025-09-03 10:31:36,438 - distributed.worker - INFO -          dashboard at:          10.6.102.15:46665
2025-09-03 10:31:36,438 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,438 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,438 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,438 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,438 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-jsbep0nk
2025-09-03 10:31:36,438 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,445 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:40927
2025-09-03 10:31:36,445 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:40927
2025-09-03 10:31:36,445 - distributed.worker - INFO -          dashboard at:          10.6.102.15:33359
2025-09-03 10:31:36,445 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,445 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,445 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,445 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,445 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-rntg7bcj
2025-09-03 10:31:36,445 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,522 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:41705
2025-09-03 10:31:36,522 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:41705
2025-09-03 10:31:36,522 - distributed.worker - INFO -          dashboard at:          10.6.102.15:41511
2025-09-03 10:31:36,523 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,523 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,523 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,523 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,523 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-0hpkqu2n
2025-09-03 10:31:36,523 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,546 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:36305
2025-09-03 10:31:36,546 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:36305
2025-09-03 10:31:36,547 - distributed.worker - INFO -          dashboard at:          10.6.102.15:46305
2025-09-03 10:31:36,547 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,547 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,547 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,547 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-yd6m0eg6
2025-09-03 10:31:36,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,615 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:34633
2025-09-03 10:31:36,615 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:34633
2025-09-03 10:31:36,615 - distributed.worker - INFO -          dashboard at:          10.6.102.15:45023
2025-09-03 10:31:36,615 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,615 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,615 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,615 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,615 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-trmpc_e5
2025-09-03 10:31:36,615 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,626 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:35239
2025-09-03 10:31:36,626 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:35239
2025-09-03 10:31:36,626 - distributed.worker - INFO -          dashboard at:          10.6.102.15:44513
2025-09-03 10:31:36,626 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,626 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,626 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,626 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,626 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-wglk2ric
2025-09-03 10:31:36,626 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,738 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:34981
2025-09-03 10:31:36,738 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:34981
2025-09-03 10:31:36,738 - distributed.worker - INFO -          dashboard at:          10.6.102.15:36775
2025-09-03 10:31:36,738 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,738 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,738 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,738 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,738 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ql4ntgxl
2025-09-03 10:31:36,739 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,741 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:46363
2025-09-03 10:31:36,741 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:46363
2025-09-03 10:31:36,741 - distributed.worker - INFO -          dashboard at:          10.6.102.15:45049
2025-09-03 10:31:36,741 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,741 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,741 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,741 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,741 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-nrs410kq
2025-09-03 10:31:36,741 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,183 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:33039
2025-09-03 10:31:37,183 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:33039
2025-09-03 10:31:37,183 - distributed.worker - INFO -          dashboard at:          10.6.102.15:44423
2025-09-03 10:31:37,183 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,183 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,183 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,183 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,183 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7ggae0bu
2025-09-03 10:31:37,183 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,202 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:37917
2025-09-03 10:31:37,202 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:37917
2025-09-03 10:31:37,202 - distributed.worker - INFO -          dashboard at:          10.6.102.15:42737
2025-09-03 10:31:37,202 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,202 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,202 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,202 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,202 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-swjnxnxv
2025-09-03 10:31:37,202 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,505 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:37195
2025-09-03 10:31:37,505 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:37195
2025-09-03 10:31:37,505 - distributed.worker - INFO -          dashboard at:          10.6.102.15:44229
2025-09-03 10:31:37,505 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,505 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,505 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,505 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,505 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7bgcw2d4
2025-09-03 10:31:37,505 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,511 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:35079
2025-09-03 10:31:37,511 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:35079
2025-09-03 10:31:37,511 - distributed.worker - INFO -          dashboard at:          10.6.102.15:39481
2025-09-03 10:31:37,511 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,511 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,511 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,511 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,511 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-gvf7egvw
2025-09-03 10:31:37,511 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,513 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:43003
2025-09-03 10:31:37,513 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:43003
2025-09-03 10:31:37,513 - distributed.worker - INFO -          dashboard at:          10.6.102.15:39137
2025-09-03 10:31:37,513 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,513 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,513 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,513 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,513 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fqwszct8
2025-09-03 10:31:37,513 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,516 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:38157
2025-09-03 10:31:37,516 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:38157
2025-09-03 10:31:37,516 - distributed.worker - INFO -          dashboard at:          10.6.102.15:42219
2025-09-03 10:31:37,516 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,516 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,516 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,516 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,516 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-laidvhm1
2025-09-03 10:31:37,516 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,526 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:35483
2025-09-03 10:31:37,527 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:35483
2025-09-03 10:31:37,527 - distributed.worker - INFO -          dashboard at:          10.6.102.15:39571
2025-09-03 10:31:37,527 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,527 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,527 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,527 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,527 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_s2g2ikj
2025-09-03 10:31:37,527 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,546 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:42461
2025-09-03 10:31:37,547 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:42461
2025-09-03 10:31:37,547 - distributed.worker - INFO -          dashboard at:          10.6.102.15:46317
2025-09-03 10:31:37,547 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,547 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,547 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,547 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_c85q45p
2025-09-03 10:31:37,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,553 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:42481
2025-09-03 10:31:37,553 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:42481
2025-09-03 10:31:37,553 - distributed.worker - INFO -          dashboard at:          10.6.102.15:42895
2025-09-03 10:31:37,553 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,553 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,553 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,553 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-w6l0gu74
2025-09-03 10:31:37,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,559 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:42757
2025-09-03 10:31:37,559 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:42757
2025-09-03 10:31:37,559 - distributed.worker - INFO -          dashboard at:          10.6.102.15:39757
2025-09-03 10:31:37,559 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,559 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,559 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,559 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,559 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-jmn5cniy
2025-09-03 10:31:37,559 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,562 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:34711
2025-09-03 10:31:37,562 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:34711
2025-09-03 10:31:37,562 - distributed.worker - INFO -          dashboard at:          10.6.102.15:39039
2025-09-03 10:31:37,562 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,562 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,563 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,563 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-snc7vr7_
2025-09-03 10:31:37,563 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,567 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:36279
2025-09-03 10:31:37,567 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:36279
2025-09-03 10:31:37,567 - distributed.worker - INFO -          dashboard at:          10.6.102.15:36341
2025-09-03 10:31:37,567 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,567 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,567 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,567 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,567 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-53apxm4a
2025-09-03 10:31:37,567 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,569 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:34015
2025-09-03 10:31:37,569 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:34015
2025-09-03 10:31:37,569 - distributed.worker - INFO -          dashboard at:          10.6.102.15:39619
2025-09-03 10:31:37,569 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,569 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,569 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,570 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,570 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-aghmtu87
2025-09-03 10:31:37,570 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,585 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:39327
2025-09-03 10:31:37,585 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:39327
2025-09-03 10:31:37,585 - distributed.worker - INFO -          dashboard at:          10.6.102.15:43197
2025-09-03 10:31:37,585 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,585 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,585 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,585 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,585 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-kjl35vl5
2025-09-03 10:31:37,585 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,588 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:40367
2025-09-03 10:31:37,588 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:40367
2025-09-03 10:31:37,588 - distributed.worker - INFO -          dashboard at:          10.6.102.15:44475
2025-09-03 10:31:37,588 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,588 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,588 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,588 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,588 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ch27runb
2025-09-03 10:31:37,588 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,591 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:41183
2025-09-03 10:31:37,591 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:41183
2025-09-03 10:31:37,591 - distributed.worker - INFO -          dashboard at:          10.6.102.15:40969
2025-09-03 10:31:37,591 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,591 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,591 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,591 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,591 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-uulz6sry
2025-09-03 10:31:37,592 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,593 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:35213
2025-09-03 10:31:37,593 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:35213
2025-09-03 10:31:37,593 - distributed.worker - INFO -          dashboard at:          10.6.102.15:38385
2025-09-03 10:31:37,593 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,593 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,593 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,593 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,593 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-nnvgi792
2025-09-03 10:31:37,593 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,595 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:42387
2025-09-03 10:31:37,595 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:42387
2025-09-03 10:31:37,595 - distributed.worker - INFO -          dashboard at:          10.6.102.15:36741
2025-09-03 10:31:37,595 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,595 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,595 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,595 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,595 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-thrh8chf
2025-09-03 10:31:37,595 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,596 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:36183
2025-09-03 10:31:37,596 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:36183
2025-09-03 10:31:37,596 - distributed.worker - INFO -          dashboard at:          10.6.102.15:44105
2025-09-03 10:31:37,596 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,596 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,596 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,596 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7w9iy3w6
2025-09-03 10:31:37,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,598 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:45625
2025-09-03 10:31:37,598 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:45625
2025-09-03 10:31:37,598 - distributed.worker - INFO -          dashboard at:          10.6.102.15:43611
2025-09-03 10:31:37,598 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,598 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,598 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,598 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,598 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-knewfc6f
2025-09-03 10:31:37,598 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,605 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:40891
2025-09-03 10:31:37,605 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:40891
2025-09-03 10:31:37,605 - distributed.worker - INFO -          dashboard at:          10.6.102.15:46709
2025-09-03 10:31:37,605 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,605 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,605 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,605 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,605 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-y94_g8tk
2025-09-03 10:31:37,605 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,610 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:36065
2025-09-03 10:31:37,610 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:36065
2025-09-03 10:31:37,610 - distributed.worker - INFO -          dashboard at:          10.6.102.15:41551
2025-09-03 10:31:37,610 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,610 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,610 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,610 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,610 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zd13ufbl
2025-09-03 10:31:37,610 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,615 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:36459
2025-09-03 10:31:37,615 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:36459
2025-09-03 10:31:37,615 - distributed.worker - INFO -          dashboard at:          10.6.102.15:45451
2025-09-03 10:31:37,615 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,615 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,615 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,615 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,615 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-lkmc6jei
2025-09-03 10:31:37,615 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,617 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:33435
2025-09-03 10:31:37,617 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:33435
2025-09-03 10:31:37,617 - distributed.worker - INFO -          dashboard at:          10.6.102.15:36657
2025-09-03 10:31:37,617 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,617 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,617 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,617 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,617 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-907ufg9v
2025-09-03 10:31:37,617 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,626 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:42853
2025-09-03 10:31:37,626 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:42853
2025-09-03 10:31:37,626 - distributed.worker - INFO -          dashboard at:          10.6.102.15:43803
2025-09-03 10:31:37,626 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,626 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,626 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,626 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,626 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-vqc5vpby
2025-09-03 10:31:37,626 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,628 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:35815
2025-09-03 10:31:37,629 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:35815
2025-09-03 10:31:37,629 - distributed.worker - INFO -          dashboard at:          10.6.102.15:34209
2025-09-03 10:31:37,629 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,629 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,629 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,629 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,629 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-v7zts3ta
2025-09-03 10:31:37,629 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,631 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:41235
2025-09-03 10:31:37,631 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:41235
2025-09-03 10:31:37,631 - distributed.worker - INFO -          dashboard at:          10.6.102.15:44349
2025-09-03 10:31:37,631 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,631 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,631 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,631 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,631 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-39aizuk3
2025-09-03 10:31:37,631 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,640 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:40681
2025-09-03 10:31:37,640 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:40681
2025-09-03 10:31:37,640 - distributed.worker - INFO -          dashboard at:          10.6.102.15:32909
2025-09-03 10:31:37,640 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,640 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,640 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,640 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,640 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-jdgmuzne
2025-09-03 10:31:37,640 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,648 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:39909
2025-09-03 10:31:37,648 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:39909
2025-09-03 10:31:37,648 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:38125
2025-09-03 10:31:37,648 - distributed.worker - INFO -          dashboard at:          10.6.102.15:37005
2025-09-03 10:31:37,648 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:38125
2025-09-03 10:31:37,648 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,648 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,648 - distributed.worker - INFO -          dashboard at:          10.6.102.15:46829
2025-09-03 10:31:37,648 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,648 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,648 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,648 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,648 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,648 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-bh16d9ks
2025-09-03 10:31:37,648 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,648 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,648 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9wqc151v
2025-09-03 10:31:37,648 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,686 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:38781
2025-09-03 10:31:37,686 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:38781
2025-09-03 10:31:37,686 - distributed.worker - INFO -          dashboard at:          10.6.102.15:40553
2025-09-03 10:31:37,686 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,686 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,686 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,686 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,686 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-0_x4fqki
2025-09-03 10:31:37,686 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,689 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:36703
2025-09-03 10:31:37,689 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:36703
2025-09-03 10:31:37,689 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:33813
2025-09-03 10:31:37,689 - distributed.worker - INFO -          dashboard at:          10.6.102.15:42829
2025-09-03 10:31:37,689 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:33813
2025-09-03 10:31:37,689 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,689 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,689 - distributed.worker - INFO -          dashboard at:          10.6.102.15:42235
2025-09-03 10:31:37,689 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,689 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,689 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,689 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,689 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,689 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-73wpfnoh
2025-09-03 10:31:37,689 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,689 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,689 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-68_d_vy1
2025-09-03 10:31:37,689 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,700 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:34443
2025-09-03 10:31:37,700 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:34443
2025-09-03 10:31:37,700 - distributed.worker - INFO -          dashboard at:          10.6.102.15:41211
2025-09-03 10:31:37,700 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,700 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,700 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,700 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,700 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4b7d_326
2025-09-03 10:31:37,700 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,705 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:41033
2025-09-03 10:31:37,705 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:41033
2025-09-03 10:31:37,705 - distributed.worker - INFO -          dashboard at:          10.6.102.15:35741
2025-09-03 10:31:37,705 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,705 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,705 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,706 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,706 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-qi60mljb
2025-09-03 10:31:37,706 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,890 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:46177
2025-09-03 10:31:37,890 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:43487
2025-09-03 10:31:37,890 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:46177
2025-09-03 10:31:37,890 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:43487
2025-09-03 10:31:37,890 - distributed.worker - INFO -          dashboard at:          10.6.102.15:38755
2025-09-03 10:31:37,890 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,890 - distributed.worker - INFO -          dashboard at:          10.6.102.15:46599
2025-09-03 10:31:37,890 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,890 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,890 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,890 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,890 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,890 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,890 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,890 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zrk39jx4
2025-09-03 10:31:37,890 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-u60y3ycr
2025-09-03 10:31:37,890 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,890 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,890 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:38503
2025-09-03 10:31:37,891 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:38503
2025-09-03 10:31:37,891 - distributed.worker - INFO -          dashboard at:          10.6.102.15:43015
2025-09-03 10:31:37,891 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,891 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,891 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,891 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,891 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-f9dufvpx
2025-09-03 10:31:37,891 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,892 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:36117
2025-09-03 10:31:37,892 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:36117
2025-09-03 10:31:37,892 - distributed.worker - INFO -          dashboard at:          10.6.102.15:38133
2025-09-03 10:31:37,892 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,892 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,892 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,892 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,892 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-c1hnrm81
2025-09-03 10:31:37,892 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,899 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:40533
2025-09-03 10:31:37,899 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:40533
2025-09-03 10:31:37,899 - distributed.worker - INFO -          dashboard at:          10.6.102.15:45789
2025-09-03 10:31:37,899 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,899 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,899 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,899 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,899 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-o6lpq0b7
2025-09-03 10:31:37,899 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,916 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:45421
2025-09-03 10:31:37,917 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:45421
2025-09-03 10:31:37,917 - distributed.worker - INFO -          dashboard at:          10.6.102.15:35895
2025-09-03 10:31:37,917 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,917 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,917 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,917 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,917 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-bcs0rj_u
2025-09-03 10:31:37,917 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,930 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:41635
2025-09-03 10:31:37,930 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:41635
2025-09-03 10:31:37,930 - distributed.worker - INFO -          dashboard at:          10.6.102.15:43675
2025-09-03 10:31:37,930 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,930 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,930 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,930 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,930 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-48kmrm99
2025-09-03 10:31:37,930 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,953 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:41139
2025-09-03 10:31:37,953 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:41139
2025-09-03 10:31:37,953 - distributed.worker - INFO -          dashboard at:          10.6.102.15:37733
2025-09-03 10:31:37,953 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,953 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,953 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,953 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,953 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-93ih849r
2025-09-03 10:31:37,953 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,080 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:33499
2025-09-03 10:31:38,080 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:33499
2025-09-03 10:31:38,080 - distributed.worker - INFO -          dashboard at:          10.6.102.15:40119
2025-09-03 10:31:38,080 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,080 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,080 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,081 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-a2ggvfc2
2025-09-03 10:31:38,081 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,121 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:33771
2025-09-03 10:31:38,121 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:33771
2025-09-03 10:31:38,121 - distributed.worker - INFO -          dashboard at:          10.6.102.15:38603
2025-09-03 10:31:38,121 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,121 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,121 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,121 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,122 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7hddaggu
2025-09-03 10:31:38,122 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,136 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:38839
2025-09-03 10:31:38,136 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:38839
2025-09-03 10:31:38,136 - distributed.worker - INFO -          dashboard at:          10.6.102.15:43871
2025-09-03 10:31:38,136 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,136 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,136 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,136 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,136 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fgrorouj
2025-09-03 10:31:38,136 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,154 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:44745
2025-09-03 10:31:38,154 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:44745
2025-09-03 10:31:38,154 - distributed.worker - INFO -          dashboard at:          10.6.102.15:41709
2025-09-03 10:31:38,155 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,155 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,155 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,155 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,155 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-r6x7pr3f
2025-09-03 10:31:38,155 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,171 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:35413
2025-09-03 10:31:38,171 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:35413
2025-09-03 10:31:38,171 - distributed.worker - INFO -          dashboard at:          10.6.102.15:33165
2025-09-03 10:31:38,171 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,171 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,171 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,171 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,171 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-z1y6fh4a
2025-09-03 10:31:38,171 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,186 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:39751
2025-09-03 10:31:38,186 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:39751
2025-09-03 10:31:38,187 - distributed.worker - INFO -          dashboard at:          10.6.102.15:44899
2025-09-03 10:31:38,187 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,187 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,187 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,187 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,187 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-tiwghlru
2025-09-03 10:31:38,187 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,191 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:33159
2025-09-03 10:31:38,191 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:33159
2025-09-03 10:31:38,191 - distributed.worker - INFO -          dashboard at:          10.6.102.15:45143
2025-09-03 10:31:38,191 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,191 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,191 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,191 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,191 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fp7ix5hg
2025-09-03 10:31:38,191 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,212 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:45835
2025-09-03 10:31:38,212 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:45835
2025-09-03 10:31:38,212 - distributed.worker - INFO -          dashboard at:          10.6.102.15:37719
2025-09-03 10:31:38,212 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,212 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,212 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,212 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,212 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-jvvfd1er
2025-09-03 10:31:38,212 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,226 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:43735
2025-09-03 10:31:38,227 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:43735
2025-09-03 10:31:38,227 - distributed.worker - INFO -          dashboard at:          10.6.102.15:36719
2025-09-03 10:31:38,227 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,227 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,227 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,227 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,227 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-55583br5
2025-09-03 10:31:38,227 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,259 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:35041
2025-09-03 10:31:38,259 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:35041
2025-09-03 10:31:38,259 - distributed.worker - INFO -          dashboard at:          10.6.102.15:38497
2025-09-03 10:31:38,259 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,259 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,259 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,259 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,259 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-qap2imln
2025-09-03 10:31:38,259 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,260 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:37687
2025-09-03 10:31:38,260 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:37687
2025-09-03 10:31:38,260 - distributed.worker - INFO -          dashboard at:          10.6.102.15:37849
2025-09-03 10:31:38,260 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,260 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,260 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,260 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,260 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-rmt1e1fl
2025-09-03 10:31:38,260 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,267 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:38235
2025-09-03 10:31:38,267 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:38235
2025-09-03 10:31:38,267 - distributed.worker - INFO -          dashboard at:          10.6.102.15:36267
2025-09-03 10:31:38,267 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,267 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,267 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,267 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,267 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-o2yq2ip6
2025-09-03 10:31:38,267 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,268 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:43591
2025-09-03 10:31:38,268 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:43591
2025-09-03 10:31:38,269 - distributed.worker - INFO -          dashboard at:          10.6.102.15:42447
2025-09-03 10:31:38,269 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,269 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,269 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,269 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,269 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-jpru226v
2025-09-03 10:31:38,269 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,277 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:38219
2025-09-03 10:31:38,277 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:34961
2025-09-03 10:31:38,277 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:38219
2025-09-03 10:31:38,278 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:34961
2025-09-03 10:31:38,278 - distributed.worker - INFO -          dashboard at:          10.6.102.15:38569
2025-09-03 10:31:38,278 - distributed.worker - INFO -          dashboard at:          10.6.102.15:33029
2025-09-03 10:31:38,278 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,278 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,278 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,278 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,278 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,278 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,278 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,278 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,278 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-i45tqxey
2025-09-03 10:31:38,278 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-bybv1vw4
2025-09-03 10:31:38,278 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,278 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,279 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:37017
2025-09-03 10:31:38,279 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:37017
2025-09-03 10:31:38,279 - distributed.worker - INFO -          dashboard at:          10.6.102.15:35325
2025-09-03 10:31:38,279 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,279 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,279 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,279 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,279 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-cje29q5j
2025-09-03 10:31:38,279 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,281 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:35675
2025-09-03 10:31:38,281 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:35675
2025-09-03 10:31:38,281 - distributed.worker - INFO -          dashboard at:          10.6.102.15:38799
2025-09-03 10:31:38,281 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,281 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,281 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,281 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,281 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fhcmcc0v
2025-09-03 10:31:38,281 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,283 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.15:37015
2025-09-03 10:31:38,283 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.15:37015
2025-09-03 10:31:38,283 - distributed.worker - INFO -          dashboard at:          10.6.102.15:44929
2025-09-03 10:31:38,283 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,283 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,283 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,283 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,283 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3cywc3ip
2025-09-03 10:31:38,283 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,346 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,347 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,347 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,348 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,357 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,358 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,358 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,360 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,368 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,369 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,370 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,371 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,390 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,391 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,392 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,393 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,394 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,398 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,398 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,402 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,403 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,403 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,403 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,405 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,413 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,414 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,414 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,416 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,424 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,426 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,426 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,427 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,435 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,436 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,436 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,438 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,450 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,454 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,454 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,458 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,459 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,459 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,460 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,460 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,469 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,470 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,470 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,472 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,480 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,481 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,481 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,483 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,491 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,492 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,492 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,494 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,502 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,503 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,503 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,505 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,514 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,515 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,515 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,517 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,524 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,526 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,526 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,527 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,536 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,537 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,537 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,539 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,547 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,548 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,548 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,550 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,558 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,559 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,559 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,561 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,312 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,313 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,314 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,316 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,324 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,325 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,325 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,327 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,779 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,780 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,781 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,782 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,791 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,792 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,792 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,794 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,802 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,803 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,803 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,805 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,814 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,815 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,815 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,817 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,837 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,838 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,838 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,840 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,884 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,885 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,885 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,887 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,918 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,920 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,920 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,922 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:40,010 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:40,012 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:40,012 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:40,014 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:40,739 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:40,740 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:40,741 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:40,743 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:40,763 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:40,764 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:40,765 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:40,767 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:40,966 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:40,968 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:40,968 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:40,970 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:40,978 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:40,979 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:40,979 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:40,981 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:40,989 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:40,990 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:40,990 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:40,992 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,458 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,459 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,459 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,461 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,469 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,471 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,473 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,481 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,482 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,482 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,484 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,492 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,494 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,494 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,496 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,504 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,505 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,505 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,507 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,810 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,811 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,812 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,813 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,823 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,824 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,824 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,826 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,786 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,788 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,788 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,790 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,798 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,799 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,800 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,802 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,578 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,597 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,598 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,606 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,252 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,254 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,254 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,256 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,277 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,279 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,279 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,280 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,314 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,315 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,315 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,317 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,326 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,328 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,328 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,330 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,350 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,352 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,352 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,354 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,012 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,013 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,014 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,015 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,124 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,125 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,125 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,127 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,136 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,138 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,138 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,140 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,149 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,150 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,150 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,152 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,161 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,162 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,162 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,164 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,173 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,174 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,175 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,176 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,185 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,187 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,187 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,188 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,197 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,199 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,199 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,201 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,210 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,211 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,212 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,213 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,391 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,393 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,393 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,394 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,403 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,405 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,405 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,407 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,415 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,417 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,417 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,419 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,428 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,430 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,430 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,432 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,440 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,442 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,442 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,444 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,454 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,457 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,457 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,460 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,464 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,465 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,466 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,467 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,478 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,479 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,479 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,481 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,490 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,491 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,491 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,493 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,502 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,504 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,504 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,506 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,514 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,516 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,516 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,518 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,526 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,528 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,528 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,530 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,539 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,541 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,541 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,543 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,551 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,552 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,552 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,554 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,717 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,718 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,718 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,720 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,547 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,549 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,549 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,551 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,561 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,562 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,564 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,573 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,575 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,575 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,576 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,586 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,587 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,587 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,589 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,598 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,600 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,600 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,602 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:51,785 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:51,786 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:51,786 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:51,788 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:51,852 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:51,853 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:51,853 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:51,855 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:51,879 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:51,880 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:51,880 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:51,882 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:51,919 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:51,921 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:51,921 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:51,922 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:51,932 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:51,933 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:51,933 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:51,935 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:51,946 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:51,948 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:51,948 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:51,950 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:51,959 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:51,961 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:51,961 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:51,963 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:51,973 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:51,975 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:51,975 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:51,976 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:52,391 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:52,395 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:52,395 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:52,399 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:52,420 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:52,424 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:52,424 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:52,429 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:06,356 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,359 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,382 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,388 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,393 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,396 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,407 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,419 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,438 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,440 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,447 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,524 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,548 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:07,687 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:07,691 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:09,611 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:09,613 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:09,613 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:09,615 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:09,630 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:09,631 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:09,631 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:09,633 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:10,317 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:10,329 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:10,786 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:10,796 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:10,889 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:12,715 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:12,717 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:12,717 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:12,719 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:12,731 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:12,733 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:12,733 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:12,735 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:12,747 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:12,749 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:12,749 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:12,750 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:12,763 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:12,765 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:12,765 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:12,767 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:14,404 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:14,405 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:14,406 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:14,407 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:16,423 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:16,434 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:16,533 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:16,545 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:16,557 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:25,136 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:25,137 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:25,137 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:25,139 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:32,545 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:32,546 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:32,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:32,548 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:32,562 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:32,564 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:32,564 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:32,566 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:36,509 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:36,521 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:36,540 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:36,542 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:36,549 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:41,784 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:41,796 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:41,890 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:45,409 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:47,510 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:47,512 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:47,512 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:47,513 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:47,528 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:47,529 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:47,530 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:47,531 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:47,546 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:47,547 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:47,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:47,549 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:47,563 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:47,565 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:47,565 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:47,567 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:47,667 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:47,669 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:47,669 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:47,671 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:35:51,472 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,476 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,669 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,670 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,697 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,699 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,783 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,785 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,879 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,884 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,893 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,894 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,969 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,970 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,036 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,039 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,054 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,056 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,081 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,083 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,119 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,123 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,130 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,133 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,238 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,239 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,124 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,129 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,139 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,145 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,322 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,323 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,459 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,461 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,465 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,468 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,481 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,483 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,508 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,510 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,541 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,542 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,584 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,590 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,944 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,950 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,997 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,006 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,055 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,061 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,061 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,067 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,150 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,152 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,379 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,381 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,404 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,407 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,425 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,427 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,873 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,877 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,913 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,920 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,962 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,964 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,248 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,252 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,289 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,290 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,294 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,296 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,374 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,379 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,430 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,436 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,437 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,442 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,687 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,693 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,742 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,743 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,746 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,747 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,748 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,748 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,762 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,763 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,769 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,775 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,781 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,788 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,799 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,804 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,034 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,039 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,143 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,150 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,174 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,180 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,241 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,247 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,328 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,333 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,340 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,345 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,615 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,617 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,623 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,624 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,667 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,672 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,676 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,681 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,710 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,712 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,715 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,717 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,718 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,721 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,737 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,742 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,747 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,753 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,824 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,832 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,903 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,904 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,987 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,997 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,062 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,068 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,167 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,173 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,225 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,225 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,226 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,230 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,231 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,231 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,305 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,306 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,544 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,550 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,630 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,632 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,705 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,708 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,905 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,906 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,911 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,917 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,050 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,051 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,341 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,342 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,509 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,510 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,626 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,628 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,648 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,650 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,725 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,727 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,870 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,871 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,977 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,983 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,988 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,994 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,231 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,233 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,455 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,457 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,547 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,549 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,625 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,629 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,629 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,630 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,631 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,632 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,074 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,076 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,419 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,420 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,577 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,581 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,759 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,761 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,497 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,502 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,717 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,728 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,748 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,749 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,863 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,869 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,888 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,894 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:05,052 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:05,058 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:06,549 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:06,554 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:07,707 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:07,709 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:14,226 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:14,233 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:22,882 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,884 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,884 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,886 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,892 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,894 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,895 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,896 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,897 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,903 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,903 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,905 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,912 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,914 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,912 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,917 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,924 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,924 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,926 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,926 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,930 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,933 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,949 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,948 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,951 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,953 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,957 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,962 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,386 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,387 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,390 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,390 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,392 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,392 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,395 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,397 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,401 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,403 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,405 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,407 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,497 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,499 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,504 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,506 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,521 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,523 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,529 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,531 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,532 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,534 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,534 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,536 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,554 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,556 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,789 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,795 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,804 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,806 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,856 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,858 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,859 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,861 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,869 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,871 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,873 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,874 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,875 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,876 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,880 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,883 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,886 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,888 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,889 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,889 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,891 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,891 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,912 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,914 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,029 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,031 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,033 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,033 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,083 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,085 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,094 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,099 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,099 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,101 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,122 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,124 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,125 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,126 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,127 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,128 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,129 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,135 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,229 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,231 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,236 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,239 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,331 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,332 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,333 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,334 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,346 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,347 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,347 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,349 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,349 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,350 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,350 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,352 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,352 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,354 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,391 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,393 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,396 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,398 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,399 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,401 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,438 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,440 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,462 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,468 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,498 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,500 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,499 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,501 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,625 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,627 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,663 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,665 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,674 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,676 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,681 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,681 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,682 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,683 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,684 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,686 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,691 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,693 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,755 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,756 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,759 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,761 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,793 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,795 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,859 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,864 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,890 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,892 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,894 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,896 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,896 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,898 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,902 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,904 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,921 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,923 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,940 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,943 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,943 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,945 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,967 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,970 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,969 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,972 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,014 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,016 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,041 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,044 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,264 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,266 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,267 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,269 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,468 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,470 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,708 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,711 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,712 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,714 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,729 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,731 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,833 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,835 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,887 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,889 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,980 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,982 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,118 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,123 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,245 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,247 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,312 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,315 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,403 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,405 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,437 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,439 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,572 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,574 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,733 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,738 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,953 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,955 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:29,390 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:29,393 - distributed.utils - INFO - Reload module qme_vars from .py file
