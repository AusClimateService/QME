Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-10-02 09:24:27,447 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:46563'
2025-10-02 09:24:27,456 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:39119'
2025-10-02 09:24:27,460 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:39705'
2025-10-02 09:24:27,464 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:34567'
2025-10-02 09:24:27,468 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:35021'
2025-10-02 09:24:27,472 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:43665'
2025-10-02 09:24:27,476 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:33899'
2025-10-02 09:24:27,480 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:40017'
2025-10-02 09:24:27,485 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:33291'
2025-10-02 09:24:27,490 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:36971'
2025-10-02 09:24:27,494 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:42193'
2025-10-02 09:24:27,498 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:38365'
2025-10-02 09:24:27,503 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:36287'
2025-10-02 09:24:27,507 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:38035'
2025-10-02 09:24:27,511 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:46647'
2025-10-02 09:24:27,515 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:43953'
2025-10-02 09:24:27,520 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:35379'
2025-10-02 09:24:27,524 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:33599'
2025-10-02 09:24:27,529 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:33951'
2025-10-02 09:24:27,534 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:34181'
2025-10-02 09:24:27,643 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:34523'
2025-10-02 09:24:27,648 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:43441'
2025-10-02 09:24:27,653 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:34159'
2025-10-02 09:24:27,657 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:33523'
2025-10-02 09:24:27,662 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:38379'
2025-10-02 09:24:27,666 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:39547'
2025-10-02 09:24:27,671 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:42285'
2025-10-02 09:24:27,675 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:37511'
2025-10-02 09:24:27,680 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:37393'
2025-10-02 09:24:27,685 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:39277'
2025-10-02 09:24:27,691 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:39489'
2025-10-02 09:24:27,695 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:40111'
2025-10-02 09:24:27,699 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:33015'
2025-10-02 09:24:27,704 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:39103'
2025-10-02 09:24:27,709 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:46551'
2025-10-02 09:24:27,714 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:46361'
2025-10-02 09:24:27,719 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:41861'
2025-10-02 09:24:27,723 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:44819'
2025-10-02 09:24:27,727 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:41967'
2025-10-02 09:24:27,731 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:43493'
2025-10-02 09:24:27,736 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:39219'
2025-10-02 09:24:27,741 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:36571'
2025-10-02 09:24:27,745 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:36283'
2025-10-02 09:24:27,750 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:43445'
2025-10-02 09:24:27,754 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:40881'
2025-10-02 09:24:27,758 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:44813'
2025-10-02 09:24:27,762 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:42725'
2025-10-02 09:24:27,765 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:33275'
2025-10-02 09:24:27,769 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:45827'
2025-10-02 09:24:27,775 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:38415'
2025-10-02 09:24:27,783 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:39963'
2025-10-02 09:24:27,787 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:38525'
2025-10-02 09:24:28,585 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:43551
2025-10-02 09:24:28,585 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:41509
2025-10-02 09:24:28,585 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:38703
2025-10-02 09:24:28,585 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:43551
2025-10-02 09:24:28,585 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:45871
2025-10-02 09:24:28,585 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:41523
2025-10-02 09:24:28,585 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:45799
2025-10-02 09:24:28,585 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:41509
2025-10-02 09:24:28,585 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:38703
2025-10-02 09:24:28,585 - distributed.worker - INFO -          dashboard at:           10.6.83.15:33977
2025-10-02 09:24:28,585 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:45871
2025-10-02 09:24:28,585 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:41523
2025-10-02 09:24:28,585 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:45799
2025-10-02 09:24:28,585 - distributed.worker - INFO -          dashboard at:           10.6.83.15:46515
2025-10-02 09:24:28,585 - distributed.worker - INFO -          dashboard at:           10.6.83.15:39955
2025-10-02 09:24:28,585 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,585 - distributed.worker - INFO -          dashboard at:           10.6.83.15:39759
2025-10-02 09:24:28,585 - distributed.worker - INFO -          dashboard at:           10.6.83.15:44169
2025-10-02 09:24:28,585 - distributed.worker - INFO -          dashboard at:           10.6.83.15:38271
2025-10-02 09:24:28,585 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,585 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,585 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,585 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,585 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,585 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,585 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,585 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,585 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,585 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,585 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,585 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,585 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,585 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,585 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,585 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,585 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,585 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,585 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,585 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,585 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-lmnrz8rm
2025-10-02 09:24:28,585 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,585 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,585 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,585 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-ypkn9mjs
2025-10-02 09:24:28,585 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-cocrzy5l
2025-10-02 09:24:28,585 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,585 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-03poa8ei
2025-10-02 09:24:28,585 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-6qovbbci
2025-10-02 09:24:28,585 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-65c4wmmo
2025-10-02 09:24:28,585 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,585 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,585 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,585 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,585 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,596 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:46201
2025-10-02 09:24:28,596 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:46201
2025-10-02 09:24:28,596 - distributed.worker - INFO -          dashboard at:           10.6.83.15:46175
2025-10-02 09:24:28,596 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,596 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,596 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,596 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,596 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-367nmqan
2025-10-02 09:24:28,596 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,605 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:45261
2025-10-02 09:24:28,605 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:45261
2025-10-02 09:24:28,605 - distributed.worker - INFO -          dashboard at:           10.6.83.15:37109
2025-10-02 09:24:28,605 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,605 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,605 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,605 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,605 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-tll6bdg1
2025-10-02 09:24:28,605 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,611 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,611 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,611 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,612 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,615 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,616 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,616 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,617 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:35907
2025-10-02 09:24:28,617 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:35907
2025-10-02 09:24:28,617 - distributed.worker - INFO -          dashboard at:           10.6.83.15:33721
2025-10-02 09:24:28,617 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,617 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,617 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,617 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,617 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-dalnuyn1
2025-10-02 09:24:28,617 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,617 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,622 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,623 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,623 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,625 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:44491
2025-10-02 09:24:28,625 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:44491
2025-10-02 09:24:28,625 - distributed.worker - INFO -          dashboard at:           10.6.83.15:38169
2025-10-02 09:24:28,625 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,625 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,625 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,625 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,625 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-mc9xhdjf
2025-10-02 09:24:28,625 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,625 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,625 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,626 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,626 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,628 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,628 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,629 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,629 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,631 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,631 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,632 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,632 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,633 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,634 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,635 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,635 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,636 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:40895
2025-10-02 09:24:28,636 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:40895
2025-10-02 09:24:28,636 - distributed.worker - INFO -          dashboard at:           10.6.83.15:46147
2025-10-02 09:24:28,636 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,636 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,636 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,636 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,636 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-vd9w2big
2025-10-02 09:24:28,636 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,636 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,637 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,637 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,637 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,639 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,651 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:33083
2025-10-02 09:24:28,652 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:33083
2025-10-02 09:24:28,652 - distributed.worker - INFO -          dashboard at:           10.6.83.15:35119
2025-10-02 09:24:28,652 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,652 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,652 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,652 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,652 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-ntiplj_2
2025-10-02 09:24:28,652 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,656 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:38031
2025-10-02 09:24:28,656 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:38031
2025-10-02 09:24:28,657 - distributed.worker - INFO -          dashboard at:           10.6.83.15:37415
2025-10-02 09:24:28,657 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,657 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,657 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,657 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,657 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-mlm2x7yc
2025-10-02 09:24:28,657 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,658 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,659 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,659 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,661 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,661 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,661 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:41229
2025-10-02 09:24:28,662 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:41229
2025-10-02 09:24:28,662 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,662 - distributed.worker - INFO -          dashboard at:           10.6.83.15:39493
2025-10-02 09:24:28,662 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,662 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,662 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,662 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,662 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,662 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-cpf1qq8i
2025-10-02 09:24:28,662 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,663 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,663 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,664 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,664 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,665 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,671 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,672 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,672 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,673 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,680 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,681 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,681 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,682 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,682 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,682 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:36171
2025-10-02 09:24:28,682 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:36171
2025-10-02 09:24:28,683 - distributed.worker - INFO -          dashboard at:           10.6.83.15:44659
2025-10-02 09:24:28,683 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,683 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,683 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,683 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,683 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:44555
2025-10-02 09:24:28,683 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-is6fq8n3
2025-10-02 09:24:28,683 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:44555
2025-10-02 09:24:28,683 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,683 - distributed.worker - INFO -          dashboard at:           10.6.83.15:39281
2025-10-02 09:24:28,683 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,683 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,683 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,683 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,683 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-3iy7d3b1
2025-10-02 09:24:28,683 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,683 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,683 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,685 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,686 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:38275
2025-10-02 09:24:28,686 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:38275
2025-10-02 09:24:28,686 - distributed.worker - INFO -          dashboard at:           10.6.83.15:45313
2025-10-02 09:24:28,686 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,686 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,686 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,686 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,687 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-z22ncifa
2025-10-02 09:24:28,687 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,690 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:38253
2025-10-02 09:24:28,690 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:38253
2025-10-02 09:24:28,690 - distributed.worker - INFO -          dashboard at:           10.6.83.15:44793
2025-10-02 09:24:28,690 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,690 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,690 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,690 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,690 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-xpqz7r1o
2025-10-02 09:24:28,690 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,702 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,702 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,702 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,703 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,707 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,708 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,708 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,709 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,710 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,711 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,711 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,713 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,713 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,714 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,714 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,716 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,777 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:41567
2025-10-02 09:24:28,778 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:41567
2025-10-02 09:24:28,778 - distributed.worker - INFO -          dashboard at:           10.6.83.15:40755
2025-10-02 09:24:28,778 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,778 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,778 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,778 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,778 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-ldlzyghj
2025-10-02 09:24:28,778 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,802 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,802 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,803 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,804 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,813 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:38193
2025-10-02 09:24:28,813 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:38193
2025-10-02 09:24:28,813 - distributed.worker - INFO -          dashboard at:           10.6.83.15:45263
2025-10-02 09:24:28,813 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,813 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,813 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,813 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,813 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-a2b4p19n
2025-10-02 09:24:28,813 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,815 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:36027
2025-10-02 09:24:28,815 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:36027
2025-10-02 09:24:28,815 - distributed.worker - INFO -          dashboard at:           10.6.83.15:42817
2025-10-02 09:24:28,815 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,816 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,816 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,816 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,816 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-wm49lxft
2025-10-02 09:24:28,816 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,836 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,837 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,838 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,839 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,841 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,842 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,842 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,844 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,845 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:45113
2025-10-02 09:24:28,845 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:45113
2025-10-02 09:24:28,845 - distributed.worker - INFO -          dashboard at:           10.6.83.15:34275
2025-10-02 09:24:28,845 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,845 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,845 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,845 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,845 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-zmakcoj1
2025-10-02 09:24:28,845 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,876 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,877 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,877 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,879 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:28,935 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:39427
2025-10-02 09:24:28,936 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:39427
2025-10-02 09:24:28,936 - distributed.worker - INFO -          dashboard at:           10.6.83.15:34125
2025-10-02 09:24:28,936 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,936 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,936 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:28,936 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:28,936 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-lv2zbi9l
2025-10-02 09:24:28,936 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,960 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:28,961 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:28,961 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:28,963 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,048 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:45245
2025-10-02 09:24:29,048 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:45245
2025-10-02 09:24:29,048 - distributed.worker - INFO -          dashboard at:           10.6.83.15:35327
2025-10-02 09:24:29,048 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,048 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,048 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,048 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,048 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-h6sqztm_
2025-10-02 09:24:29,048 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,061 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:36673
2025-10-02 09:24:29,061 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:36673
2025-10-02 09:24:29,062 - distributed.worker - INFO -          dashboard at:           10.6.83.15:42119
2025-10-02 09:24:29,062 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,062 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,062 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,062 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,062 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-rdxjksjt
2025-10-02 09:24:29,062 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,064 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:43329
2025-10-02 09:24:29,064 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:43329
2025-10-02 09:24:29,065 - distributed.worker - INFO -          dashboard at:           10.6.83.15:43099
2025-10-02 09:24:29,065 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,065 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,065 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,065 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,065 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-o6t_g_si
2025-10-02 09:24:29,065 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,072 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:35217
2025-10-02 09:24:29,072 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:35217
2025-10-02 09:24:29,072 - distributed.worker - INFO -          dashboard at:           10.6.83.15:35317
2025-10-02 09:24:29,072 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,072 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,073 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,072 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,073 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,073 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-3i1x98vu
2025-10-02 09:24:29,073 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,074 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,074 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,075 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,081 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:33051
2025-10-02 09:24:29,081 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:33051
2025-10-02 09:24:29,081 - distributed.worker - INFO -          dashboard at:           10.6.83.15:35477
2025-10-02 09:24:29,081 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,081 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,081 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,081 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,081 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-q4h1jxcq
2025-10-02 09:24:29,081 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,084 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,084 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:39143
2025-10-02 09:24:29,084 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:39143
2025-10-02 09:24:29,084 - distributed.worker - INFO -          dashboard at:           10.6.83.15:41143
2025-10-02 09:24:29,084 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,084 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,084 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,084 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,084 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,084 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-8rni888t
2025-10-02 09:24:29,084 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,084 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,084 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:39203
2025-10-02 09:24:29,085 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:39203
2025-10-02 09:24:29,085 - distributed.worker - INFO -          dashboard at:           10.6.83.15:45487
2025-10-02 09:24:29,085 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,085 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,085 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,085 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,085 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-aj1qe4pj
2025-10-02 09:24:29,085 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,086 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,086 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:34545
2025-10-02 09:24:29,086 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:34545
2025-10-02 09:24:29,086 - distributed.worker - INFO -          dashboard at:           10.6.83.15:34687
2025-10-02 09:24:29,086 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,086 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,086 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,086 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,086 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-89v9n_g2
2025-10-02 09:24:29,086 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,086 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:43087
2025-10-02 09:24:29,086 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:43087
2025-10-02 09:24:29,086 - distributed.worker - INFO -          dashboard at:           10.6.83.15:43293
2025-10-02 09:24:29,086 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,087 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,087 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,087 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,087 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-pp11vf3n
2025-10-02 09:24:29,087 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,088 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:43567
2025-10-02 09:24:29,088 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:43567
2025-10-02 09:24:29,088 - distributed.worker - INFO -          dashboard at:           10.6.83.15:45159
2025-10-02 09:24:29,088 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,088 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,088 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,088 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:39347
2025-10-02 09:24:29,088 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,088 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:39347
2025-10-02 09:24:29,088 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-7_tzprzj
2025-10-02 09:24:29,088 - distributed.worker - INFO -          dashboard at:           10.6.83.15:43639
2025-10-02 09:24:29,088 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,088 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,088 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,088 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,088 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,088 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-ekmzqc5c
2025-10-02 09:24:29,088 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,088 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:41441
2025-10-02 09:24:29,088 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:41441
2025-10-02 09:24:29,088 - distributed.worker - INFO -          dashboard at:           10.6.83.15:37187
2025-10-02 09:24:29,088 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,088 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,088 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,088 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,088 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-opeotu07
2025-10-02 09:24:29,088 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,089 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:37545
2025-10-02 09:24:29,089 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:37545
2025-10-02 09:24:29,090 - distributed.worker - INFO -          dashboard at:           10.6.83.15:36037
2025-10-02 09:24:29,090 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,090 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,090 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,090 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,090 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-ob_7kenh
2025-10-02 09:24:29,090 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,090 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,090 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:34507
2025-10-02 09:24:29,090 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:34507
2025-10-02 09:24:29,090 - distributed.worker - INFO -          dashboard at:           10.6.83.15:37027
2025-10-02 09:24:29,090 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,091 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,091 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,091 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,091 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-zjgrr9k6
2025-10-02 09:24:29,091 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,091 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,091 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,092 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,093 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:37463
2025-10-02 09:24:29,093 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:37463
2025-10-02 09:24:29,093 - distributed.worker - INFO -          dashboard at:           10.6.83.15:44191
2025-10-02 09:24:29,093 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,093 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,093 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,093 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,093 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-y_zrgcp5
2025-10-02 09:24:29,093 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,097 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,097 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:45881
2025-10-02 09:24:29,097 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:45881
2025-10-02 09:24:29,097 - distributed.worker - INFO -          dashboard at:           10.6.83.15:45419
2025-10-02 09:24:29,097 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,097 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,097 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,097 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,097 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-1qmo9d4l
2025-10-02 09:24:29,097 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,098 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,098 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,098 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:45443
2025-10-02 09:24:29,098 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:45443
2025-10-02 09:24:29,098 - distributed.worker - INFO -          dashboard at:           10.6.83.15:38573
2025-10-02 09:24:29,098 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,098 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,098 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,098 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,098 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-bcra6d05
2025-10-02 09:24:29,098 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,099 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,101 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:36725
2025-10-02 09:24:29,101 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:36725
2025-10-02 09:24:29,101 - distributed.worker - INFO -          dashboard at:           10.6.83.15:35497
2025-10-02 09:24:29,101 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,101 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,102 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,102 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,102 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,102 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-jsm_5h5v
2025-10-02 09:24:29,102 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,102 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,102 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,102 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,103 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:38847
2025-10-02 09:24:29,103 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:38847
2025-10-02 09:24:29,103 - distributed.worker - INFO -          dashboard at:           10.6.83.15:37561
2025-10-02 09:24:29,103 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,103 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,103 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,103 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,103 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-dq0xzo2b
2025-10-02 09:24:29,103 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,104 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,105 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,105 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,105 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:42293
2025-10-02 09:24:29,105 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:42293
2025-10-02 09:24:29,105 - distributed.worker - INFO -          dashboard at:           10.6.83.15:39091
2025-10-02 09:24:29,105 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,105 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,105 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,105 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,105 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-q7fpdjfi
2025-10-02 09:24:29,105 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,105 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,106 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:41763
2025-10-02 09:24:29,106 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:41763
2025-10-02 09:24:29,106 - distributed.worker - INFO -          dashboard at:           10.6.83.15:36867
2025-10-02 09:24:29,106 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,106 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,106 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,106 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,107 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-c6iih_6l
2025-10-02 09:24:29,107 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,107 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:39527
2025-10-02 09:24:29,107 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:39527
2025-10-02 09:24:29,107 - distributed.worker - INFO -          dashboard at:           10.6.83.15:45829
2025-10-02 09:24:29,107 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,107 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,107 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:40655
2025-10-02 09:24:29,107 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,107 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,107 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:40655
2025-10-02 09:24:29,107 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-uxt7pw7u
2025-10-02 09:24:29,107 - distributed.worker - INFO -          dashboard at:           10.6.83.15:45579
2025-10-02 09:24:29,107 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,107 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,107 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,107 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,107 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,107 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-zn3s2xxc
2025-10-02 09:24:29,107 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,108 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,108 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,108 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,109 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,110 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,110 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,110 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,111 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,112 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,113 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,113 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,113 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:36411
2025-10-02 09:24:29,113 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:36411
2025-10-02 09:24:29,113 - distributed.worker - INFO -          dashboard at:           10.6.83.15:42011
2025-10-02 09:24:29,113 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,114 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,114 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,114 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,114 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-o7plf5w7
2025-10-02 09:24:29,114 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,114 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,116 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,116 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,116 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,117 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,118 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,118 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,118 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,119 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,120 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,120 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,120 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,121 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,121 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,122 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,122 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:37257
2025-10-02 09:24:29,122 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:37257
2025-10-02 09:24:29,122 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,122 - distributed.worker - INFO -          dashboard at:           10.6.83.15:37701
2025-10-02 09:24:29,122 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,122 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,122 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,122 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,122 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-oriw5a2r
2025-10-02 09:24:29,122 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,123 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,124 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,124 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,124 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,124 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,124 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,124 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,125 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,125 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,125 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,126 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,126 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,127 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,127 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:43051
2025-10-02 09:24:29,127 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:43051
2025-10-02 09:24:29,127 - distributed.worker - INFO -          dashboard at:           10.6.83.15:46679
2025-10-02 09:24:29,127 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,127 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,127 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,127 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,127 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-6ikm04uh
2025-10-02 09:24:29,127 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,128 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,129 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,129 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,129 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:35739
2025-10-02 09:24:29,129 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:35739
2025-10-02 09:24:29,129 - distributed.worker - INFO -          dashboard at:           10.6.83.15:35823
2025-10-02 09:24:29,129 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,129 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,129 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,130 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,130 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-t_hgn8vn
2025-10-02 09:24:29,130 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,131 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,131 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,131 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:36245
2025-10-02 09:24:29,132 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:36245
2025-10-02 09:24:29,132 - distributed.worker - INFO -          dashboard at:           10.6.83.15:45013
2025-10-02 09:24:29,132 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,132 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,132 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,132 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,132 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,132 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-jqt_u1ji
2025-10-02 09:24:29,132 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,132 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,132 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,133 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:35401
2025-10-02 09:24:29,133 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:35401
2025-10-02 09:24:29,133 - distributed.worker - INFO -          dashboard at:           10.6.83.15:37203
2025-10-02 09:24:29,133 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,133 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,133 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:29,133 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:29,133 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-4anr9uzd
2025-10-02 09:24:29,133 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,133 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,133 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,133 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,133 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,134 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,135 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,135 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,135 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,136 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,136 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,136 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,136 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,137 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,137 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,138 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,138 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,138 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,139 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,139 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,141 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,145 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,146 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,147 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,147 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,147 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,147 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,147 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,148 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,148 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,148 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,148 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,148 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,149 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,149 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,149 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,149 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,150 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,150 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,150 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,151 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:29,160 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:29,161 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:29,161 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:29,163 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:56,292 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,292 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,292 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,292 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,293 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,293 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,293 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,294 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,294 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,294 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,294 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,294 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,294 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,294 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,295 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,295 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,295 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,295 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,295 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,295 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,295 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,295 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,295 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,295 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,295 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,295 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,295 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,296 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,295 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,296 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,296 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,296 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,296 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,296 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,296 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,296 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,296 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,296 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,296 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,297 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,297 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,297 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,297 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,297 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,297 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,297 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,297 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,297 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,297 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,298 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,297 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,298 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,298 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,298 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,298 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,296 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,298 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,298 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,298 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,298 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,298 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,298 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,298 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,298 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,297 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,299 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,299 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,299 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,297 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,299 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,299 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,297 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,299 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,297 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,299 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,299 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,299 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,299 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,298 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,299 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,300 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,298 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,300 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,300 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,299 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,300 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,300 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,301 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,301 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,302 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,306 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,307 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,307 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,308 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,308 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,308 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,308 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,309 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,310 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,311 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,311 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,311 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,312 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,312 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:59,047 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,047 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,048 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,048 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,047 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,048 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,048 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,048 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,048 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,048 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,048 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,048 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,048 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,049 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,049 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,049 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,049 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,049 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,049 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,049 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,049 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,049 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,050 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,050 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,050 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,050 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,050 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,050 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,051 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,051 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,051 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,050 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,051 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,051 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,051 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,051 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,051 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,051 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,051 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,050 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,051 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,051 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,051 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,051 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,051 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,051 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,052 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,051 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,052 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,051 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,052 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,052 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,051 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,052 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,052 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,052 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,052 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,052 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,051 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,052 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,052 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,052 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,052 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,052 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,052 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,052 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,052 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,053 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,052 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,053 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,053 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,052 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,052 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,053 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,053 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,053 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,053 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,053 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,053 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,053 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,053 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,054 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,053 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,054 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,054 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,054 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,054 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,055 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,055 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,055 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,055 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,055 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,055 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,055 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,056 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,056 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,056 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,056 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,056 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,056 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,056 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,056 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,057 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,057 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,446 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,447 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,447 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,447 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,447 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,447 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,447 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,447 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,447 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,448 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,448 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,448 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,448 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,448 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,448 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,448 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,448 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,449 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,449 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,449 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,449 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,449 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,449 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,450 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,450 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,450 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,450 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,450 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,450 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,450 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,450 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,450 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,450 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,450 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,451 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,451 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,451 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,451 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,451 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,451 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,451 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,451 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,451 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,451 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,451 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,452 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,452 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,452 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,452 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,452 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,452 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,452 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,452 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,452 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,452 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,452 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,452 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,452 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,452 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,452 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,453 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,452 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,453 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,453 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,453 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,453 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,453 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,454 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,454 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,454 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,454 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,454 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,454 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,454 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,454 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,454 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,454 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,454 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,454 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,454 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,454 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,455 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,455 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,455 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,455 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,455 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,455 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,455 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,455 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,455 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,455 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,456 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,456 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,456 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,456 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,456 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,456 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,457 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,457 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,457 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,457 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,457 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,457 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,457 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,882 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,882 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,883 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,883 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,883 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,883 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,883 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,883 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,883 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,883 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,883 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,884 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,884 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,884 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,884 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,884 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,884 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,884 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,884 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,885 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,885 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,885 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,885 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,885 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,885 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,885 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,885 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,885 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,885 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,885 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,885 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,885 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,885 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,885 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,885 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,885 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,885 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,885 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,885 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,886 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,886 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,886 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,886 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,886 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,886 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,886 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,886 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,886 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,886 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,886 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,886 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,886 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,886 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,886 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,886 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,886 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,886 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,887 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,887 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,887 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,887 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,887 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,887 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,887 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,887 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,887 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,887 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,887 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,887 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,888 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,888 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,888 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,888 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,888 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,888 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,888 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,888 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,888 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,888 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,888 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,888 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,889 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,889 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,889 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,889 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,889 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,889 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,890 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,890 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,890 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,890 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,890 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,890 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,890 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,890 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,891 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,891 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,891 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,891 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,891 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,891 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,891 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,891 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,892 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:25:21,754 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:21,754 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:21,756 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:22,781 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,018 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,026 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,046 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,059 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,061 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,062 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,063 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,066 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,075 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,099 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,102 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,105 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,106 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,109 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,111 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,113 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,132 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,140 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,148 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,158 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,162 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,164 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,169 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,181 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,186 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,190 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,193 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,226 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,238 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 11:28:39,467 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 11:28:39,469 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 11:28:39,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 11:28:39,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 11:28:39,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 11:28:39,474 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 11:28:39,475 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 11:28:39,480 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 19:25:43,475 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,475 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,475 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,477 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,495 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:40655. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,475 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,495 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:36725. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,475 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,496 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:42293. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,476 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,496 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:45113. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,475 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,496 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:33051. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,477 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,496 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:37257. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,475 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,476 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,497 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:41441. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,497 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:41763. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,475 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,478 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,497 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:34507. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,497 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:46201. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,476 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,477 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,498 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:41523. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,498 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:38847. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,477 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,498 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:41567. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,477 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,476 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,498 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:35401. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,498 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:35739. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,476 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,476 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,499 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:36245. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,476 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,499 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:35217. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,476 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,477 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,479 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,500 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:39347. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,500 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:36673. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,500 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:35907. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,500 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:45261. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,500 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:44555. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,501 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:43087. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,504 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:45871. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,501 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,501 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,502 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,505 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,508 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:36283'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,510 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:45799. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,510 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:43551. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,511 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:43051. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,511 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,511 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,511 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,512 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,512 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,502 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,511 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,515 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:41509. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,515 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:33523'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,516 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:46361'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,516 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,516 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:36571'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,516 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,516 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,517 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,517 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:42285'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,517 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,517 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,517 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,517 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,517 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:39489'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,517 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,517 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,517 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,517 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,514 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,517 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,518 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:44819'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,514 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,518 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,515 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,518 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,518 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,514 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,518 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,518 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:37511'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,518 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,518 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,518 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,518 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,518 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,519 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,519 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,519 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:38415'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,519 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,519 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:36411. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,519 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,519 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,519 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,519 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,516 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,519 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,519 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,519 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,519 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,516 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,520 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,519 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,520 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,516 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,517 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,520 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,520 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:43567. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,520 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,521 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,521 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,521 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,519 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,523 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,523 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:37545. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,523 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:37463. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,523 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:39143. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,524 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:45443. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,521 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,521 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,524 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:34567'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,521 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,524 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,525 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:34159'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,525 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,525 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:38275. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,525 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:43441'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,525 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,525 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:36027. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,525 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:42725'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,525 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,525 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,526 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:45827'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,526 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:45245. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,526 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:33083. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,526 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,526 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,526 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:46551'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,526 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,526 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,526 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,526 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,526 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,526 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:41967'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,526 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,526 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,526 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,526 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:33015'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,526 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,526 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,527 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,527 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,527 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:39119'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,527 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,527 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,527 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,527 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,516 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,527 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,527 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,527 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:38365'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,527 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,527 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,527 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,527 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,527 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:40017'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,527 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:41229. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,527 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,528 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:36287'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,528 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,528 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,528 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,528 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,528 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,528 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,528 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:39547'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,528 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,528 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,528 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,528 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,528 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:39103'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,528 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,528 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,528 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,528 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,528 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,529 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,529 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,529 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,529 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,529 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,529 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,529 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,515 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,529 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,529 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,529 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,529 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,529 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,529 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,529 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,529 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,529 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,530 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,530 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,530 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,530 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,530 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,530 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,530 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,530 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:39203. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,530 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:45881. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,530 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,530 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:39527. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,530 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,530 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,531 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,531 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,531 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,519 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,531 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,532 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,533 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:40895. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,533 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,535 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:38703. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,532 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,536 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,536 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:35379'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,537 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:44491. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,538 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 2, 4, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,526 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,539 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:34545. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,539 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,540 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,540 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,540 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,541 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:43329. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,541 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,542 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,543 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,540 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,543 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,544 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,546 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,546 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,546 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,549 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:38253. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,553 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,554 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,555 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,554 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,560 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,563 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:36171. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,565 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,578 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:33951'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,589 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 14, 9, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,599 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:40111'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,602 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,606 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,611 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:38193. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,611 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,615 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 13, 19, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,616 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,622 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,627 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,637 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:35021'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,641 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,647 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,652 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,658 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,663 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,688 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:34523'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,712 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:46563'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,725 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 7, 20, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,725 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:38525'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,728 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,731 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,733 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:46647'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,736 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:33599'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,736 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,737 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:38031. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,742 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,747 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,750 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:39277'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,752 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,753 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:43953'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,754 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:43493'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,755 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:43445'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,753 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,762 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.15:39427. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,765 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:36971'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,767 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:42193'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,774 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:39705'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,775 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:44813'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,794 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:38379'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,805 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 14, 5, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,811 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,812 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:38035'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,816 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,821 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,827 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,832 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,865 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:43665'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,866 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:40881'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,885 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 13, 2, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,886 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,887 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,887 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,887 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,887 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,900 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 5, 7, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,900 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 16, 5, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,906 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,912 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,917 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,919 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:39963'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,922 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,924 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:39219'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,927 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,928 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,932 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,937 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,943 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,944 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:41861'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,948 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,951 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 5, 13, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,957 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,961 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 0, 3, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,963 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,967 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,967 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:33275'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,968 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,971 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 14, 4, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,972 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,973 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,977 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,977 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,978 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,982 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,983 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,988 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,988 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,993 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,994 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:37393'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,996 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 4, 0, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,998 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,002 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,004 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:34181'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:44,006 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 0, 6, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,007 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 14, 21, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,008 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,012 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 16, 9, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,013 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,013 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,018 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,018 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,018 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,024 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,024 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,024 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,029 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,029 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,030 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 10, 5, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,034 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,034 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,036 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,039 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,042 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,046 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 7, 14, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,047 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,052 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,053 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,057 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,059 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,064 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,068 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,069 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,073 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,074 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,079 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,084 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,089 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,176 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 14, 20, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,200 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 11, 19, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,202 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 5, 10, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,203 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,206 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,209 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,212 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,214 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,217 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,220 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,223 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,225 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,225 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:33899'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:44,228 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,229 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.15:33291'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:44,248 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 1, 7, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,252 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 4, 20, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,266 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,271 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,276 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 14, 8, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,276 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,282 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,284 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,285 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,287 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,290 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,291 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,295 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,296 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,300 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,301 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,303 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,305 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,306 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,308 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 2, 18, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,314 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,319 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,324 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,355 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 7, 19, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,370 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 12, 14, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,377 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,382 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,388 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,393 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,398 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,445 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,446 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 12, 9, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,449 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,451 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,454 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,456 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,460 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,461 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,465 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,466 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,470 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,472 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 3, 20, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,519 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,520 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,525 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,525 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,530 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,531 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,535 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,536 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,541 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,541 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,740 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 8, 6, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:45,020 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14a2647b10d0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:44,809 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14c5a64a3110>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:44,851 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:45,029 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14a9b398f290>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:45,521 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,529 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,529 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,531 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,531 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,533 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,536 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,537 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,540 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,544 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,544 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,545 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,545 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,546 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,548 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,550 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,551 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,556 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:45,557 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,560 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,561 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:45,151 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:45,566 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:45,572 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:45,577 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:45,185 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x147d0cf94990>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:45,806 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:36283'. Reason: nanny-close-gracefully
2025-10-02 19:25:45,808 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:46361'. Reason: nanny-close-gracefully
2025-10-02 19:25:45,810 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:36283' closed.
2025-10-02 19:25:45,811 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:46361' closed.
2025-10-02 19:25:45,816 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:38415'. Reason: nanny-close-gracefully
2025-10-02 19:25:45,818 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:38415' closed.
2025-10-02 19:25:45,919 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:39119'. Reason: nanny-close-gracefully
2025-10-02 19:25:45,920 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:39119' closed.
2025-10-02 19:25:45,955 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:39547'. Reason: nanny-close-gracefully
2025-10-02 19:25:45,957 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:39547' closed.
2025-10-02 19:25:45,966 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:36571'. Reason: nanny-close-gracefully
2025-10-02 19:25:45,969 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:36571' closed.
2025-10-02 19:25:45,982 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:39489'. Reason: nanny-close-gracefully
2025-10-02 19:25:45,984 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:39489' closed.
2025-10-02 19:25:46,079 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:33523'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,081 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:33523' closed.
2025-10-02 19:25:46,083 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:44819'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,084 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:44819' closed.
2025-10-02 19:25:46,099 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:42285'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,100 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:42285' closed.
2025-10-02 19:25:46,129 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:43441'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,132 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:37511'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,132 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:43441' closed.
2025-10-02 19:25:46,133 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:37511' closed.
2025-10-02 19:25:46,136 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:42725'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,137 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:42725' closed.
2025-10-02 19:25:46,139 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:34567'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,140 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:34567' closed.
2025-10-02 19:25:46,160 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:33015'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,162 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:33015' closed.
2025-10-02 19:25:46,182 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:38365'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,183 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:38365' closed.
2025-10-02 19:25:46,208 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:34159'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,215 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:41967'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,216 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:34159' closed.
2025-10-02 19:25:46,217 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:41967' closed.
2025-10-02 19:25:46,223 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:40017'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,224 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:46551'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,224 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:40017' closed.
2025-10-02 19:25:46,224 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:46551' closed.
2025-10-02 19:25:46,238 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:36287'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,239 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:36287' closed.
2025-10-02 19:25:46,352 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:39103'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,353 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:39103' closed.
2025-10-02 19:25:46,408 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:45827'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,409 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:45827' closed.
2025-10-02 19:25:46,067 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1512923c1810>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:48,597 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:48,784 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:50,601 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:50,789 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:51,066 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:39219'. Reason: nanny-close-gracefully
2025-10-02 19:25:51,067 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:39219' closed.
2025-10-02 19:25:51,269 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.15:33275'. Reason: nanny-close-gracefully
2025-10-02 19:25:51,271 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.15:33275' closed.
